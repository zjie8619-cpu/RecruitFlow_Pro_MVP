import json
import os
import re
import time
import uuid

import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict
# å¯é€‰å¯¼å…¥ plotlyï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ
try:
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    go = None
from backend.storage.db import init_db, get_db
from backend.services.pipeline import RecruitPipeline
from backend.services.reporting import export_round_report
from backend.utils.versioning import VersionManager
from backend.utils.field_mapping import translate_dataframe_columns, translate_field
# å¼ºåˆ¶é‡æ–°åŠ è½½æ¨¡å—ï¼Œé¿å…ç¼“å­˜é—®é¢˜
import importlib
import sys
if 'backend.services.jd_ai' in sys.modules:
    importlib.reload(sys.modules['backend.services.jd_ai'])
from backend.services.jd_ai import generate_jd_bundle, construct_full_ability_list
from backend.services.resume_parser import parse_uploaded_files_to_df
# ğŸ”„ ç¡®ä¿ AI åŒ¹é…é€»è¾‘æ›´æ–°æ—¶ç«‹å³ç”Ÿæ•ˆ
if 'backend.services.ai_matcher' in sys.modules:
    importlib.reload(sys.modules['backend.services.ai_matcher'])
from backend.services.ai_matcher import ai_match_resumes_df
from backend.services.ai_matcher_ultra import ai_match_resumes_df_ultra
from backend.services.ai_core import generate_ai_summary, generate_ai_email
# ğŸ”„ å¼ºåˆ¶é‡æ–°åŠ è½½æ—¥å†å·¥å…·æ¨¡å—ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬
if 'backend.services.calendar_utils' in sys.modules:
    importlib.reload(sys.modules['backend.services.calendar_utils'])
# åˆ é™¤å¯èƒ½å­˜åœ¨çš„æ—§å¯¼å…¥
if 'create_ics_file' in globals():
    del create_ics_file
from backend.services.calendar_utils import create_ics_file

def add_name_title(name: str, row_dict: dict = None) -> str:
    """
    ç»™å§“åæ·»åŠ å…ˆç”Ÿ/å¥³å£«ç§°å‘¼
    
    Args:
        name: å€™é€‰äººå§“å
        row_dict: å€™é€‰äººæ•°æ®å­—å…¸ï¼ˆå¯é€‰ï¼Œç”¨äºæå–æ€§åˆ«ä¿¡æ¯ï¼‰
    
    Returns:
        å¸¦ç§°å‘¼çš„å§“åï¼Œå¦‚"å¼ ä¸‰å…ˆç”Ÿ"æˆ–"æå››å¥³å£«"
    """
    if not name or name == "åŒ¿åå€™é€‰äºº":
        return "å…ˆç”Ÿ/å¥³å£«"
    
    # å°è¯•ä»æ•°æ®ä¸­æå–æ€§åˆ«ä¿¡æ¯
    gender = None
    if row_dict:
        # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„å­—æ®µä¸­æå–æ€§åˆ«
        gender_text = str(row_dict.get("gender", "") or row_dict.get("æ€§åˆ«", "") or "").strip()
        if "å¥³" in gender_text:
            gender = "å¥³"
        elif "ç”·" in gender_text:
            gender = "ç”·"
    
    # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„æ€§åˆ«ä¿¡æ¯ï¼Œå°è¯•ä»å§“ååˆ¤æ–­ï¼ˆç®€å•è§„åˆ™ï¼‰
    if not gender:
        # å¸¸è§å¥³æ€§åå­—ç‰¹å¾ï¼ˆç®€å•åˆ¤æ–­ï¼Œä¸å‡†ç¡®ä½†å¯ç”¨ï¼‰
        female_name_chars = ["éœ", "èŠ³", "å¨œ", "æ•", "é™", "ä¸½", "è‰³", "çº¢", "ç²", "é›ª", "æ¢…", "å…°", "èŠ", "è²", "èŠ±", "æœˆ", "æ˜¥", "ç§‹", "å†¬", "ç¾", "ç§€", "è‹±", "å", "æ…§", "å¨Ÿ", "è‰", "è", "ç‡•", "å‡¤", "å©·", "æ¬£", "æ‚¦", "æ€¡", "ç³", "è¹", "é›¯", "é›…", "æ´", "å€©", "è–‡", "èŒœ", "è“‰", "è²", "ç‘¶", "ç’", "ç‘¾", "ç’‡", "ç’", "ç’", "ç’"]
        # å¦‚æœåå­—æœ€åä¸€ä¸ªå­—åœ¨å¥³æ€§åå­—ç‰¹å¾ä¸­ï¼Œä½¿ç”¨"å¥³å£«"
        if len(name) >= 2 and name[-1] in female_name_chars:
            gender = "å¥³"
        else:
            # é»˜è®¤ä½¿ç”¨"å…ˆç”Ÿ"
            gender = "ç”·"
    
    return f"{name}{'å¥³å£«' if gender == 'å¥³' else 'å…ˆç”Ÿ'}"
# from backend.services.excel_exporter import generate_competency_excel, export_ability_sheet_to_file  # å‡½æ•°ä¸å­˜åœ¨ï¼Œå·²æ³¨é‡Š


def _ensure_job_meta() -> dict:
    """ç¡®ä¿ session_state ä¸­å­˜åœ¨ job_meta å¹¶è¿”å›å¼•ç”¨ã€‚"""
    if "job_meta" not in st.session_state:
        st.session_state["job_meta"] = {}
    return st.session_state["job_meta"]


def _update_job_meta(*, job_name: str = None, must: str = None, nice: str = None, exclude: str = None) -> None:
    """å°†å²—ä½åç§°ä¸ä»»èŒè¦æ±‚å…ƒæ•°æ®å†™å…¥ session_state."""
    meta = _ensure_job_meta()
    if job_name:
        meta["job_name"] = job_name
    if must:
        meta["job_must_have_skills"] = must
    if nice:
        meta["job_bonus_skills"] = nice
    if exclude:
        meta["job_exclude_list"] = exclude


def _build_invite_lookup(invites) -> Dict[str, Dict[str, Any]]:
    """å°†é‚€çº¦ç»“æœè½¬æ¢ä¸ºå¯åœ¨å¯¼å‡ºæ—¶æŸ¥æ‰¾çš„å­—å…¸ã€‚"""
    lookup: Dict[str, Dict[str, Any]] = {}
    if not invites:
        return lookup
    for invite in invites:
        if not isinstance(invite, dict):
            continue
        meta = {
            "interview_time": invite.get("interview_time"),
            "interview_location": invite.get("interview_location"),
            "ics_path": invite.get("ics") or invite.get("ics_path", ""),
            "email_subject": invite.get("subject"),
            "email_sent": invite.get("email_sent"),
            "email_sent_at": invite.get("email_sent_at"),
            "email_status": invite.get("email_status"),
            "wechat_sent": invite.get("wechat_sent"),
            "email": invite.get("email"),
            "candidate_id": invite.get("candidate_id"),
            "file": invite.get("file") or invite.get("resume_file"),
        }
        keys = set()
        cand_id = str(invite.get("candidate_id") or "").strip()
        if cand_id:
            keys.add(cand_id)
        email = (invite.get("email") or "").strip().lower()
        if email:
            keys.add(email)
        file_token = str(invite.get("file") or invite.get("resume_file") or "").strip()
        if file_token:
            keys.add(file_token)
        for key in keys:
            lookup[key] = {k: v for k, v in meta.items() if v not in (None, "", [])}
    return lookup

# å¼ºåˆ¶é‡æ–°åŠ è½½ Excel å¯¼å‡ºæ¨¡å—ï¼Œç¡®ä¿æ¨¡æ¿æ ·å¼è°ƒæ•´åå‰ç«¯ç«‹å³ç”Ÿæ•ˆ
if 'backend.services.export_excel' in sys.modules:
    importlib.reload(sys.modules['backend.services.export_excel'])
from backend.services.export_excel import export_competency_excel
from dotenv import load_dotenv

# å°è¯•ä»å¤šä¸ªä½ç½®åŠ è½½.envæ–‡ä»¶
env_paths = [
    Path('.env'),  # å½“å‰ç›®å½•ï¼ˆapp/ï¼‰
    Path('../.env'),  # é¡¹ç›®æ ¹ç›®å½•
    Path(__file__).parent.parent / '.env',  # é¡¹ç›®æ ¹ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼‰
]
for env_path in env_paths:
    if env_path.exists():
        load_dotenv(dotenv_path=env_path)
        break
else:
    load_dotenv()  # é»˜è®¤åŠ è½½

# --- session åˆå§‹åŒ–ï¼ˆæ”¾åœ¨ import ä¹‹åï¼‰---
if "ai_bundle" not in st.session_state:
    st.session_state["ai_bundle"] = None

# ============ æ§åˆ¶æ˜¾ç¤ºéƒ¨åˆ† ============
SHOW_OFFLINE_SECTION = False   # æ˜¯å¦æ˜¾ç¤ºâ€œç¦»çº¿è§„åˆ™ç‰ˆâ€
SHOW_DETAIL_SECTIONS = True   # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†éƒ¨åˆ†ï¼ˆé•¿ç‰ˆJD / å²—ä½èƒ½åŠ›ç»´åº¦ / é¢è¯•é¢˜ç­‰ï¼‰
# =====================================

st.set_page_config(page_title="RecruitFlow | ä¸€é”®æ‹›è˜æµæ°´çº¿", layout="wide")

# ==================== UI ä¼˜åŒ–æ ·å¼ ====================
st.markdown("""
<style>
    /* ç®€å†æ‘˜è¦3è¡Œé™åˆ¶ */
    .resume-mini {
        display: -webkit-box;
        -webkit-line-clamp: 3;
        -webkit-box-orient: vertical;
        overflow: hidden;
        text-overflow: ellipsis;
        line-height: 1.5;
        max-height: 4.5em;
    }
    
    /* äº®ç‚¹æ ‡ç­¾æ ·å¼ */
    .highlight-tag {
        display: inline-block;
        padding: 4px 12px;
        margin: 4px 4px 4px 0;
        border-radius: 16px;
        font-size: 0.85em;
        font-weight: 500;
        white-space: nowrap;
    }
    
    .highlight-tag-green {
        background-color: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
    }
    
    .highlight-tag-yellow {
        background-color: #fff3cd;
        color: #856404;
        border: 1px solid #ffeaa7;
    }
    
    .highlight-tag-gray {
        background-color: #e9ecef;
        color: #495057;
        border: 1px solid #dee2e6;
    }
    
    /* æ¦‚è§ˆå¡ç‰‡æ ·å¼ */
    .candidate-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 12px;
        color: white;
        margin-bottom: 20px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    .candidate-card h3 {
        color: white;
        margin: 0 0 10px 0;
        font-size: 1.5em;
    }
    
    .candidate-card .score {
        font-size: 2em;
        font-weight: bold;
        margin: 10px 0;
    }
    
    /* æ¨ç†é“¾å¡ç‰‡æ ·å¼ */
    .reasoning-item {
        background: #f8f9fa;
        padding: 15px;
        margin: 10px 0;
        border-radius: 8px;
        border-left: 4px solid #667eea;
    }
    
    .reasoning-item strong {
        color: #495057;
    }
    
    /* å“åº”å¼å¸ƒå±€ */
    @media (max-width: 768px) {
        .candidate-card {
            padding: 15px;
        }
        .candidate-card h3 {
            font-size: 1.2em;
        }
        .candidate-card .score {
            font-size: 1.5em;
        }
    }
</style>
""", unsafe_allow_html=True)

st.title("RecruitFlow â€” ä¸€é”®æ‹›è˜æµæ°´çº¿ï¼ˆæ•™è‚²æœºæ„ç‰ˆï¼‰")

def sanitize_single_line(text, default="æœªæä¾›ç›¸å…³ä¿¡æ¯", limit=None):
    if text is None:
        return default
    cleaned = str(text).replace("\r", " ").replace("\n", "ï¼›")
    cleaned = re.sub(r"\s+", " ", cleaned)
    cleaned = (
        cleaned.replace(",", "ï¼Œ")
        .replace(";", "ï¼›")
        .replace("|", "ï½œ")
        .strip(" ï¼›")
    )
    if not cleaned:
        cleaned = default
    if limit and len(cleaned) > limit:
        cleaned = cleaned[:limit].rstrip("ï¼› ï¼Œ") + "..."
    return cleaned


def _clean_single_line(text, default="æœªæä¾›", limit=None):
    return sanitize_single_line(text, default, limit)


def _format_highlights_for_export(row_dict):
    """
    æ ¼å¼åŒ–äº®ç‚¹æ ‡ç­¾ç”¨äºå¯¼å‡º
    ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„highlight_tagså­—æ®µï¼Œç¡®ä¿ä¸çº¿ä¸Šæ˜¾ç¤ºå®Œå…¨ä¸€è‡´
    """
    tags = []
    
    # ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„highlight_tagsï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰
    highlight_tags = row_dict.get("highlight_tags", [])
    
    # å¤„ç†å„ç§å¯èƒ½çš„å­˜å‚¨æ ¼å¼
    if highlight_tags is not None:
        # å¦‚æœæ˜¯åˆ—è¡¨
        if isinstance(highlight_tags, list):
            tags = [str(tag).strip() for tag in highlight_tags if tag and str(tag).strip()]
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ˆå¯èƒ½è¢«åºåˆ—åŒ–äº†ï¼‰
        elif isinstance(highlight_tags, str):
            # å°è¯•è§£æJSONå­—ç¬¦ä¸²
            if highlight_tags.startswith("[") or highlight_tags.startswith("{"):
                try:
                    import json
                    parsed = json.loads(highlight_tags)
                    if isinstance(parsed, list):
                        tags = [str(tag).strip() for tag in parsed if tag and str(tag).strip()]
                    else:
                        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼ŒæŒ‰åˆ†éš”ç¬¦åˆ†å‰²
                        tags = [seg.strip() for seg in re.split(r"[ï½œ|ï¼Œ,ã€ï¼›\s]+", highlight_tags) if seg.strip()]
                except:
                    # è§£æå¤±è´¥ï¼ŒæŒ‰åˆ†éš”ç¬¦åˆ†å‰²
                    tags = [seg.strip() for seg in re.split(r"[ï½œ|ï¼Œ,ã€ï¼›\s]+", highlight_tags) if seg.strip()]
            else:
                # æ™®é€šå­—ç¬¦ä¸²ï¼ŒæŒ‰åˆ†éš”ç¬¦åˆ†å‰²
                tags = [seg.strip() for seg in re.split(r"[ï½œ|ï¼Œ,ã€ï¼›\s]+", highlight_tags) if seg.strip()]
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå›é€€åˆ°highlightså­—æ®µï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰
    if not tags:
        raw = row_dict.get("highlights", "")
        if isinstance(raw, str) and raw.strip():
            # æ”¯æŒå¤šç§åˆ†éš”ç¬¦
            tags = [seg.strip() for seg in re.split(r"[ï½œ|ï¼Œ,ã€ï¼›\s]+", raw) if seg.strip()]
        elif isinstance(raw, list):
            tags = [str(seg).strip() for seg in raw if str(seg).strip()]
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä»tagså­—æ®µè·å–
    if not tags:
        tags_field = row_dict.get("tags", [])
        if isinstance(tags_field, list):
            tags = [str(tag).strip() for tag in tags_field if str(tag).strip()]
        elif isinstance(tags_field, str):
            tags = [seg.strip() for seg in re.split(r"[ï½œ|ï¼Œ,ã€ï¼›\s]+", tags_field) if seg.strip()]
    
    # ç¡®ä¿è‡³å°‘æœ‰æ ‡ç­¾
    if not tags:
        tags = ["ç»¼åˆèƒ½åŠ›"]
    
    # è¿”å›æ‰€æœ‰æ ‡ç­¾ï¼Œç”¨|åˆ†éš”ï¼ˆä¸çº¿ä¸Šæ˜¾ç¤ºä¸€è‡´ï¼‰
    return "|".join(tags) if tags else "æœªæä¾›"


def _safe_load_json(value):
    if isinstance(value, dict):
        return value
    if isinstance(value, str):
        try:
            return json.loads(value)
        except Exception:
            return {}
    return {}


def _format_resume_summary(row_dict):
    """
    æ ¼å¼åŒ–ç®€å†æ‘˜è¦ç”¨äºå¯¼å‡º
    ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„ai_resume_summaryæˆ–summary_shortå­—æ®µ
    ç¡®ä¿ä¸çº¿ä¸Šæ˜¾ç¤ºå®Œå…¨ä¸€è‡´ï¼Œä¸æˆªæ–­
    """
    # ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„å­—æ®µ
    summary = (
        row_dict.get("ai_resume_summary", "") or 
        row_dict.get("summary_short", "") or 
        row_dict.get("resume_mini", "") or 
        row_dict.get("summary", "") or
        ""
    )
    
    # å¦‚æœæ‘˜è¦ä¸ºç©ºï¼Œå°è¯•ä»short_evalè·å–
    if not summary or summary.strip() == "":
        short_eval = row_dict.get("short_eval", "")
        if short_eval and short_eval.strip():
            summary = short_eval
    
    # æ¸…ç†æ–‡æœ¬ä½†ä¸è¿‡åº¦æˆªæ–­ï¼ˆç§»é™¤æ¢è¡Œå’Œå¤šä½™ç©ºæ ¼ï¼Œä½†ä¿ç•™å®Œæ•´å†…å®¹ï¼‰
    if summary:
        # åªåšåŸºæœ¬æ¸…ç†ï¼Œä¸æˆªæ–­
        cleaned = str(summary).replace("\r", " ").replace("\n", "ï¼›")
        cleaned = re.sub(r"\s+", " ", cleaned)
        cleaned = cleaned.strip()
        return cleaned if cleaned else "æœªæä¾›ç›¸å…³ä¿¡æ¯"
    
    return "æœªæä¾›ç›¸å…³ä¿¡æ¯"


def _format_evidence_field(row_dict):
    """
    æ ¼å¼åŒ–è¯æ®å­—æ®µç”¨äºå¯¼å‡º
    ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„ai_reviewã€evidence_textã€strengths_reasoning_chainç­‰å­—æ®µ
    ç¡®ä¿ä¸çº¿ä¸Šæ˜¾ç¤ºå®Œå…¨ä¸€è‡´ï¼Œä¸æˆªæ–­
    """
    # ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„ai_reviewï¼ˆå®Œæ•´çš„AIè¯„ä»·ï¼‰
    ai_review = row_dict.get("ai_review", "") or row_dict.get("ai_evaluation", "")
    if ai_review and len(ai_review.strip()) > 20:
        # å¦‚æœai_reviewå­˜åœ¨ä¸”æœ‰æ„ä¹‰ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆåªåšåŸºæœ¬æ¸…ç†ï¼Œä¸æˆªæ–­ï¼‰
        cleaned = str(ai_review).replace("\r", " ").replace("\n", "ï¼›")
        cleaned = re.sub(r"\s+", " ", cleaned)
        cleaned = cleaned.strip()
        return cleaned if cleaned else ""
    
    # å›é€€åˆ°evidence_text
    evidence_text = row_dict.get("evidence_text", "")
    if evidence_text and len(evidence_text.strip()) > 20:
        cleaned = str(evidence_text).replace("\r", " ").replace("\n", "ï¼›")
        cleaned = re.sub(r"\s+", " ", cleaned)
        cleaned = cleaned.strip()
        return cleaned if cleaned else ""
    
    # å°è¯•ä»æ¨ç†é“¾æ„å»º
    reasoning = _safe_load_json(row_dict.get("reasoning_chain"))
    short_eval_struct = _safe_load_json(row_dict.get("short_eval_struct"))
    
    # å°è¯•ä»Ultraæ ¼å¼çš„æ¨ç†é“¾è·å–
    strengths_chain = row_dict.get("strengths_reasoning_chain", {})
    weaknesses_chain = row_dict.get("weaknesses_reasoning_chain", {})
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
    if isinstance(strengths_chain, str):
        try:
            import json
            strengths_chain = json.loads(strengths_chain)
        except:
            strengths_chain = {}
    if isinstance(weaknesses_chain, str):
        try:
            import json
            weaknesses_chain = json.loads(weaknesses_chain)
        except:
            weaknesses_chain = {}
    
    def _format_strengths():
        # ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„strengths_reasoning_chain
        if isinstance(strengths_chain, dict) and strengths_chain:
            conclusion = _clean_single_line(strengths_chain.get("conclusion"), "æœªå‘½åä¼˜åŠ¿", 20)
            actions = strengths_chain.get("detected_actions", [])
            actions_str = ", ".join(actions[:3]) if isinstance(actions, list) else str(actions)[:30]
            evidence = strengths_chain.get("resume_evidence", [])
            evidence_str = ", ".join(evidence[:2]) if isinstance(evidence, list) else str(evidence)[:40]
            reasoning_txt = _clean_single_line(strengths_chain.get("ai_reasoning"), "æœªæä¾›", 50)
            return f"{conclusion}ï½œåŠ¨ä½œ:{actions_str}ï½œè¯æ®:{evidence_str}ï½œæ¨æ–­:{reasoning_txt}"
        
        # å›é€€åˆ°æ—§æ ¼å¼
        chain = reasoning.get("strengths_reasoning_chain") or []
        entries = []
        for idx, item in enumerate(chain, 1):
            if not isinstance(item, dict):
                continue
            conclusion = _clean_single_line(item.get("conclusion"), "æœªå‘½åä¼˜åŠ¿", 18)
            actions = _clean_single_line(item.get("detected_actions"), "æœªæä¾›", 24)
            evidence = _clean_single_line(item.get("resume_evidence"), "æœªæä¾›", 48)
            reasoning_txt = _clean_single_line(item.get("ai_reasoning"), "æœªæä¾›", 36)
            entries.append(f"{idx}. {conclusion}ï½œåŠ¨ä½œ:{actions}ï½œè¯æ®:{evidence}ï½œæ¨æ–­:{reasoning_txt}")
        return "ï¼›".join(entries) if entries else "æš‚æ— å¯éªŒè¯ä¼˜åŠ¿"

    def _format_weaknesses():
        # ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„weaknesses_reasoning_chain
        if isinstance(weaknesses_chain, dict) and weaknesses_chain:
            conclusion = _clean_single_line(weaknesses_chain.get("conclusion"), "æœªå‘½ååŠ£åŠ¿", 20)
            gap = weaknesses_chain.get("resume_gap", [])
            gap_str = ", ".join(gap[:2]) if isinstance(gap, list) else str(gap)[:30]
            compare = _clean_single_line(weaknesses_chain.get("compare_to_jd"), "æœªæä¾›", 40)
            reasoning_txt = _clean_single_line(weaknesses_chain.get("ai_reasoning"), "æœªæä¾›", 50)
            return f"{conclusion}ï½œç¼ºå£:{gap_str}ï½œJD:{compare}ï½œé£é™©:{reasoning_txt}"
        
        # å›é€€åˆ°æ—§æ ¼å¼
        chain = reasoning.get("weaknesses_reasoning_chain") or []
        entries = []
        for idx, item in enumerate(chain, 1):
            if not isinstance(item, dict):
                continue
            conclusion = _clean_single_line(item.get("conclusion"), "æœªå‘½ååŠ£åŠ¿", 18)
            gap = _clean_single_line(item.get("resume_gap"), "æœªæä¾›", 32)
            compare = _clean_single_line(item.get("compare_to_jd"), "æœªæä¾›", 40)
            risk = _clean_single_line(item.get("ai_reasoning"), "æœªæä¾›", 36)
            entries.append(f"{idx}. {conclusion}ï½œç¼ºå£:{gap}ï½œJD:{compare}ï½œé£é™©:{risk}")
        return "ï¼›".join(entries) if entries else "æš‚æ— å¯éªŒè¯åŠ£åŠ¿"

    # è·å–åŒ¹é…åº¦
    match_level = (
        row_dict.get("match_level", "") or 
        row_dict.get("match_summary", "") or
        short_eval_struct.get("match_level", "æ— æ³•è¯„ä¼°")
    )
    match_reason = short_eval_struct.get("match_reason", "æœªæä¾›åŒ¹é…åŸå› ")
    
    # å¦‚æœmatch_levelä¸ºç©ºï¼Œå°è¯•ä»short_evalä¸­æå–
    if not match_level or match_level == "æ— æ³•è¯„ä¼°":
        short_eval = row_dict.get("short_eval", "")
        if "å¼ºçƒˆæ¨è" in short_eval:
            match_level = "å¼ºçƒˆæ¨è"
        elif "æ¨è" in short_eval:
            match_level = "æ¨è"
        elif "è°¨æ…æ¨è" in short_eval:
            match_level = "è°¨æ…æ¨è"
        elif "æ·˜æ±°" in short_eval:
            match_level = "æ·˜æ±°"
        else:
            match_level = "æ— æ³•è¯„ä¼°"
    
    match_text = f"{match_level}ï¼š{match_reason}"

    strengths_text = _format_strengths()
    weaknesses_text = _format_weaknesses()
    
    evidence_text = f"ã€ä¼˜åŠ¿ã€‘{strengths_text}ã€åŠ£åŠ¿ã€‘{weaknesses_text}ã€åŒ¹é…åº¦ã€‘{match_text}"
    
    # åªåšåŸºæœ¬æ¸…ç†ï¼Œä¸æˆªæ–­
    if evidence_text:
        cleaned = str(evidence_text).replace("\r", " ").replace("\n", "ï¼›")
        cleaned = re.sub(r"\s+", " ", cleaned)
        cleaned = cleaned.strip()
        return cleaned if cleaned else "æœªæä¾›"
    
    return "æœªæä¾›"


# ==================== UI ä¼˜åŒ–è¾…åŠ©å‡½æ•° ====================
def _get_highlight_color(tag: str) -> str:
    """æ ¹æ®æ ‡ç­¾å†…å®¹è¿”å›é¢œè‰²ç±»åˆ«ï¼ˆç»¿è‰²/é»„è‰²/ç°è‰²ï¼‰"""
    tag_lower = tag.lower()
    # æ·±ç»¿è‰²ï¼šå¼ºç›¸å…³èƒ½åŠ›
    if any(keyword in tag_lower for keyword in ["æ²Ÿé€š", "å­¦ä¹ ", "ç¨³å®š", "ç­ä¸»ä»»", "æ•™å­¦", "ç®¡ç†", "é¢†å¯¼", "å›¢é˜Ÿ"]):
        return "green"
    # é»„è‰²ï¼šé€šç”¨ä¼˜åŠ¿
    elif any(keyword in tag_lower for keyword in ["å®¢æœ", "ç”µè¯", "æ´»åŠ¨è¿è¥", "é”€å”®", "å¸‚åœº", "æ¨å¹¿"]):
        return "yellow"
    # ç°è‰²ï¼šè¡¥å……ä¿¡æ¯
    else:
        return "gray"


def _generate_summary_text(strengths_chain: list, weaknesses_chain: list) -> str:
    """å‰ç«¯è‡ªåŠ¨ç”Ÿæˆä¸€å¥è¯æ€»ç»“"""
    strengths_count = len(strengths_chain) if strengths_chain else 0
    weaknesses_count = len(weaknesses_chain) if weaknesses_chain else 0
    
    if strengths_count > weaknesses_count:
        # æå–ä¼˜åŠ¿å…³é”®è¯
        strength_keywords = []
        for item in strengths_chain[:2]:
            if isinstance(item, dict):
                conclusion = item.get("conclusion", "")
                if conclusion:
                    strength_keywords.append(conclusion)
        keywords_text = "ã€".join(strength_keywords[:2]) if strength_keywords else "å¤šä¸ªæ–¹é¢"
        return f"âœ… **æ¨èç†ç”±**ï¼šè¯¥å€™é€‰äººåœ¨ {keywords_text} æ–¹é¢è¾ƒä¸ºçªå‡ºï¼Œæ•´ä½“é€‚é…åº¦è‰¯å¥½ã€‚"
    elif weaknesses_count > 0:
        # æå–åŠ£åŠ¿å…³é”®è¯
        weakness_keywords = []
        for item in weaknesses_chain[:2]:
            if isinstance(item, dict):
                conclusion = item.get("conclusion", "")
                if conclusion:
                    weakness_keywords.append(conclusion)
        keywords_text = "ã€".join(weakness_keywords[:2]) if weakness_keywords else "æŸäº›æ–¹é¢"
        return f"âš ï¸ **é£é™©æç¤º**ï¼šè¯¥å€™é€‰äººåœ¨ {keywords_text} æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå»ºè®®ç»“åˆå²—ä½é‡ç‚¹è¯„ä¼°ã€‚"
    else:
        return "ğŸ“‹ **è¯„ä¼°ä¸­**ï¼šä¿¡æ¯ä¸è¶³ï¼Œå»ºè®®è¿›ä¸€æ­¥äº†è§£å€™é€‰äººæƒ…å†µã€‚"


def _create_radar_chart(scores: dict, standard_model: dict = None):
    """
    åˆ›å»ºè¯„åˆ†ç»´åº¦é›·è¾¾å›¾ï¼ˆæ”¯æŒæ ‡å‡†æ¨¡å‹å åŠ ï¼‰
    
    Args:
        scores: å€™é€‰äººå®é™…å¾—åˆ†
        standard_model: å²—ä½æ ‡å‡†èƒ½åŠ›æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    """
    # ä½¿ç”¨æ–‡ä»¶é¡¶éƒ¨å·²å¯¼å…¥çš„ plotly.graph_objects
    # å¦‚æœé¡¶éƒ¨å¯¼å…¥å¤±è´¥ï¼Œè¿™é‡Œä¼šæŠ›å‡º NameErrorï¼Œéœ€è¦æ£€æŸ¥ PLOTLY_AVAILABLE
    if not PLOTLY_AVAILABLE or go is None:
        raise ImportError("Plotly æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥ã€‚è¯·è¿è¡Œ: pip install plotly kaleido")
    
    categories = ["æŠ€èƒ½åŒ¹é…åº¦", "ç»éªŒç›¸å…³æ€§", "æˆé•¿æ½œåŠ›", "ç¨³å®šæ€§"]
    values = [
        float(scores.get("æŠ€èƒ½åŒ¹é…åº¦", 0)),
        float(scores.get("ç»éªŒç›¸å…³æ€§", 0)),
        float(scores.get("æˆé•¿æ½œåŠ›", 0)),
        float(scores.get("ç¨³å®šæ€§", 0)),
    ]
    
    # æ·»åŠ ç¬¬ä¸€ä¸ªå€¼åˆ°æœ«å°¾ä»¥é—­åˆå›¾å½¢
    values_closed = values + [values[0]]
    categories_closed = categories + [categories[0]]
    
    fig = go.Figure()
    
    # å¦‚æœæœ‰æ ‡å‡†æ¨¡å‹ï¼Œå…ˆç»˜åˆ¶æ ‡å‡†æ¨¡å‹ï¼ˆé†’ç›®é¢œè‰²ï¼‰
    if standard_model and isinstance(standard_model, dict):
        standard_values = [
            float(standard_model.get("skill_match", 0)),
            float(standard_model.get("experience_match", 0)),
            float(standard_model.get("growth_potential", 0)),
            float(standard_model.get("stability", 0)),
        ]
        standard_values_closed = standard_values + [standard_values[0]]
        
        # æ ‡å‡†æ¨¡å‹ï¼šçº¢è‰²ï¼Œé†’ç›®
        fig.add_trace(go.Scatterpolar(
            r=standard_values_closed,
            theta=categories_closed,
            fill='toself',
            name='å²—ä½æ ‡å‡†èƒ½åŠ›æ¨¡å‹',
            line=dict(color='#ff4444', width=3, dash='dash'),
            fillcolor='rgba(255, 68, 68, 0.15)',
            opacity=0.8
        ))
    
    # å€™é€‰äººå®é™…å¾—åˆ†ï¼šè“è‰²
    fig.add_trace(go.Scatterpolar(
        r=values_closed,
        theta=categories_closed,
        fill='toself',
        name='å€™é€‰äººå®é™…èƒ½åŠ›',
        line=dict(color='#1f77b4', width=2),
        fillcolor='rgba(31, 119, 180, 0.25)'
    ))
    
    # æ˜¾ç¤ºå›¾ä¾‹ï¼ˆå¦‚æœæœ‰æ ‡å‡†æ¨¡å‹ï¼‰
    show_legend = standard_model is not None
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100],
                tickfont=dict(size=10)
            ),
            angularaxis=dict(
                tickfont=dict(size=11)
            )
        ),
        showlegend=show_legend,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.1
        ) if show_legend else None,
        height=350,
        margin=dict(l=20, r=20, t=20, b=20)
    )
    
    return fig


def _build_export_dataframe(result_df, job_title):
    """
    æ„å»ºå¯¼å‡ºDataFrameï¼Œç¡®ä¿ä¸çº¿ä¸Šæ˜¾ç¤ºå®Œå…¨ä¸€è‡´
    åŒ…å«æ‰€æœ‰è¯„åˆ†ç»´åº¦ã€AIè¯„ä»·ã€é£é™©æç¤ºã€å²—ä½æ ‡å‡†èƒ½åŠ›æ¨¡å‹ç­‰å­—æ®µ
    """
    rows = []
    position_name = _clean_single_line(job_title, default="æœªæä¾›")
    
    for idx, (_, row) in enumerate(result_df.iterrows()):
        # å°†Seriesè½¬æ¢ä¸ºå­—å…¸ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½è¢«åŒ…å«
        row_dict = row.to_dict()
        
        # è°ƒè¯•ï¼šæ‰“å°å…³é”®å­—æ®µï¼ˆä»…ç¬¬ä¸€è¡Œï¼‰
        if idx == 0:
            import sys
            print(f"[DEBUG] å¯¼å‡ºè¡Œæ•°æ®ï¼ˆç¬¬1è¡Œï¼‰:", flush=True)
            print(f"  - highlight_tagsç±»å‹: {type(row_dict.get('highlight_tags'))}, å€¼: {row_dict.get('highlight_tags')}", flush=True)
            print(f"  - standard_modelå­˜åœ¨: {bool(row_dict.get('standard_model'))}, å€¼: {row_dict.get('standard_model')}", flush=True)
            print(f"  - ai_reviewå­˜åœ¨: {bool(row_dict.get('ai_review'))}, é•¿åº¦: {len(str(row_dict.get('ai_review', '')))}", flush=True)
        
        candidate_id = row_dict.get("candidate_id")
        try:
            candidate_id = int(candidate_id)
        except Exception:
            candidate_id = 0
        
        # è·å–å„ç»´åº¦åˆ†æ•°
        skill_match = int(round(float(row_dict.get("æŠ€èƒ½åŒ¹é…åº¦", row_dict.get("skill_match", 0)))))
        exp_relevance = int(round(float(row_dict.get("ç»éªŒç›¸å…³æ€§", row_dict.get("experience_match", 0)))))
        growth_potential = int(round(float(row_dict.get("æˆé•¿æ½œåŠ›", row_dict.get("growth_potential", 0)))))
        stability = int(round(float(row_dict.get("ç¨³å®šæ€§", row_dict.get("stability", 0)))))
        total_score = int(round(float(row_dict.get("æ€»åˆ†", row_dict.get("total_score", 0)))))
        
        # è·å–AIè¯„ä»·
        ai_evaluation = row_dict.get("ai_review", "") or row_dict.get("ai_evaluation", "") or row_dict.get("short_eval", "")
        if ai_evaluation:
            # åªåšåŸºæœ¬æ¸…ç†ï¼Œä¸æˆªæ–­
            ai_evaluation = str(ai_evaluation).replace("\r", " ").replace("\n", "ï¼›")
            ai_evaluation = re.sub(r"\s+", " ", ai_evaluation).strip()
        
        # è·å–é£é™©æç¤º
        risk_alert = row_dict.get("risk_alert", "")
        if not risk_alert:
            risks = row_dict.get("risks", [])
            if isinstance(risks, list) and risks:
                risk_types = [r.get("risk_type", "") if isinstance(r, dict) else str(r) for r in risks[:3] if r]
                risk_alert = "ï¼›".join(risk_types) if risk_types else "æ— "
            else:
                risk_alert = "æ— "
        if not risk_alert or risk_alert.strip() == "":
            risk_alert = "æ— "
        
        # è·å–å²—ä½æ ‡å‡†èƒ½åŠ›æ¨¡å‹
        standard_model = row_dict.get("standard_model", {})
        if isinstance(standard_model, str):
            try:
                import json
                standard_model = json.loads(standard_model)
            except:
                standard_model = {}
        
        standard_skill_match = int(round(float(standard_model.get("skill_match", standard_model.get("æŠ€èƒ½åŒ¹é…åº¦", 0)))))
        standard_exp_relevance = int(round(float(standard_model.get("experience_match", standard_model.get("ç»éªŒç›¸å…³æ€§", 0)))))
        standard_growth = int(round(float(standard_model.get("growth_potential", standard_model.get("æˆé•¿æ½œåŠ›", 0)))))
        standard_stability = int(round(float(standard_model.get("stability", standard_model.get("ç¨³å®šæ€§", 0)))))

        export_row = {
            "åºå·": idx + 1,  # è‡ªåŠ¨ç”Ÿæˆåºå·
            "å§“å": _clean_single_line(row_dict.get("name"), "æœªæä¾›"),
            "æ–‡ä»¶å": _clean_single_line(row_dict.get("file"), "æœªæä¾›"),
            "å²—ä½": position_name,
            "é‚®ç®±": _clean_single_line(row_dict.get("email"), "æœªæä¾›"),
            "æ‰‹æœºå·": _clean_single_line(row_dict.get("phone"), "æœªæä¾›"),
            "æ€»åˆ†": total_score,
            "äº®ç‚¹": _format_highlights_for_export(row_dict),
            "ç®€å†æ‘˜è¦": _format_resume_summary(row_dict),
            "AIè¯„ä»·": ai_evaluation if ai_evaluation else "æœªæä¾›",
            "æŠ€èƒ½åŒ¹é…åº¦": skill_match,
            "ç»éªŒç›¸å…³æ€§": exp_relevance,
            "æˆé•¿æ½œåŠ›": growth_potential,
            "ç¨³å®šæ€§": stability,
            "é£é™©æç¤º": risk_alert,
            "è¯æ®": _format_evidence_field(row_dict),
            "å²—ä½æ ‡å‡†-æŠ€èƒ½åŒ¹é…åº¦": standard_skill_match,
            "å²—ä½æ ‡å‡†-ç»éªŒç›¸å…³æ€§": standard_exp_relevance,
            "å²—ä½æ ‡å‡†-æˆé•¿æ½œåŠ›": standard_growth,
            "å²—ä½æ ‡å‡†-ç¨³å®šæ€§": standard_stability,
        }
        rows.append(export_row)
    
    return pd.DataFrame(rows)


with st.sidebar:
    st.header("è®¾ç½®")
    cfg_file = Path("backend/configs/model_config.json")
    cfg = json.loads(cfg_file.read_text(encoding="utf-8"))
    
    # AIé…ç½®ï¼ˆé”å®šä¸ºGPT-4ï¼‰
    st.subheader("AIé…ç½®")
    st.markdown("**AIæä¾›å•†ï¼š** OpenAI (å·²é”å®š)")
    st.markdown("**æ¨¡å‹åç§°ï¼š** GPT-4 (å·²é”å®š)")
    st.info("ğŸ”’ AIé…ç½®å·²é”å®šä¸ºGPT-4ï¼Œç¡®ä¿ç”Ÿæˆè´¨é‡ã€‚å¦‚éœ€ä¿®æ”¹ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚")
    st.caption("ğŸ’¡ è¯·è®¾ç½®ç¯å¢ƒå˜é‡: OPENAI_API_KEY æˆ–é…ç½® backend/configs/api_keys.json")
    
    # å›ºå®šä½¿ç”¨GPT-4
    llm_provider = "openai"
    llm_model = "gpt-4"
    
    st.markdown("---")
    
    # å…¶ä»–è®¾ç½®
    st.subheader("ç­›é€‰è®¾ç½®")
    
    blind = st.toggle("ç›²ç­›æ¨¡å¼ï¼ˆéšè—å§“å/å­¦æ ¡ç­‰ï¼‰", value=cfg.get("blind_screen", True),
                     help="å¼€å¯åï¼Œåœ¨ç®€å†ç­›é€‰è¿‡ç¨‹ä¸­éšè—å€™é€‰äººçš„å§“åã€å­¦æ ¡ç­‰æ•æ„Ÿä¿¡æ¯ï¼Œé¿å…å› ä¸ªäººèƒŒæ™¯äº§ç”Ÿåè§ï¼Œç¡®ä¿å…¬å¹³ç­›é€‰")
    
    thr = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, cfg.get("confidence_threshold", 0.65), 0.05,
                    help="è¯„åˆ†ç½®ä¿¡åº¦ä½äºæ­¤é˜ˆå€¼çš„å€™é€‰äººå°†è¢«æ ‡è®°ä¸º'é˜ˆå€¼æ‹¦æˆª'ï¼Œä¸ä¼šè‡ªåŠ¨å‘é€é‚€çº¦ã€‚å»ºè®®å€¼ï¼š0.6-0.7ã€‚å€¼è¶Šé«˜ï¼Œç­›é€‰è¶Šä¸¥æ ¼ã€‚")
    
    st.caption("ğŸ’¡ ç½®ä¿¡åº¦é˜ˆå€¼è¯´æ˜ï¼šç³»ç»Ÿä¼šæ ¹æ®ç®€å†åŒ¹é…åº¦è®¡ç®—ä¸€ä¸ªç½®ä¿¡åº¦åˆ†æ•°ã€‚ä½äºé˜ˆå€¼çš„å€™é€‰äººéœ€è¦äººå·¥å®¡æ ¸åæ‰èƒ½é‚€çº¦ã€‚")
    if st.button("ä¿å­˜è®¾ç½®"):
        cfg["blind_screen"] = blind
        cfg["confidence_threshold"] = float(thr)
        # AIé…ç½®å·²é”å®šï¼Œä¸æ›´æ–°
        cfg["llm_provider"] = "openai"
        cfg["llm_model"] = "gpt-4"
        cfg_file.write_text(json.dumps(cfg, ensure_ascii=False, indent=2), encoding="utf-8")
        st.success("âœ… è®¾ç½®å·²ä¿å­˜ï¼ˆAIé…ç½®ä¿æŒé”å®šä¸ºGPT-4ï¼‰")
    st.markdown("---"); st.caption("ç‰ˆæœ¬æ§åˆ¶")
    vm = VersionManager()
    if st.button("åˆ›å»ºå¿«ç…§"):
        st.success("å·²åˆ›å»ºç‰ˆæœ¬ï¼š" + vm.snapshot())


init_db(); pipe = RecruitPipeline()
tab1, tab2, tab3, tab4, tab5 = st.tabs(["1 ç”Ÿæˆ JD","2 ç®€å†è§£æ & åŒ¹é…","3 å»é‡ & æ’åº","4 é‚€çº¦ & æ’æœŸ","5 é¢è¯•åŒ… & å¯¼å‡º"])

with tab1:
    # ==========================================================
    # âœ… ç»Ÿä¸€æŒ‰é’®å®šä¹‰ï¼Œé˜²æ­¢ StreamlitDuplicateElementId é”™è¯¯
    # ==========================================================
    
    # ğŸ”¹ åŠŸèƒ½ï¼šä¿å­˜ JD ä¸ Rubric æ•°æ®
    # ğŸ”¹ ä¿®å¤ï¼šä¸ºæŒ‰é’®åˆ†é…å”¯ä¸€ keyï¼Œé˜²æ­¢é‡å¤ ID å†²çª
    # ğŸ”¹ æµ‹è¯•ç»“æœï¼šå·²é€šè¿‡å¤šæ¬¡ Cursor ä¸ Streamlit è¿è¡ŒéªŒè¯ï¼ˆæ— å¼‚å¸¸ï¼‰
    # ==========================================================
    
    # å°è£…æŒ‰é’®è¡Œä¸ºï¼ˆå¯å¤ç”¨ï¼‰
    def save_to_system_action():
        """ç»Ÿä¸€çš„ä¿å­˜ JD + é¢˜åº“æ“ä½œ"""
        current_bundle = st.session_state.get("ai_bundle")
        if not current_bundle:
            st.warning('è¯·å…ˆç‚¹å‡»"ç”Ÿæˆ JD"è·å¾— AI ç»“æœã€‚')
            return
        
        try:
            job_to_save = (st.session_state.get("job_name") or "").strip()
            if not job_to_save:
                job_to_save = current_bundle.get("rubric", {}).get("job", "")
    
            pipe.save_jd(job_to_save, current_bundle["jd_long"], current_bundle["jd_short"], current_bundle["rubric"])
    
            q_path = Path("data/templates/é¢˜åº“ç¤ºä¾‹.csv")
            rows = []
            for q in current_bundle.get("interview", []):
                points = q.get("points") or []
                points_str = "ï¼›".join(points) if isinstance(points, list) else (str(q.get("points", "")) if q.get("points") else "")
                rows.append({
                    "job": job_to_save,
                    "èƒ½åŠ›ç»´åº¦": q.get("dimension", "é€šç”¨"),
                    "é¢˜ç›®": q.get("question", ""),
                    "è¯„åˆ†è¦ç‚¹": points_str,
                    "åˆ†å€¼": int(q.get("score", 0)),
                    "æƒé‡": round(float(q.get("score", 0)) / 100.0, 4)
                })
            if rows:
                qdf = pd.DataFrame(rows)
                q_path.parent.mkdir(parents=True, exist_ok=True)
                header = not q_path.exists()
                qdf.to_csv(q_path, mode="a", index=False, encoding="utf-8-sig", header=header)
            st.success("å·²å†™å…¥ï¼šJD / Rubric / é¢˜åº“")
        except Exception as e:
            st.error(f"âŒ å†™å…¥å¤±è´¥ï¼š{e}")
    
    st.subheader("æ™ºèƒ½ç”Ÿæˆ JDï¼ˆAIåˆ†æï¼‰")
    
    # === æ–°å¢ï¼šæ™ºèƒ½ç”Ÿæˆ JDï¼ˆAI åˆ†æï¼‰ ===
    st.markdown("### ğŸ¤– æ™ºèƒ½ç”Ÿæˆ JDï¼ˆAI åˆ†æï¼‰")
    
    # é¢„æ£€æŸ¥ï¼šAI Key
    key_present = bool(os.getenv("SILICONFLOW_API_KEY") or os.getenv("OPENAI_API_KEY"))
    if not key_present:
        st.warning("âš ï¸ æœªæ£€æµ‹åˆ° AI Keyï¼šè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` å¹¶é…ç½® SILICONFLOW_API_KEYã€‚")
    
    with st.form("ai_jd_form"):
        ai_job = st.text_input("å²—ä½åç§° *", value=st.session_state.get("job_name",""), help="ä¾‹å¦‚ï¼šæ•°å­¦ç«èµ›æ•™ç»ƒ/æ•™å­¦è¿è¥ä¸“å‘˜/ç­ä¸»ä»»/Javaåç«¯")
        ai_must = st.text_area("å¿…å¤‡ç»éªŒ/æŠ€èƒ½", value="", height=80, help="åˆ†å·æˆ–ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚ï¼šå›½ä¸€; LaTeX; IMOè®­ç»ƒ")
        ai_nice = st.text_area("åŠ åˆ†é¡¹", value="", height=60, help="å¦‚ï¼šç«èµ›å‡ºé¢˜ç»éªŒ; å…¬å¼€è¯¾; å†…å®¹åˆ¶ä½œ")
        ai_excl = st.text_area("æ’é™¤é¡¹", value="", height=60, help="å¦‚ï¼šä»…å®ä¹ ; å…¼èŒ")
        submitted = st.form_submit_button("ğŸš€ ç”Ÿæˆ JD", type="primary", use_container_width=True)
        
        if submitted:
            if not ai_job:
                st.error("âŒ è¯·å¡«å†™å²—ä½åç§°")
            else:
                st.session_state["job_name"] = ai_job
                _update_job_meta(
                    job_name=st.session_state["job_name"],
                    must=ai_must,
                    nice=ai_nice,
                    exclude=ai_excl,
                )
                # è¾“å…¥æ¸…æ´—ï¼štex -> LaTeX
                ai_must = ai_must.replace("tex", "LaTeX").replace("Tex", "LaTeX")
                ai_nice = ai_nice.replace("tex", "LaTeX").replace("Tex", "LaTeX")
                try:
                    # å¼ºåˆ¶é‡æ–°åŠ è½½æ¨¡å—ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°ä»£ç 
                    if 'backend.services.jd_ai' in sys.modules:
                        importlib.reload(sys.modules['backend.services.jd_ai'])
                        from backend.services.jd_ai import generate_jd_bundle
                    with st.spinner("ğŸ¤– AIæ­£åœ¨æ™ºèƒ½åˆ†æå²—ä½éœ€æ±‚ï¼Œç”Ÿæˆä¸“ä¸šJDã€èƒ½åŠ›ç»´åº¦ã€é¢è¯•é¢˜ç›®ï¼Œè¯·ç¨å€™ï¼ˆé€šå¸¸éœ€è¦10-30ç§’ï¼‰..."):
                        bundle = generate_jd_bundle(ai_job, ai_must, ai_nice, ai_excl)
                        # åŸºäºé•¿ç‰ˆ JD å†åšä¸€æ¬¡â€œçŸ­ç‰ˆJDæå– + ä»»èŒè¦æ±‚æŠ½å–èƒ½åŠ›ä¸é¢è¯•é¢˜â€
                        from backend.services.jd_ai import extract_short_and_competencies_from_long_jd
                        extracted = extract_short_and_competencies_from_long_jd(bundle.get("jd_long",""), ai_job)
                        if extracted:
                            # âœ… ä¸å†ç”¨æŠ½å–å¾—åˆ°çš„çŸ­ç‰ˆ JD è¦†ç›–ï¼Œä»¥å…ç ´åâ€œå°çº¢ä¹¦é£æ ¼â€çŸ­ç‰ˆ JD
                            # å¦‚éœ€æŸ¥çœ‹æŠ½å–ç‰ˆçŸ­ JDï¼Œå¯åç»­å•ç‹¬åœ¨å‰ç«¯å±•ç¤º extracted["short_jd"]
                            # ç”¨æŠ½å–å¾—åˆ°çš„èƒ½åŠ›ç»´åº¦/é¢è¯•é¢˜è¦†ç›–å±•ç¤ºï¼ˆè½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼ï¼‰
                            dims = []
                            for d in extracted.get("èƒ½åŠ›ç»´åº¦", []):
                                anchors = d.get("è¯„åˆ†é”šç‚¹") or {}
                                dims.append({
                                    "name": d.get("ç»´åº¦åç§°", ""),
                                    "weight": round(float(d.get("æƒé‡", 0)) / 100.0, 4),
                                    "desc": d.get("å®šä¹‰", ""),
                                    "anchors": {
                                        "20": anchors.get("20") or "åŸºç¡€è¾¾æˆï¼šè¯·ç»“åˆ JD ä¸­çš„åŸºç¡€è¦æ±‚æè¿°ã€‚",
                                        "60": anchors.get("60") or "è‰¯å¥½è¾¾æˆï¼šèƒ½å¤Ÿç¨³å®šäº§å‡ºå¹¶ä¸æ–­ä¼˜åŒ–ã€‚",
                                        "100": anchors.get("100") or "ä¼˜ç§€è¾¾æˆï¼šæŒç»­è¾“å‡ºæ°å‡ºæˆæœå¹¶é‡åŒ–å½±å“ã€‚",
                                    },
                                })
                            if dims:
                                bundle["dimensions"] = dims
                            qs = []
                            for q in extracted.get("èƒ½åŠ›ç»´åº¦_é¢è¯•é¢˜", []):
                                raw_points = q.get("è¯„åˆ†è¦ç‚¹", [])
                                if isinstance(raw_points, str):
                                    points_list = [p.strip() for p in re.split(r"[ï¼›;ã€\n]", raw_points) if p.strip()]
                                else:
                                    points_list = [str(p).strip() for p in (raw_points or []) if str(p).strip()]
                                question_text = q.get("é¢è¯•é¢˜", "")
                                if isinstance(question_text, list):
                                    question_text = "ï¼›".join(str(item).strip() for item in question_text if str(item).strip())
                                qs.append({
                                    "dimension": q.get("ç»´åº¦åç§°", ""),
                                    "question": question_text,
                                    "points": points_list,
                                    "score": float(q.get("åˆ†å€¼", 0)),
                                })
                            if qs:
                                bundle["interview"] = qs
                            bundle["full_ability_list"] = construct_full_ability_list(
                                bundle.get("dimensions"), bundle.get("interview")
                            )
                    # âœ… æŒä¹…åŒ–ï¼šåç»­å…¶å®ƒæŒ‰é’®/åŒºåŸŸå¯å¤ç”¨
                    st.session_state["ai_bundle"] = bundle
                    st.success("âœ… AI ç”Ÿæˆå®Œæˆ")
                except Exception as e:
                    error_msg = str(e)
                    # æå–æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
                    if "Key" in error_msg or "æœªé…ç½®" in error_msg:
                        st.error(f"âŒ {error_msg}")
                        st.info("ğŸ’¡ è¯·æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶ï¼Œç¡®ä¿åŒ…å« SILICONFLOW_API_KEY æˆ– OPENAI_API_KEYï¼Œç„¶åé‡å¯ Streamlitã€‚")
                    elif "401" in error_msg or "403" in error_msg:
                        st.error(f"âŒ API Key éªŒè¯å¤±è´¥ï¼š{error_msg}")
                        st.info("ğŸ’¡ è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ API Key æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æ˜¯å¦å·²è¿‡æœŸã€‚")
                    elif "404" in error_msg or "æ¨¡å‹" in error_msg:
                        st.error(f"âŒ æ¨¡å‹ä¸å¯ç”¨ï¼š{error_msg}")
                        st.info("ğŸ’¡ è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ AI_MODEL æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•æ›´æ¢ä¸ºå…¶ä»–å¯ç”¨æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-32B-Instructï¼‰ã€‚")
                    else:
                        st.error(f"âŒ AI ç”Ÿæˆå¤±è´¥ï¼š{error_msg}")
                        st.info("ğŸ’¡ ç³»ç»Ÿå°†ç»§ç»­æ”¯æŒ'ç¦»çº¿è§„åˆ™ç‰ˆ'ç”Ÿæˆï¼Œç¡®ä¿å¯ç”¨ã€‚å±•å¼€ä¸‹æ–¹çš„'AI è¿æ¥è¯Šæ–­'æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")
    
    # æ˜¾ç¤ºAIç”Ÿæˆç»“æœ
    bundle = st.session_state.get("ai_bundle")
    if SHOW_DETAIL_SECTIONS:
        if bundle:
            st.subheader("ğŸ“„ é•¿ç‰ˆ JDï¼ˆBossç›´è˜å¯ç”¨ï¼‰")
            st.text_area("é•¿ç‰ˆ JD", bundle["jd_long"], height=260)
        
            st.subheader("ğŸª§ çŸ­ç‰ˆ JDï¼ˆç¤¾åª’/å†…æ¨ï¼‰")
            st.text_area("çŸ­ç‰ˆ JD", bundle["jd_short"], height=100)
        
            st.markdown("### å²—ä½èƒ½åŠ›ç»´åº¦ä¸é¢è¯•é¢˜ç›®ï¼ˆAIåˆ†æ + AIç”Ÿæˆï¼‰")
            full_ability = bundle.get("full_ability_list") or construct_full_ability_list(
                bundle.get("dimensions"), bundle.get("interview")
            )
            bundle["full_ability_list"] = full_ability

            display_rows = []
            for item in full_ability:
                display_rows.append({
                    "èƒ½åŠ›ç»´åº¦": item.get("dimension", ""),
                    "è¯´æ˜": item.get("description", ""),
                    "æƒé‡(%)": round(float(item.get("weight", 0.0)) * 100, 1),
                    "é¢è¯•é¢˜ç›®": item.get("question", ""),
                    "è¯„åˆ†è¦ç‚¹": item.get("score_points", ""),
                    "20åˆ†è¡Œä¸ºè¡¨ç°": item.get("score_20", ""),
                    "60åˆ†è¡Œä¸ºè¡¨ç°": item.get("score_60", ""),
                    "100åˆ†è¡Œä¸ºè¡¨ç°": item.get("score_100", ""),
                    "åˆ†å€¼": item.get("score_value", 0.0),
                })

            df_full = pd.DataFrame(display_rows)
            st.dataframe(df_full, use_container_width=True)

            # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ Excelï¼ˆæ–°ç‰ˆæœ¬ï¼Œå®Œå…¨åŸºäºæ¨¡æ¿ï¼‰
            job_name = (st.session_state.get('job_name') or 'å²—ä½').strip()
            try:
                # è½¬æ¢æ•°æ®æ ¼å¼ä¸º DataFrame
                dimensions_data = []
                for ability in full_ability:
                    dimensions_data.append({
                        "èƒ½åŠ›ç»´åº¦": ability.get("dimension", ""),
                        "è¯´æ˜": ability.get("description", ""),
                        "é¢è¯•é¢˜ç›®": ability.get("question", ""),
                        "è¯„åˆ†è¦ç‚¹": ability.get("score_points", ""),
                        "20åˆ†è¡Œä¸ºè¡¨ç°": ability.get("score_20", ""),
                        "60åˆ†è¡Œä¸ºè¡¨ç°": ability.get("score_60", ""),
                        "100åˆ†è¡Œä¸ºè¡¨ç°": ability.get("score_100", ""),
                        "æƒé‡": ability.get("weight", 0.0),
                    })
                
                # åˆ›å»º DataFrameï¼ˆå»æ‰æ§åˆ¶å°è°ƒè¯•è¾“å‡ºï¼Œé¿å… Windows æ§åˆ¶å°ç¼–ç å¯¼è‡´ OSErrorï¼‰
                data_df = pd.DataFrame(dimensions_data)
                
                # å›ºå®šè¾“å‡ºè·¯å¾„
                output_path = r"C:\RecruitFlow_Pro_MVP\docs\è¯¾ç¨‹é¡¾é—®_èƒ½åŠ›ç»´åº¦è¯„åˆ†è¡¨(æ”¹)_è¾“å‡º.xlsx"
                
                def _coerce_excel_result(result, fallback_path):
                    if isinstance(result, tuple):
                        return result
                    if isinstance(result, bytes):
                        return result, fallback_path
                    read_path = result if isinstance(result, str) else fallback_path
                    with open(read_path, "rb") as f:
                        return f.read(), read_path
                
                # ä½¿ç”¨æ–°çš„å¯¼å‡ºå‡½æ•°ï¼ˆå®Œå…¨åŸºäºæ¨¡æ¿ï¼‰
                try:
                    export_result = export_competency_excel(
                        data_df, output_path, job_title=job_name
                    )
                except TypeError:
                    print("[streamlit] export_competency_excel fallback to legacy signature")
                    export_result = export_competency_excel(data_df, output_path)

                excel_bytes, saved_path = _coerce_excel_result(export_result, output_path)

                if saved_path and saved_path != output_path:
                    st.warning(f"åŸå§‹è¾“å‡ºæ–‡ä»¶è¢«å ç”¨ï¼Œå·²æ”¹ä¸ºä¿å­˜åˆ°ï¼š`{saved_path}`")
                
                download_name = f"{job_name}_èƒ½åŠ›ç»´åº¦è¯„åˆ†è¡¨.xlsx"
                st.download_button(
                    "ğŸ“„ å¯¼å‡ºèƒ½åŠ›ç»´åº¦è¯„åˆ†è¡¨ï¼ˆExcelï¼‰",
                    data=excel_bytes,
                    file_name=download_name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )
            except Exception as e:
                st.error(f"å¯¼å‡ºå¤±è´¥ï¼š{str(e)}")
                st.exception(e)
 
            # ä¿ç•™å•ä¸€ä¿å­˜å…¥å£
            if st.button("ğŸ’¾ å†™å…¥ç³»ç»Ÿï¼ˆä¿å­˜ JD + é¢˜åº“ï¼‰", type="primary", key="btn_save_rubric_1"):
                save_to_system_action()
        else:
            st.info('å°šæœªç”Ÿæˆ Rubricï¼ˆè¯·å…ˆç‚¹å‡»ä¸Šæ–¹"ç”Ÿæˆ JD"ï¼‰')
        
        # âœ… éšè—è¯„åˆ†ç»´åº¦è§„åˆ™ï¼ˆRubricï¼‰éƒ¨åˆ†ï¼Œåªä¿ç•™åŠŸèƒ½é€»è¾‘
        # è¿™é‡Œä¿ç•™ bundle_for_rubric çš„ç”Ÿæˆå’Œä¿å­˜é€»è¾‘ï¼Œä½†ä¸æ¸²æŸ“åˆ°é¡µé¢
        bundle_for_rubric = st.session_state.get("ai_bundle")
        # bundle_for_rubric å˜é‡ä¿ç•™ï¼Œä¾›å†…éƒ¨é€»è¾‘ä½¿ç”¨ï¼ˆå¦‚ save_to_system_action å‡½æ•°ä¸­ä¼šç”¨åˆ°ï¼‰
        
        # ä¸å†æ˜¾ç¤ºæ ‡é¢˜å’Œå±•å¼€å—ï¼Œé¿å… UI é‡å¤
        # st.subheader("è¯„åˆ†ç»´åº¦è§„åˆ™ï¼ˆRubricï¼‰")  # âŒ æ³¨é‡Šæ‰
        # with st.expander("è¯„åˆ†ç»´åº¦è§„åˆ™ï¼ˆRubricï¼‰", expanded=False):
        #     st.json(bundle_for_rubric["rubric"])
        
        # âœ… ä»…ä¿ç•™ä¸€æ¬¡ä¿å­˜æŒ‰é’®ï¼ˆä¸Šæ–¹å·²æœ‰çš„æŒ‰é’® btn_save_rubric_1ï¼‰
        # å› æ­¤è¿™é‡Œåˆ é™¤é‡å¤æŒ‰é’®ï¼Œé˜²æ­¢é‡å¤æ˜¾ç¤º
        # if st.button("ğŸ’¾ å†™å…¥ç³»ç»Ÿï¼ˆä¿å­˜ JD + é¢˜åº“ï¼‰", type="primary", key="btn_save_rubric_2"):
        #     save_to_system_action()
    
    # ==== AI è¿æ¥è¯Šæ–­ï¼ˆæ”¾åœ¨é¡µé¢åº•éƒ¨ï¼‰====
    with st.expander("ğŸ”§ AI è¿æ¥è¯Šæ–­ï¼ˆæ‰“ä¸å¼€å°±ç‚¹æˆ‘ï¼‰"):
        try:
            # å¼ºåˆ¶é‡æ–°åŠ è½½æ¨¡å—ï¼Œé¿å…ç¼“å­˜é—®é¢˜
            import importlib
            import sys
            if 'backend.services.ai_client' in sys.modules:
                importlib.reload(sys.modules['backend.services.ai_client'])
            from backend.services.ai_client import get_client_and_cfg, AIConfig, chat_completion
        except ImportError as e:
            st.error(f"âŒ å¯¼å…¥ AI å®¢æˆ·ç«¯å¤±è´¥ï¼š{e}")
            st.info("ğŸ’¡ è¯·æ£€æŸ¥ backend/services/ai_client.py æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯æ­£å¸¸å¯¼å…¥")
            st.stop()
        
        cfg = AIConfig()
        key_present = bool(cfg.api_key)
        st.write("**å·²æ£€æµ‹åˆ° Keyï¼š**", "âœ…" if key_present else "âŒ")
        if key_present:
            st.write("**Key å‰ç¼€ï¼š**", cfg.api_key[:10] + "..." if len(cfg.api_key) > 10 else cfg.api_key)
        st.write("**Base URLï¼š**", cfg.base_url)
        st.write("**å½“å‰æ¨¡å‹ï¼š**", cfg.model)
        st.write("**Temperatureï¼š**", cfg.temperature)
        
        if st.button("ğŸ§ª æµ‹è¯•ä¸€æ¬¡ AI è¿é€šæ€§"):
            try:
                client, cfg = get_client_and_cfg()
                with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                    res = chat_completion(
                        client,
                        cfg,
                        messages=[{"role":"user","content":"åªè¿”å› OK"}],
                        temperature=0,
                        max_tokens=10
                    )
                    result = res["choices"][0]["message"]["content"].strip()
                    st.success(f"âœ… AI è¿é€šæ€§æµ‹è¯•æˆåŠŸï¼è¿”å›ï¼š{result}")
            except Exception as e:
                error_detail = str(e)
                st.error(f"âŒ è¿é€šæ€§å¤±è´¥ï¼š{error_detail}")
                if "ChatCompletion" in error_detail or "openai>=1.0.0" in error_detail:
                    st.error("âš ï¸ OpenAI API ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜")
                    st.info("ğŸ’¡ è¿™é€šå¸¸æ˜¯å› ä¸ºä»£ç ä¸­ä½¿ç”¨äº†æ—§ç‰ˆæœ¬çš„ OpenAI APIã€‚è¯·ç¡®ä¿ï¼š\n"
                           "1. å·²å®‰è£… openai>=1.0.0ï¼š`pip install --upgrade openai`\n"
                           "2. ä»£ç ä½¿ç”¨ `client.chat.completions.create` è€Œä¸æ˜¯ `openai.ChatCompletion.create`\n"
                           "3. é‡å¯ Streamlit åº”ç”¨ä»¥æ¸…é™¤ç¼“å­˜")
                    st.code("pip install --upgrade openai", language="bash")
                elif "Key" in error_detail or "æœªé…ç½®" in error_detail:
                    st.info("ğŸ’¡ æ£€æŸ¥ .env çš„ Key é…ç½®ï¼›ç¡®ä¿æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼›é‡å¯ Streamlit")
                elif "401" in error_detail or "403" in error_detail:
                    st.info("ğŸ’¡ API Key æ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·æ£€æŸ¥ .env ä¸­çš„ Key æ˜¯å¦æ­£ç¡®")
                elif "404" in error_detail:
                    st.info("ğŸ’¡ æ¨¡å‹ä¸å­˜åœ¨æˆ–æœªå¼€é€šï¼Œè¯·æ£€æŸ¥ .env ä¸­çš„ AI_MODELï¼Œå°è¯•æ›´æ¢ä¸º Qwen2.5-32B-Instruct")
                elif "timeout" in error_detail.lower() or "è¿æ¥" in error_detail:
                    st.info("ğŸ’¡ ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ£€æŸ¥å…¬å¸ç½‘ç»œæ˜¯å¦æ”¾è¡Œ api.siliconflow.cnï¼›æˆ–å°è¯•ä½¿ç”¨ OpenAI")
                else:
                    st.info("ğŸ’¡ æ£€æŸ¥ .env çš„ Key/æ¨¡å‹/Base URLï¼›æˆ–å…¬å¸ç½‘ç»œæ˜¯å¦æ”¾è¡Œ api.siliconflow.cn")
    
    # ä¸€é”®å¯åŠ¨è¯´æ˜
    with st.expander("ğŸš€ ä¸€é”®å¯åŠ¨ç¨‹åºï¼ˆé¦–æ¬¡ä½¿ç”¨å¿…çœ‹ï¼‰", expanded=False):
        st.markdown("""
        ### å¿«é€Ÿå¯åŠ¨æ–¹æ³•
        
        1. **æœ€ç®€å•æ–¹å¼**ï¼šåŒå‡»é¡¹ç›®æ ¹ç›®å½•çš„ `å¯åŠ¨ç¨‹åº.bat` æ–‡ä»¶
        2. **PowerShell æ–¹å¼**ï¼šå³é”® `å¯åŠ¨ç¨‹åº.ps1` -> ä½¿ç”¨ PowerShell è¿è¡Œ
        3. **å‘½ä»¤è¡Œæ–¹å¼**ï¼šè¿è¡Œ `å¯åŠ¨ç¨‹åº.bat` æˆ– `.\\å¯åŠ¨ç¨‹åº.ps1`
        
        ### é¦–æ¬¡ä½¿ç”¨å‰å‡†å¤‡
        
        - âœ… ç¡®ä¿å·²å®‰è£… Python 3.8+
        - âœ… å·²åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š`python -m venv .venv`
        - âœ… å·²å®‰è£…ä¾èµ–ï¼š`.venv\\Scripts\\pip install -r requirements.txt`
        - âœ… å·²é…ç½® `.env` æ–‡ä»¶ï¼ˆAI Key ç­‰ï¼Œå¯é€‰ï¼‰
        
        ### è¯¦ç»†ä½¿ç”¨è¯´æ˜
        
        è¯·æŸ¥çœ‹é¡¹ç›®æ ¹ç›®å½•çš„ `ä½¿ç”¨è¯´æ˜.md` æ–‡ä»¶ï¼ŒåŒ…å«ï¼š
        - ğŸ“‹ å®Œæ•´åŠŸèƒ½è¯´æ˜
        - ğŸ”§ å¸¸è§é—®é¢˜è§£ç­”
        - ğŸ¯ å„åŠŸèƒ½æ¨¡å—ä½¿ç”¨æŒ‡å—
        
        ### å½“å‰è¿è¡ŒçŠ¶æ€
        
        - ğŸŒ è®¿é—®åœ°å€ï¼šhttp://localhost:8501
        - ğŸ“ é¡¹ç›®ç›®å½•ï¼š""" + str(Path.cwd()) + """
        """)
        
        # æ˜¾ç¤ºå¯åŠ¨è„šæœ¬è·¯å¾„
        bat_path = Path.cwd() / "å¯åŠ¨ç¨‹åº.bat"
        ps1_path = Path.cwd() / "å¯åŠ¨ç¨‹åº.ps1"
        
        if bat_path.exists():
            st.success(f"âœ… å¯åŠ¨è„šæœ¬å·²æ‰¾åˆ°ï¼š`{bat_path}`")
        else:
            st.warning(f"âš ï¸ å¯åŠ¨è„šæœ¬ä¸å­˜åœ¨ï¼š`{bat_path}`")
        
        if ps1_path.exists():
            st.success(f"âœ… PowerShell è„šæœ¬å·²æ‰¾åˆ°ï¼š`{ps1_path}`")
        
        # æä¾›å¿«é€Ÿå‘½ä»¤
        cmd_text = f"""# å¿«é€Ÿå¯åŠ¨å‘½ä»¤ï¼ˆå¤åˆ¶åˆ°å‘½ä»¤è¡Œè¿è¡Œï¼‰
cd "{Path.cwd()}"
.venv\\Scripts\\python.exe -m streamlit run app/streamlit_app.py --server.port 8501"""
        st.code(cmd_text, language="bash")
    
    st.markdown("---")
    if SHOW_OFFLINE_SECTION:
        st.markdown("---")
        st.markdown("### ğŸ“‹ ç¦»çº¿è§„åˆ™ç‰ˆï¼ˆå¤‡ç”¨ï¼‰")
        
        # é‡æ–°è¯»å–é…ç½®ï¼ˆå› ä¸ºå¯èƒ½åœ¨ä¾§è¾¹æ å·²æ›´æ–°ï¼‰
        cfg = json.loads(cfg_file.read_text(encoding="utf-8"))
        use_ai = cfg.get("llm_provider") in ["openai", "claude", "siliconflow"]
        
        # è¾“å…¥è¡¨å•ï¼ˆç¦»çº¿ç‰ˆï¼‰
        with st.form("jd_generation_form"):
            col1, col2 = st.columns(2)
            with col1:
                job_name = st.text_input("å²—ä½åç§° *", placeholder="ä¾‹å¦‚ï¼šæ•°æ®åˆ†æå¸ˆã€äº§å“ç»ç†ã€è¿è¥ä¸“å‘˜ç­‰", 
                                        value=st.session_state.get("job_name", ""))
            with col2:
                st.caption("ğŸ’¡ å¿…å¡«é¡¹")
            
            must_have = st.text_area("å¿…å¤‡ç»éªŒ/æŠ€èƒ½", placeholder="ä¾‹å¦‚ï¼š3å¹´ä»¥ä¸Šæ•°æ®åˆ†æç»éªŒï¼›ç†Ÿæ‚‰Pythonã€SQLï¼›æœ‰æ•™è‚²è¡Œä¸šèƒŒæ™¯", 
                                    height=80, help="ç”¨åˆ†å·(;)åˆ†éš”å¤šä¸ªæŠ€èƒ½")
            nice_to_have = st.text_area("åŠ åˆ†é¡¹", placeholder="ä¾‹å¦‚ï¼šç†Ÿæ‚‰æœºå™¨å­¦ä¹ ï¼›æœ‰å›¢é˜Ÿç®¡ç†ç»éªŒï¼›æ•°æ®å¯è§†åŒ–èƒ½åŠ›å¼º", 
                                       height=80, help="ç”¨åˆ†å·(;)åˆ†éš”å¤šä¸ªåŠ åˆ†é¡¹")
            exclude_keywords = st.text_area("æ’é™¤é¡¹", placeholder="ä¾‹å¦‚ï¼šé¢‘ç¹è·³æ§½ï¼›ä»…å®ä¹ ç»éªŒï¼›å¤–åŒ…ç»å†", 
                                           height=60, help="ç”¨åˆ†å·(;)åˆ†éš”å¤šä¸ªæ’é™¤å…³é”®è¯")
            
            submitted = st.form_submit_button("ğŸš€ ç”Ÿæˆ JD", type="primary", use_container_width=True)
        
        # å¤„ç†ç”Ÿæˆè¯·æ±‚
        if submitted:
            if not job_name:
                st.error("âŒ è¯·å¡«å†™å²—ä½åç§°")
            else:
                st.session_state["job_name"] = job_name
                _update_job_meta(
                    job_name=job_name,
                    must=must_have,
                    nice=nice_to_have,
                    exclude=exclude_keywords,
                )
                with st.spinner("ğŸ¤– AIæ­£åœ¨æ™ºèƒ½åˆ†æå²—ä½éœ€æ±‚ï¼Œç”Ÿæˆä¸“ä¸šJDã€èƒ½åŠ›ç»´åº¦ã€é¢è¯•é¢˜ç›®ï¼Œè¯·ç¨å€™ï¼ˆé€šå¸¸éœ€è¦10-30ç§’ï¼‰..."):
                    try:
                        jd_long, jd_short, rubric, interview_questions = pipe.generate_jd(
                            job_name, must_have=must_have, nice_to_have=nice_to_have, 
                            exclude_keywords=exclude_keywords, use_ai=use_ai
                        )
                        st.session_state["jd_result"] = (jd_long, jd_short, rubric, interview_questions)
                        st.success("âœ… AIç”ŸæˆæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
                        if use_ai:
                            st.info("æ­£åœ¨å°è¯•ä½¿ç”¨ç¦»çº¿æ¨¡å¼...")
                            try:
                                jd_long, jd_short, rubric, interview_questions = pipe.generate_jd(
                                    job_name, must_have=must_have, nice_to_have=nice_to_have, 
                                    exclude_keywords=exclude_keywords, use_ai=False
                                )
                                st.session_state["jd_result"] = (jd_long, jd_short, rubric, interview_questions)
                                st.success("âœ… ç¦»çº¿æ¨¡å¼ç”ŸæˆæˆåŠŸ")
                            except Exception as e2:
                                st.error(f"âŒ ç¦»çº¿æ¨¡å¼ä¹Ÿå¤±è´¥: {str(e2)}")
        
        # æ˜¾ç¤ºç»“æœ
        if "jd_result" in st.session_state:
            jd_long, jd_short, rubric, interview_questions = st.session_state["jd_result"]
            
            # é•¿ç‰ˆJD
            st.markdown("### ğŸ“„ é•¿ç‰ˆ JDï¼ˆBossç›´è˜å¯ç”¨ï¼‰")
            st.text_area("", jd_long, height=300, key="jd_long_display", label_visibility="collapsed")
            
            # çŸ­ç‰ˆJD
            st.markdown("### âœ¨ çŸ­ç‰ˆ JDï¼ˆç¤¾åª’/å†…æ¨ï¼‰")
            st.text_area("", jd_short, height=100, key="jd_short_display", label_visibility="collapsed")
            
            # èƒ½åŠ›ç»´åº¦
            st.markdown("### ğŸ¯ å²—ä½èƒ½åŠ›ç»´åº¦ï¼ˆAIåˆ†æï¼‰")
            if rubric.get("dimensions"):
                dim_data = []
                for dim in rubric["dimensions"]:
                    weight = float(dim.get("weight", 0))
                    dim_data.append({
                        "èƒ½åŠ›ç»´åº¦": dim.get("name", ""),
                        "æƒé‡": f"{weight * 100:.1f}%",
                        "è¯´æ˜": dim.get("description", "")
                    })
                dim_df = pd.DataFrame(dim_data)
                st.dataframe(dim_df, use_container_width=True)
            else:
                st.info('å°šæœªç”Ÿæˆ Rubricï¼ˆè¯·å…ˆç‚¹å‡»ä¸Šæ–¹"ç”Ÿæˆ JD"ï¼‰')
            
            # é¢è¯•é¢˜ç›®
            st.markdown("### ğŸ’¬ é¢è¯•é¢˜ç›®å’Œè¯„åˆ†æ ‡å‡†ï¼ˆAIç”Ÿæˆï¼‰")
            if interview_questions and interview_questions.get("questions"):
                for idx, q in enumerate(interview_questions["questions"], 1):
                    weight_pct = float(q.get('weight', 0)) * 100
                    with st.expander(f"é¢˜ç›® {idx}: {q.get('dimension', 'é€šç”¨')} - æƒé‡: {weight_pct:.0f}%"):
                        st.markdown(f"**é—®é¢˜ï¼š** {q.get('question', '')}")
                        st.markdown(f"**è¯„åˆ†æ ‡å‡†ï¼š** {q.get('evaluation_criteria', '')}")
                        if q.get('weight'):
                            st.caption(f"æƒé‡: {float(q.get('weight', 0)) * 100:.0f}%")
            else:
                st.info("æš‚æ— é¢è¯•é¢˜ç›®")
            
            # ä¿å­˜æŒ‰é’®
            col1, col2 = st.columns([1, 4])
            with col1:
                if st.button("ğŸ’¾ ä¿å­˜ JD & è¯„åˆ†ç»´åº¦", type="primary", key="btn_save_jd_score"):
                    pipe.save_jd(job_name, jd_long, jd_short, rubric, interview_questions)
                    st.success("âœ… å·²ä¿å­˜")

with tab2:
    st.subheader("å¯¼å…¥ç®€å†ï¼ˆCSV/TXT ç¤ºä¾‹ï¼‰å¹¶åŒ¹é…æ‰“åˆ†")
    uploaded = st.file_uploader("ä¸Šä¼ ç®€å† CSVï¼ˆè§ data/samples/sample_resumes.csvï¼‰æˆ– TXTï¼ˆå•ä¸ªï¼‰", type=["csv","txt"], accept_multiple_files=True)
    if uploaded:
        for f in uploaded:
            if f.name.endswith(".csv"):
                df = pd.read_csv(f); pipe.ingest_resumes_df(df)
            else:
                txt = f.read().decode("utf-8", errors="ignore"); pipe.ingest_text_resume(txt)
        st.success("å·²å¯¼å…¥")
    if st.button("æ‰¹é‡è¯„åˆ†"):
        start = time.time()
        result_df = pipe.score_all(st.session_state.get("job_name"))
        if st.session_state.get("job_name"):
            _update_job_meta(job_name=st.session_state.get("job_name"))
        st.session_state["scored"] = result_df
        st.info(f"è¯„åˆ†å®Œæˆï¼Œç”¨æ—¶ {time.time()-start:.2f} s")
        # æ±‰åŒ–æ˜¾ç¤º
        result_df_display = translate_dataframe_columns(result_df)
        st.dataframe(result_df_display, use_container_width=True)

    st.markdown("---")
    st.markdown("## ğŸ¤– AI æ™ºèƒ½åŒ¹é…ï¼ˆæ‰¹é‡ä¸Šä¼  PDF/DOCX/å›¾ç‰‡ï¼‰")

    jd_text = ""
    if st.session_state.get("ai_bundle") and st.session_state["ai_bundle"].get("jd_long"):
        jd_text = st.session_state["ai_bundle"]["jd_long"]

    jd_text = st.text_area(
        "å²—ä½ JD æ–‡æœ¬ï¼ˆå·²è‡ªåŠ¨å¸¦å…¥ AI é•¿ç‰ˆ JDï¼Œå¯æ‰‹åŠ¨ç¼–è¾‘ï¼‰",
        value=jd_text,
        height=200,
        help="AI ä¼šåŸºäºè¿™é‡Œçš„ JD ä¸ç®€å†è¿›è¡ŒåŒ¹é…ï¼Œè¯·ç¡®ä¿å†…å®¹å‡†ç¡®ã€‚"
    )

    uploaded_files = st.file_uploader(
        "ä¸Šä¼ å¤šä»½ç®€å†ï¼ˆæ”¯æŒï¼špdfã€docxã€txtã€jpgã€jpegã€pngï¼‰",
        type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
        accept_multiple_files=True,
        key="ai_resume_uploader"
    )

    if uploaded_files:
        with st.spinner("æ­£åœ¨è§£æç®€å†æ–‡ä»¶â€¦"):
            resumes_df = parse_uploaded_files_to_df(uploaded_files)
        if resumes_df.empty:
            st.warning("æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆç®€å†ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
        else:
            st.success(f"å·²è§£æ {len(resumes_df)} ä»½ç®€å†ã€‚")
            base_columns = ["candidate_id", "name", "file", "email", "phone", "text_len"]
            for col in base_columns:
                if col not in resumes_df.columns:
                    if col == "candidate_id":
                        resumes_df[col] = range(1, len(resumes_df) + 1)
                    elif col == "text_len":
                        resumes_df[col] = resumes_df.get("resume_text", "").apply(lambda x: len(str(x)) if x else 0)
                    else:
                        resumes_df[col] = ""
            # ä½¿ç”¨å­—æ®µæ˜ å°„ç¿»è¯‘åˆ—å
            display_resumes_df = resumes_df[base_columns].copy()
            display_resumes_df = translate_dataframe_columns(display_resumes_df)
            st.dataframe(
                display_resumes_df,
                use_container_width=True
            )

            if st.button("ğŸš€ ç”¨ AI æ‰¹é‡åŒ¹é…å¹¶æ‰“åˆ†"):
                if not jd_text.strip():
                    st.warning("è¯·å…ˆå¡«å†™/ç²˜è´´å²—ä½ JDã€‚")
                else:
                    # è·å–å²—ä½åç§°ï¼Œç”¨äºå²—ä½çº§æ¸…æ´—é€»è¾‘
                    job_title = st.session_state.get("job_name", "")
                    if job_title:
                        _update_job_meta(job_name=job_title)
                    # æ·»åŠ æ—¥å¿—æŸ¥çœ‹å™¨ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    with st.expander("ğŸ” è°ƒè¯•æ—¥å¿—ï¼ˆç‚¹å‡»æŸ¥çœ‹åç«¯æ—¥å¿—ï¼‰", expanded=False):
                        st.info("ğŸ’¡ Pythonçš„print()è¾“å‡ºåœ¨è¿è¡ŒStreamlitçš„ç»ˆç«¯/æ§åˆ¶å°ä¸­ï¼Œä¸åœ¨æµè§ˆå™¨æ§åˆ¶å°ã€‚")
                        st.info("ğŸ’¡ è¯·æŸ¥çœ‹å¯åŠ¨Streamlitçš„ç»ˆç«¯çª—å£ï¼Œåº”è¯¥èƒ½çœ‹åˆ° [DEBUG] å¼€å¤´çš„æ—¥å¿—ã€‚")
                        st.code("""
ç¤ºä¾‹æ—¥å¿—æ ¼å¼ï¼š
[DEBUG] ai_match_resumes_df_ultra: å¼€å§‹æ‰¹é‡åŒ¹é…ï¼Œå…±2ä»½ç®€å†
[DEBUG] ç®€å†1/2: å¼€å§‹è¯„åˆ†ï¼Œæ–‡æœ¬é•¿åº¦=XXX
[DEBUG] Ultraå¼•æ“.score() å¼€å§‹: resume_length=XXX
[DEBUG] S2: å¼€å§‹åŠ¨ä½œè¯†åˆ«...
[DEBUG] S9: æ„å»ºè¯æ®é“¾å®Œæˆï¼Œevidence_chainæ•°é‡=X
[DEBUG] ç®€å†1/2: è¯„åˆ†å®Œæˆï¼Œai_review=True, highlight_tags=X
                        """, language="text")
                    
                    with st.spinner("AI æ­£åœ¨æ™ºèƒ½åˆ†æåŒ¹é…åº¦ï¼ˆUltraå¼•æ“ï¼‰ï¼Œè¯·ç¨å€™â€¦"):
                        # ä¼˜å…ˆä½¿ç”¨Ultraç‰ˆè¯„åˆ†å¼•æ“
                        scored_df = None
                        try:
                            scored_df = ai_match_resumes_df_ultra(jd_text, resumes_df, job_title)
                        except Exception as e:
                            import traceback
                            error_trace = traceback.format_exc()
                            st.error(f"âŒ Ultraå¼•æ“å¼‚å¸¸: {str(e)}")
                            with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                                st.code(error_trace, language="python")
                            st.warning(f"Ultraå¼•æ“å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†ç‰ˆæœ¬: {str(e)[:100]}")
                        
                        # åªæœ‰åœ¨Ultraå¼•æ“å¤±è´¥æ—¶æ‰ä½¿ç”¨æ ‡å‡†ç‰ˆæœ¬
                        if scored_df is None or scored_df.empty:
                            scored_df = ai_match_resumes_df(jd_text, resumes_df, job_title)
                    # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨ï¼ˆä¼˜å…ˆä½¿ç”¨Ultraå­—æ®µï¼Œå…¼å®¹æ—§å­—æ®µï¼‰
                    score_columns = [
                        "candidate_id",
                        "name",
                        "file",
                        "email",
                        "phone",
                        "æ€»åˆ†",
                        "æŠ€èƒ½åŒ¹é…åº¦",
                        "ç»éªŒç›¸å…³æ€§",
                        "æˆé•¿æ½œåŠ›",
                        "ç¨³å®šæ€§",
                        "score_explain",
                        "short_eval",
                        "highlights",
                        "resume_mini",
                        "è¯æ®",
                    ]
                    for col in score_columns:
                        if col not in scored_df.columns:
                            if col == "candidate_id":
                                scored_df[col] = range(1, len(scored_df) + 1)
                            else:
                                scored_df[col] = ""
                    
                    # ç¡®ä¿Ultraå­—æ®µæ˜ å°„åˆ°å…¼å®¹å­—æ®µï¼ˆç”¨äºåˆ—è¡¨é¡µæ˜¾ç¤ºï¼‰
                    # å¦‚æœå…¼å®¹å­—æ®µä¸ºç©ºï¼Œä»Ultraå­—æ®µå¡«å……
                    if "short_eval" in scored_df.columns:
                        mask = scored_df["short_eval"].isna() | (scored_df["short_eval"] == "")
                        # æ£€æŸ¥ ai_review åˆ—æ˜¯å¦å­˜åœ¨
                        if "ai_review" in scored_df.columns:
                            scored_df.loc[mask, "short_eval"] = scored_df.loc[mask, "ai_review"].fillna("")
                        elif "ai_evaluation" in scored_df.columns:
                            scored_df.loc[mask, "short_eval"] = scored_df.loc[mask, "ai_evaluation"].fillna("")
                    
                    if "highlights" in scored_df.columns:
                        mask = scored_df["highlights"].isna() | (scored_df["highlights"] == "")
                        # ä»highlight_tagsåˆ—è¡¨è½¬ä¸ºå­—ç¬¦ä¸²
                        def format_highlights(row):
                            highlight_tags = row.get("highlight_tags")
                            # å®‰å…¨æ£€æŸ¥ï¼šå¤„ç†å„ç§æ•°æ®ç±»å‹ï¼ˆé¿å…ç©ºæ•°ç»„çš„æ­§ä¹‰ï¼‰
                            try:
                                # å¦‚æœæ˜¯åˆ—è¡¨ä¸”ä¸ä¸ºç©º
                                if isinstance(highlight_tags, list) and len(highlight_tags) > 0:
                                    tags = [str(tag) for tag in highlight_tags if tag]
                                    if tags:
                                        return " | ".join(tags)
                                # å¦‚æœæ˜¯numpyæ•°ç»„æˆ–å…¶ä»–å¯è¿­ä»£å¯¹è±¡
                                elif highlight_tags is not None and hasattr(highlight_tags, '__iter__') and not isinstance(highlight_tags, str):
                                    try:
                                        # å°è¯•è½¬æ¢ä¸ºåˆ—è¡¨
                                        tags_list = list(highlight_tags)
                                        if len(tags_list) > 0:
                                            tags = [str(tag) for tag in tags_list if tag]
                                            if tags:
                                                return " | ".join(tags)
                                    except (TypeError, ValueError):
                                        pass
                                # å¦‚æœæ˜¯å­—ç¬¦ä¸²
                                elif isinstance(highlight_tags, str) and highlight_tags.strip():
                                    return highlight_tags
                            except Exception:
                                pass
                            
                            # å›é€€åˆ°highlightså­—æ®µ
                            highlights_val = row.get("highlights", "")
                            if isinstance(highlights_val, str) and highlights_val.strip():
                                return highlights_val
                            elif isinstance(highlights_val, list) and len(highlights_val) > 0:
                                tags = [str(tag) for tag in highlights_val if tag]
                                return " | ".join(tags) if tags else ""
                            return ""
                        scored_df.loc[mask, "highlights"] = scored_df.loc[mask].apply(format_highlights, axis=1)
                    
                    if "resume_mini" in scored_df.columns:
                        mask = scored_df["resume_mini"].isna() | (scored_df["resume_mini"] == "")
                        # æ£€æŸ¥ ai_resume_summary åˆ—æ˜¯å¦å­˜åœ¨
                        if "ai_resume_summary" in scored_df.columns:
                            scored_df.loc[mask, "resume_mini"] = scored_df.loc[mask, "ai_resume_summary"].fillna("")
                        elif "summary_short" in scored_df.columns:
                            scored_df.loc[mask, "resume_mini"] = scored_df.loc[mask, "summary_short"].fillna("")
                    
                    if "è¯æ®" in scored_df.columns:
                        mask = scored_df["è¯æ®"].isna() | (scored_df["è¯æ®"] == "")
                        # æ£€æŸ¥ evidence_text åˆ—æ˜¯å¦å­˜åœ¨
                        if "evidence_text" in scored_df.columns:
                            scored_df.loc[mask, "è¯æ®"] = scored_df.loc[mask, "evidence_text"].fillna("")
                    
                    result_df = scored_df
                    
                    # è°ƒè¯•ï¼šæ£€æŸ¥æ¨ç†é“¾å­—æ®µæ˜¯å¦åœ¨DataFrameä¸­
                    if not result_df.empty:
                        sample_row = result_df.iloc[0]
                        print(f"[DEBUG] å‰ç«¯DataFrameæ£€æŸ¥: åˆ—æ•°={len(result_df.columns)}, è¡Œæ•°={len(result_df)}", flush=True)
                        print(f"[DEBUG] å‰ç«¯DataFrameåˆ—å: {list(result_df.columns)[:20]}...", flush=True)
                        if "strengths_reasoning_chain" in result_df.columns:
                            sample_strengths = sample_row.get("strengths_reasoning_chain", {})
                            print(f"[DEBUG] å‰ç«¯DataFrameä¸­strengths_reasoning_chainå­˜åœ¨: type={type(sample_strengths)}, value={sample_strengths if isinstance(sample_strengths, dict) else 'N/A'}", flush=True)
                        else:
                            print(f"[DEBUG] å‰ç«¯DataFrameä¸­strengths_reasoning_chainä¸å­˜åœ¨ï¼", flush=True)
                        if "weaknesses_reasoning_chain" in result_df.columns:
                            sample_weaknesses = sample_row.get("weaknesses_reasoning_chain", {})
                            print(f"[DEBUG] å‰ç«¯DataFrameä¸­weaknesses_reasoning_chainå­˜åœ¨: type={type(sample_weaknesses)}, value={sample_weaknesses if isinstance(sample_weaknesses, dict) else 'N/A'}", flush=True)
                        else:
                            print(f"[DEBUG] å‰ç«¯DataFrameä¸­weaknesses_reasoning_chainä¸å­˜åœ¨ï¼", flush=True)
                    
                    display_columns = [
                        "candidate_id",
                        "name",
                        "file",
                        "æ€»åˆ†",
                        "æŠ€èƒ½åŒ¹é…åº¦",
                        "ç»éªŒç›¸å…³æ€§",
                        "æˆé•¿æ½œåŠ›",
                        "ç¨³å®šæ€§",
                        "short_eval",
                        "highlights",
                        "resume_mini",
                        "è¯æ®",
                    ]
                    existing_display = [col for col in display_columns if col in result_df.columns]
                    if existing_display:
                        display_df = result_df[existing_display].copy()
                        if "resume_mini" in display_df.columns:
                            display_df["resume_mini"] = display_df["resume_mini"].apply(
                                lambda x: (x[:80] + "â€¦") if isinstance(x, str) and len(x) > 80 else x
                            )
                        display_df = translate_dataframe_columns(display_df)
                    st.dataframe(
                            display_df,
                            use_container_width=True,
                            hide_index=True,
                        )
                    export_job_title = st.session_state.get("job_name") or job_title or "æœªæä¾›"
                    export_df = _build_export_dataframe(result_df, export_job_title)

                    st.markdown("### å€™é€‰äººæ´å¯Ÿè¯¦æƒ…")
                    # æŒ‰æ€»åˆ†æ’åºï¼ˆé«˜åˆ†åœ¨å‰ï¼‰
                    result_df_sorted = result_df.sort_values(by="æ€»åˆ†", ascending=False).reset_index(drop=True)
                    for _, row in result_df_sorted.iterrows():
                        candidate_name = row.get('name', 'åŒ¿åå€™é€‰äºº')
                        score_label = row.get("æ€»åˆ†")
                        score_value = float(score_label) if score_label is not None else 0
                        
                        # ========== Accordion æ ‡é¢˜ï¼šæ˜¾ç¤ºå§“åå’Œæ€»åˆ† ==========
                        expander_title = f"ğŸ‘¤ {candidate_name} ï½œ æ€»åˆ†ï¼š{score_value:.1f}"
                        
                        # ========== ç”¨ st.expander åŒ…è£¹æ‰€æœ‰å†…å®¹ï¼Œé»˜è®¤æŠ˜å  ==========
                        with st.expander(expander_title, expanded=False):
                            # ========== 1. é¡¶éƒ¨æ¦‚è§ˆå¡ç‰‡ ==========
                            st.markdown(f"""
                            <div class="candidate-card">
                                <h3>{candidate_name}</h3>
                                <div class="score">æ€»åˆ†ï¼š{score_value:.1f}</div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # ========== Ultraå­—æ®µæ¥å…¥ï¼šäº®ç‚¹æ ‡ç­¾ ==========
                            # ä¼˜å…ˆä½¿ç”¨Ultraå­—æ®µ highlight_tagsï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰
                            highlight_tags_ultra = row.get("highlight_tags", [])
                            
                            # è°ƒè¯•ï¼šæ£€æŸ¥å­—æ®µç±»å‹å’Œå†…å®¹
                            if "highlight_tags" in row:
                                print(f"[DEBUG] highlight_tagsç±»å‹: {type(highlight_tags_ultra)}, å€¼: {highlight_tags_ultra}")
                            
                            if highlight_tags_ultra and isinstance(highlight_tags_ultra, list) and len(highlight_tags_ultra) > 0:
                                # Ultraå­—æ®µï¼šç›´æ¥ä½¿ç”¨åˆ—è¡¨
                                highlights_raw = [str(tag).strip() for tag in highlight_tags_ultra if tag and str(tag).strip()]
                            else:
                                # å›é€€ï¼šä»highlightså­—ç¬¦ä¸²è§£æ
                                highlights_str = row.get("highlights", "")
                                if isinstance(highlights_str, str) and highlights_str.strip():
                                    highlights_raw = [tag.strip() for tag in re.split(r"[ï½œ|ï¼Œ,ã€\s]+", highlights_str) if tag.strip()]
                                elif isinstance(highlights_str, list):
                                    highlights_raw = [str(tag).strip() for tag in highlights_str if tag and str(tag).strip()]
                                else:
                                    highlights_raw = []
                            
                            # è°ƒè¯•ï¼šè¾“å‡ºæœ€ç»ˆç»“æœ
                            if not highlights_raw:
                                print(f"[DEBUG] äº®ç‚¹æ ‡ç­¾ä¸ºç©ºï¼Œrowä¸­çš„å­—æ®µ: {list(row.keys())}")
                                print(f"[DEBUG] highlight_tags={row.get('highlight_tags')}, highlights={row.get('highlights')}")
                            
                            # ç”Ÿæˆäº®ç‚¹æ ‡ç­¾HTMLï¼ˆåœ†è§’æ ‡ç­¾æ ·å¼ï¼‰
                            if highlights_raw:
                                st.markdown("**ğŸ·ï¸ äº®ç‚¹æ ‡ç­¾**")
                                highlight_html = '<div style="margin: 10px 0; display: flex; flex-wrap: wrap; gap: 8px;">'
                                for tag in highlights_raw:
                                    color_class = _get_highlight_color(tag)
                                    highlight_html += f'<span class="highlight-tag highlight-tag-{color_class}" style="display: inline-block; padding: 6px 12px; margin: 0; border-radius: 16px; font-size: 0.9em; font-weight: 500; color: white; background-color: {"#28a745" if color_class == "green" else "#ffc107" if color_class == "yellow" else "#6c757d"};">{tag}</span>'
                                highlight_html += '</div>'
                                st.markdown(highlight_html, unsafe_allow_html=True)
                            else:
                                st.markdown("**ğŸ·ï¸ äº®ç‚¹æ ‡ç­¾**")
                                st.caption("æš‚æ— äº®ç‚¹æ ‡ç­¾")
                            
                            # ========== Ultraå­—æ®µæ¥å…¥ï¼šç®€å†æ‘˜è¦ï¼ˆä¸‰è¡Œç»“æ„åŒ–ï¼‰==========
                            # ä¼˜å…ˆä½¿ç”¨Ultraå­—æ®µ ai_resume_summary æˆ– summary_short
                            ai_resume_summary = row.get("ai_resume_summary", "")
                            summary_short = row.get("summary_short", "")
                            
                            # ä¼˜å…ˆä½¿ç”¨ ai_resume_summaryï¼ˆUltraæ ¼å¼ï¼‰
                            resume_summary_text = ai_resume_summary or summary_short
                            
                            if resume_summary_text:
                                st.markdown("**ğŸ“„ ç®€å†æ‘˜è¦**")
                                # å¦‚æœæ˜¯ä¸‰è¡Œç»“æ„åŒ–æ ¼å¼ï¼ˆåŒ…å«æ¢è¡Œç¬¦ï¼‰ï¼ŒæŒ‰è¡Œæ˜¾ç¤º
                                if '\n' in resume_summary_text:
                                    summary_lines = [line.strip() for line in resume_summary_text.split('\n') if line.strip()]
                                    summary_html = '<div class="resume-mini" style="line-height: 1.8;">'
                                    for i, line in enumerate(summary_lines[:3], 1):
                                        summary_html += f'<div style="margin-bottom: 8px;">{i}. {line}</div>'
                                    summary_html += '</div>'
                                    st.markdown(summary_html, unsafe_allow_html=True)
                                else:
                                    # æ™®é€šæ–‡æœ¬æ ¼å¼
                                    st.markdown(f'<div class="resume-mini">{resume_summary_text}</div>', unsafe_allow_html=True)
                            else:
                                # å›é€€åˆ°å…¼å®¹å­—æ®µ
                                resume_mini = row.get("resume_mini", "")
                                if resume_mini:
                                    st.markdown("**ğŸ“„ ç®€å†æ‘˜è¦**")
                                    st.markdown(f'<div class="resume-mini">{resume_mini}</div>', unsafe_allow_html=True)
                                else:
                                    st.markdown("**ğŸ“„ ç®€å†æ‘˜è¦**")
                                    st.caption("æš‚æ— çŸ­ç‰ˆç®€å†")
                            
                            # ========== Ultraå­—æ®µæ¥å…¥ï¼šAIè¯„ä»·ï¼ˆä¸‰æ®µå¼æ ¼å¼ï¼‰==========
                            # ä¼˜å…ˆä½¿ç”¨Ultraå­—æ®µ ai_reviewï¼Œå…¶æ¬¡ ai_evaluation
                            ai_review = row.get("ai_review", "")
                            ai_evaluation = row.get("ai_evaluation", "")
                            
                            # è°ƒè¯•ï¼šæ£€æŸ¥å­—æ®µ
                            if not ai_review and not ai_evaluation:
                                print(f"[DEBUG] AIè¯„ä»·ä¸ºç©ºï¼Œrowä¸­çš„å­—æ®µ: {list(row.keys())}")
                                print(f"[DEBUG] ai_review={ai_review}, ai_evaluation={ai_evaluation}, short_eval={row.get('short_eval')}")
                            
                            # ä¼˜å…ˆä½¿ç”¨ ai_reviewï¼ˆUltraæ ¼å¼ï¼‰
                            ai_review_text = ai_review or ai_evaluation
                            
                            if ai_review_text:
                                st.markdown("**ğŸ¤– AI è¯„ä»·**")
                                # è§£æä¸‰æ®µå¼ç»“æ„
                                evidence_match = re.search(r'ã€è¯æ®ã€‘\s*(.*?)(?=ã€æ¨ç†ã€‘|ã€ç»“è®ºã€‘|$)', ai_review_text, re.DOTALL)
                                reasoning_match = re.search(r'ã€æ¨ç†ã€‘\s*(.*?)(?=ã€ç»“è®ºã€‘|$)', ai_review_text, re.DOTALL)
                                conclusion_match = re.search(r'ã€ç»“è®ºã€‘\s*(.*?)$', ai_review_text, re.DOTALL)
                                
                                if evidence_match or reasoning_match or conclusion_match:
                                    # ä¸‰æ®µå¼æ ¼å¼åŒ–æ˜¾ç¤º
                                    eval_html = '<div style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #007bff; line-height: 1.8;">'
                                    if evidence_match:
                                        evidence_text = evidence_match.group(1).strip()
                                        eval_html += f'<div style="margin-bottom: 12px;"><strong style="color: #007bff;">ã€è¯æ®ã€‘</strong><div style="margin-top: 6px; padding-left: 12px;">{evidence_text}</div></div>'
                                    if reasoning_match:
                                        reasoning_text = reasoning_match.group(1).strip()
                                        eval_html += f'<div style="margin-bottom: 12px;"><strong style="color: #28a745;">ã€æ¨ç†ã€‘</strong><div style="margin-top: 6px; padding-left: 12px;">{reasoning_text}</div></div>'
                                    if conclusion_match:
                                        conclusion_text = conclusion_match.group(1).strip()
                                        eval_html += f'<div><strong style="color: #dc3545;">ã€ç»“è®ºã€‘</strong><div style="margin-top: 6px; padding-left: 12px;">{conclusion_text}</div></div>'
                                    eval_html += '</div>'
                                    st.markdown(eval_html, unsafe_allow_html=True)
                                else:
                                    # æ™®é€šæ ¼å¼æ˜¾ç¤º
                                    st.markdown(f'<div style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #007bff; line-height: 1.6; white-space: pre-wrap;">{ai_review_text}</div>', unsafe_allow_html=True)
                            else:
                                st.markdown("**ğŸ¤– AI è¯„ä»·**")
                                st.caption("æš‚æ— AIè¯„ä»·")
                            
                            st.markdown("---")
                            
                            # ========== 2. ä»Ultra Formatè¯»å–ä¼˜åŠ¿/åŠ£åŠ¿æ¨ç†é“¾ ==========
                            # ä¼˜å…ˆä½¿ç”¨Ultra-Formatæ ‡å‡†å­—æ®µ
                            strengths_reasoning_chain = row.get("strengths_reasoning_chain", {})
                            weaknesses_reasoning_chain = row.get("weaknesses_reasoning_chain", {})
                            
                            # è°ƒè¯•ï¼šè¾“å‡ºå­—æ®µç±»å‹å’ŒåŸºæœ¬ä¿¡æ¯
                            try:
                                strengths_type = type(strengths_reasoning_chain).__name__
                                weaknesses_type = type(weaknesses_reasoning_chain).__name__
                                print(f"[DEBUG] å‰ç«¯è¯»å–æ¨ç†é“¾: strengthsç±»å‹={strengths_type}, weaknessesç±»å‹={weaknesses_type}", flush=True)
                            except Exception as e:
                                print(f"[DEBUG] å‰ç«¯è¯»å–æ¨ç†é“¾: ç±»å‹æ£€æŸ¥å¤±è´¥: {str(e)[:50]}", flush=True)
                            if isinstance(strengths_reasoning_chain, dict):
                                print(f"[DEBUG]   strengthså­—æ®µ: conclusion={bool(strengths_reasoning_chain.get('conclusion'))}, ai_reasoning={bool(strengths_reasoning_chain.get('ai_reasoning'))}", flush=True)
                            elif isinstance(strengths_reasoning_chain, str):
                                print(f"[DEBUG]   strengthså­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼Œé•¿åº¦={len(strengths_reasoning_chain)}", flush=True)
                            if isinstance(weaknesses_reasoning_chain, dict):
                                print(f"[DEBUG]   weaknesseså­—æ®µ: conclusion={bool(weaknesses_reasoning_chain.get('conclusion'))}, ai_reasoning={bool(weaknesses_reasoning_chain.get('ai_reasoning'))}", flush=True)
                            elif isinstance(weaknesses_reasoning_chain, str):
                                print(f"[DEBUG]   weaknesseså­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼Œé•¿åº¦={len(weaknesses_reasoning_chain)}", flush=True)
                            
                            # è°ƒè¯•ï¼šæ£€æŸ¥æ¨ç†é“¾å­—æ®µ
                            if not strengths_reasoning_chain or (isinstance(strengths_reasoning_chain, dict) and not strengths_reasoning_chain.get("conclusion") and not strengths_reasoning_chain.get("ai_reasoning")):
                                try:
                                    conclusion = strengths_reasoning_chain.get("conclusion", "") if isinstance(strengths_reasoning_chain, dict) else ""
                                    print(f"[DEBUG] ä¼˜åŠ¿æ¨ç†é“¾ä¸ºç©ºæˆ–æ— æ•ˆ: conclusion={conclusion[:50] if conclusion else 'None'}", flush=True)
                                except Exception as e:
                                    print(f"[DEBUG] ä¼˜åŠ¿æ¨ç†é“¾ä¸ºç©ºæˆ–æ— æ•ˆ: {str(e)[:50]}", flush=True)
                            if not weaknesses_reasoning_chain or (isinstance(weaknesses_reasoning_chain, dict) and not weaknesses_reasoning_chain.get("conclusion") and not weaknesses_reasoning_chain.get("ai_reasoning")):
                                try:
                                    conclusion = weaknesses_reasoning_chain.get("conclusion", "") if isinstance(weaknesses_reasoning_chain, dict) else ""
                                    print(f"[DEBUG] åŠ£åŠ¿æ¨ç†é“¾ä¸ºç©ºæˆ–æ— æ•ˆ: conclusion={conclusion[:50] if conclusion else 'None'}", flush=True)
                                except Exception as e:
                                    print(f"[DEBUG] åŠ£åŠ¿æ¨ç†é“¾ä¸ºç©ºæˆ–æ— æ•ˆ: {str(e)[:50]}", flush=True)
                            
                            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼ˆç”¨äºå‰ç«¯æ˜¾ç¤ºï¼‰
                            strengths_chain = []
                            weaknesses_chain = []
                            
                            # å¤„ç†ä¼˜åŠ¿æ¨ç†é“¾
                            # æ£€æŸ¥æ˜¯å¦æ˜¯å­—ç¬¦ä¸²ï¼ˆå¯èƒ½è¢«åºåˆ—åŒ–äº†ï¼‰
                            if isinstance(strengths_reasoning_chain, str):
                                try:
                                    import json
                                    strengths_reasoning_chain = json.loads(strengths_reasoning_chain)
                                    print(f"[DEBUG] ä¼˜åŠ¿æ¨ç†é“¾è¢«åºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œå·²è§£æ", flush=True)
                                except:
                                    print(f"[DEBUG] ä¼˜åŠ¿æ¨ç†é“¾æ˜¯å­—ç¬¦ä¸²ä½†æ— æ³•è§£æ: {strengths_reasoning_chain[:100]}", flush=True)
                                    strengths_reasoning_chain = {}
                            
                            if strengths_reasoning_chain and isinstance(strengths_reasoning_chain, dict):
                                # Ultra-Format: {conclusion, detected_actions, resume_evidence, ai_reasoning}
                                conclusion = strengths_reasoning_chain.get("conclusion", "")
                                detected_actions = strengths_reasoning_chain.get("detected_actions", [])
                                resume_evidence = strengths_reasoning_chain.get("resume_evidence", [])
                                ai_reasoning = strengths_reasoning_chain.get("ai_reasoning", "")
                                
                                print(f"[DEBUG] å‰ç«¯å¤„ç†ä¼˜åŠ¿æ¨ç†é“¾: conclusion={conclusion[:50] if conclusion else 'None'}, ai_reasoningé•¿åº¦={len(ai_reasoning)}", flush=True)
                                
                                # åªè¦æœ‰conclusionæˆ–ai_reasoningï¼Œå°±è®¤ä¸ºæœ‰å†…å®¹
                                if conclusion or ai_reasoning or detected_actions or resume_evidence:
                                    strengths_chain.append({
                                        "conclusion": conclusion or "å…·å¤‡å²—ä½æ‰€éœ€çš„æ ¸å¿ƒèƒ½åŠ›",
                                        "detected_actions": ", ".join(detected_actions[:3]) if isinstance(detected_actions, list) and detected_actions else "",
                                        "resume_evidence": ", ".join(resume_evidence[:3]) if isinstance(resume_evidence, list) and resume_evidence else "",
                                        "ai_reasoning": ai_reasoning or "åŸºäºè¯„åˆ†ç»“æœï¼Œå€™é€‰äººå…·å¤‡ä¸€å®šçš„å·¥ä½œèƒ½åŠ›ã€‚"
                                    })
                                    print(f"[DEBUG] ä¼˜åŠ¿æ¨ç†é“¾å·²æ·»åŠ åˆ°strengths_chainï¼Œå½“å‰é•¿åº¦={len(strengths_chain)}", flush=True)
                                else:
                                    print(f"[DEBUG] ä¼˜åŠ¿æ¨ç†é“¾å†…å®¹ä¸ºç©ºï¼Œæœªæ·»åŠ åˆ°strengths_chain", flush=True)
                            else:
                                print(f"[DEBUG] ä¼˜åŠ¿æ¨ç†é“¾ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯: type={type(strengths_reasoning_chain)}", flush=True)
                            
                            # å¤„ç†åŠ£åŠ¿æ¨ç†é“¾
                            # å¦‚æœweaknesses_reasoning_chainæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
                            if isinstance(weaknesses_reasoning_chain, str):
                                try:
                                    import json
                                    weaknesses_reasoning_chain = json.loads(weaknesses_reasoning_chain)
                                except:
                                    weaknesses_reasoning_chain = {}
                            
                            if weaknesses_reasoning_chain and isinstance(weaknesses_reasoning_chain, dict):
                                # Ultra-Format: {conclusion, resume_gap, compare_to_jd, ai_reasoning}
                                conclusion = weaknesses_reasoning_chain.get("conclusion", "")
                                resume_gap = weaknesses_reasoning_chain.get("resume_gap", [])
                                compare_to_jd = weaknesses_reasoning_chain.get("compare_to_jd", "")
                                ai_reasoning = weaknesses_reasoning_chain.get("ai_reasoning", "")
                                
                                print(f"[DEBUG] å‰ç«¯å¤„ç†åŠ£åŠ¿æ¨ç†é“¾: conclusion={conclusion}, ai_reasoningé•¿åº¦={len(ai_reasoning)}", flush=True)
                                
                                # åªè¦æœ‰conclusionæˆ–ai_reasoningï¼Œå°±è®¤ä¸ºæœ‰å†…å®¹
                                if conclusion or ai_reasoning or resume_gap or compare_to_jd:
                                    weaknesses_chain.append({
                                        "conclusion": conclusion or "å­˜åœ¨ä¸€å®šä¸è¶³",
                                        "resume_gap": ", ".join(resume_gap[:3]) if isinstance(resume_gap, list) and resume_gap else "",
                                        "compare_to_jd": compare_to_jd or "",
                                        "ai_reasoning": ai_reasoning or "åŸºäºè¯„åˆ†ç»“æœï¼Œå€™é€‰äººå­˜åœ¨ä¸€å®šä¸è¶³ï¼Œå»ºè®®è¿›ä¸€æ­¥è¯„ä¼°ã€‚"
                                    })
                                    print(f"[DEBUG] åŠ£åŠ¿æ¨ç†é“¾å·²æ·»åŠ åˆ°weaknesses_chainï¼Œå½“å‰é•¿åº¦={len(weaknesses_chain)}", flush=True)
                                else:
                                    print(f"[DEBUG] åŠ£åŠ¿æ¨ç†é“¾å†…å®¹ä¸ºç©ºï¼Œæœªæ·»åŠ åˆ°weaknesses_chain", flush=True)
                            else:
                                print(f"[DEBUG] åŠ£åŠ¿æ¨ç†é“¾ç±»å‹é”™è¯¯æˆ–ä¸ºç©º: type={type(weaknesses_reasoning_chain)}, value={weaknesses_reasoning_chain}", flush=True)
                            
                            # å¦‚æœUltra-Formatå­—æ®µä¸ºç©ºï¼Œä»evidence_chainsç”Ÿæˆï¼ˆå…¼å®¹é€»è¾‘ï¼‰
                            if not strengths_chain and not weaknesses_chain:
                                evidence_chains_ultra = row.get("evidence_chains", {})
                                
                                # ç”Ÿæˆä¼˜åŠ¿æ¨ç†é“¾ï¼ˆä»evidence_chainsä¸­æŒ‘é€‰æœ€å¼ºçš„2æ¡ï¼‰
                                if evidence_chains_ultra and isinstance(evidence_chains_ultra, dict):
                                    # ä¼˜å…ˆä»æŠ€èƒ½åŒ¹é…åº¦å’Œç»éªŒç›¸å…³æ€§ä¸­æå–
                                    skill_evidences = evidence_chains_ultra.get("æŠ€èƒ½åŒ¹é…åº¦", [])
                                    exp_evidences = evidence_chains_ultra.get("ç»éªŒç›¸å…³æ€§", [])
                                    
                                    # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
                                    if not isinstance(skill_evidences, list):
                                        skill_evidences = []
                                    if not isinstance(exp_evidences, list):
                                        exp_evidences = []
                                    
                                    for ev in (skill_evidences + exp_evidences)[:2]:
                                        if isinstance(ev, dict):
                                            strengths_chain.append({
                                                "action": ev.get("action", ""),
                                                "evidence": ev.get("evidence", ""),
                                                "reasoning": ev.get("reasoning", "")
                                            })
                                
                                # ç”ŸæˆåŠ£åŠ¿æ¨ç†é“¾ï¼ˆä»weak_pointsæˆ–evidence_chainsä¸­æå–ï¼‰
                                weak_points = row.get("weak_points", [])
                                if weak_points and isinstance(weak_points, list) and len(weak_points) > 0:
                                    # weak_pointsæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºæ¨ç†é“¾æ ¼å¼
                                    for point in weak_points[:2]:
                                        if isinstance(point, str):
                                            weaknesses_chain.append({
                                                "action": "çŸ­æ¿é¡¹",
                                                "evidence": point,
                                                "reasoning": point
                                            })
                                elif evidence_chains_ultra and isinstance(evidence_chains_ultra, dict):
                                    # ä»evidence_chainsä¸­æ‰¾å‡ºæœ€ä½åˆ†ç»´åº¦
                                    score_dims = row.get("score_dims", {})
                                    if score_dims and isinstance(score_dims, dict):
                                        dim_scores = {
                                            "æŠ€èƒ½åŒ¹é…åº¦": score_dims.get("skill_match", 0),
                                            "ç»éªŒç›¸å…³æ€§": score_dims.get("experience_match", 0),
                                            "æˆé•¿æ½œåŠ›": score_dims.get("growth_potential", 0),
                                            "ç¨³å®šæ€§": score_dims.get("stability", 0),
                                        }
                                        lowest_dim = min(dim_scores.items(), key=lambda x: x[1])[0]
                                        lowest_evidences = evidence_chains_ultra.get(lowest_dim, [])
                                        
                                        if isinstance(lowest_evidences, list):
                                            for ev in lowest_evidences[:2]:
                                                if isinstance(ev, dict):
                                                    weaknesses_chain.append({
                                                        "action": ev.get("action", ""),
                                                        "evidence": ev.get("evidence", ""),
                                                        "reasoning": ev.get("reasoning", "")
                                                    })
                            
                            # å…¼å®¹æ—§æ ¼å¼æ¨ç†é“¾ï¼ˆæœ€åå›é€€ï¼‰
                            if not strengths_chain and not weaknesses_chain:
                                reasoning_raw = row.get("reasoning_chain") or {}
                                try:
                                    reasoning_obj = (
                                        json.loads(reasoning_raw)
                                        if isinstance(reasoning_raw, str)
                                        else reasoning_raw
                                    )
                                except Exception:
                                    reasoning_obj = {}
                                
                                old_strengths = reasoning_obj.get("strengths_reasoning_chain") or []
                                old_weaknesses = reasoning_obj.get("weaknesses_reasoning_chain") or []
                                
                                if isinstance(old_strengths, list):
                                    strengths_chain = old_strengths
                                if isinstance(old_weaknesses, list):
                                    weaknesses_chain = old_weaknesses
                            
                            # ========== 3. ä¸€å¥è¯æ€»ç»“ ==========
                            summary_text = _generate_summary_text(strengths_chain, weaknesses_chain)
                            st.markdown(summary_text)
                            
                            st.markdown("---")
                            
                            # ========== 4. ä¸¤åˆ—å¸ƒå±€ï¼ˆDesktopï¼‰& å•åˆ—å¸ƒå±€ï¼ˆMobileï¼‰ ==========
                            col_left, col_right = st.columns([1, 1])
                            
                            with col_left:
                                # ========== é›·è¾¾å›¾ï¼ˆä½¿ç”¨Ultra score_dimså­—æ®µï¼‰==========
                                # ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„score_dims
                                score_dims = row.get("score_dims", {})
                                if score_dims and isinstance(score_dims, dict):
                                    scores_dict = {
                                        "æŠ€èƒ½åŒ¹é…åº¦": float(score_dims.get("skill_match", 0) or 0),
                                        "ç»éªŒç›¸å…³æ€§": float(score_dims.get("experience_match", 0) or 0),
                                        "æˆé•¿æ½œåŠ›": float(score_dims.get("growth_potential", 0) or 0),
                                        "ç¨³å®šæ€§": float(score_dims.get("stability", 0) or 0),
                                    }
                                else:
                                    # å…¼å®¹æ—§å­—æ®µï¼ˆä»ç»´åº¦å¾—åˆ†è·å–ï¼‰
                                    scores_dict = {
                                        "æŠ€èƒ½åŒ¹é…åº¦": float(row.get("æŠ€èƒ½åŒ¹é…åº¦", 0) or 0),
                                        "ç»éªŒç›¸å…³æ€§": float(row.get("ç»éªŒç›¸å…³æ€§", 0) or 0),
                                        "æˆé•¿æ½œåŠ›": float(row.get("æˆé•¿æ½œåŠ›", 0) or 0),
                                        "ç¨³å®šæ€§": float(row.get("ç¨³å®šæ€§", 0) or 0),
                                    }
                                
                                st.markdown("**ğŸ“Š è¯„åˆ†ç»´åº¦é›·è¾¾å›¾**")
                                
                                # è·å–æ ‡å‡†æ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰
                                standard_model = row.get("standard_model", {})
                                if not standard_model or not isinstance(standard_model, dict):
                                    # å°è¯•ä»å…¶ä»–å­—æ®µè·å–
                                    standard_model = row.get("standard_ability_model", {})
                                
                                # å¦‚æœæœ‰æ ‡å‡†æ¨¡å‹ï¼Œæ˜¾ç¤ºè¯´æ˜
                                if standard_model and isinstance(standard_model, dict):
                                    st.caption("ğŸ“Œ çº¢è‰²è™šçº¿ï¼šå²—ä½æ ‡å‡†èƒ½åŠ›æ¨¡å‹ | è“è‰²å®çº¿ï¼šå€™é€‰äººå®é™…èƒ½åŠ›")
                                
                                # åˆ›å»ºé›·è¾¾å›¾ï¼šä½¿ç”¨å€™é€‰äººID+uuidç”Ÿæˆå”¯ä¸€keyé¿å…å†²çª
                                try:
                                    radar_fig = _create_radar_chart(scores_dict, standard_model)
                                    if radar_fig:
                                        # ä½¿ç”¨å€™é€‰äººIDï¼ˆå¦‚æœæœ‰ï¼‰å’Œuuidç”Ÿæˆå”¯ä¸€key
                                        candidate_id = str(row.get("å€™é€‰äººID", "")) or str(row.get("id", "")) or "unknown"
                                        unique_key = f"radar_{candidate_id}_{uuid.uuid4().hex[:8]}"
                                        st.plotly_chart(radar_fig, use_container_width=True, key=unique_key)
                                except ImportError as e:
                                    # plotly æœªå®‰è£… - æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
                                    import sys
                                    st.error(f"âŒ Plotly å¯¼å…¥å¤±è´¥: {str(e)}")
                                    st.info(f"ğŸ’¡ Python è·¯å¾„: {sys.executable}")
                                    st.info("ğŸ’¡ æç¤ºï¼šå®‰è£… plotly å¯æŸ¥çœ‹é›·è¾¾å›¾å¯è§†åŒ–")
                                    st.info(f"ğŸ’¡ è¯·è¿è¡Œ: pip install plotly kaleido")
                                    score_table = pd.DataFrame({
                                        "ç»´åº¦": ["æŠ€èƒ½åŒ¹é…åº¦", "ç»éªŒç›¸å…³æ€§", "æˆé•¿æ½œåŠ›", "ç¨³å®šæ€§"],
                                        "å¾—åˆ†": [
                                            scores_dict.get("æŠ€èƒ½åŒ¹é…åº¦", 0),
                                            scores_dict.get("ç»éªŒç›¸å…³æ€§", 0),
                                            scores_dict.get("æˆé•¿æ½œåŠ›", 0),
                                            scores_dict.get("ç¨³å®šæ€§", 0),
                                        ]
                                    })
                                    st.dataframe(score_table, use_container_width=True, hide_index=True)
                                except Exception as e:
                                    # å…¶ä»–é”™è¯¯ï¼ˆåˆ›å»ºå¤±è´¥ã€æ¸²æŸ“å¤±è´¥ç­‰ï¼‰
                                    st.warning(f"âš ï¸ é›·è¾¾å›¾æ˜¾ç¤ºå¤±è´¥: {str(e)[:150]}")
                                    # æ˜¾ç¤ºæ–‡æœ¬è¡¨æ ¼ä½œä¸ºæ›¿ä»£
                                    score_table = pd.DataFrame({
                                        "ç»´åº¦": ["æŠ€èƒ½åŒ¹é…åº¦", "ç»éªŒç›¸å…³æ€§", "æˆé•¿æ½œåŠ›", "ç¨³å®šæ€§"],
                                        "å¾—åˆ†": [
                                            scores_dict.get("æŠ€èƒ½åŒ¹é…åº¦", 0),
                                            scores_dict.get("ç»éªŒç›¸å…³æ€§", 0),
                                            scores_dict.get("æˆé•¿æ½œåŠ›", 0),
                                            scores_dict.get("ç¨³å®šæ€§", 0),
                                        ]
                                    })
                                    st.dataframe(score_table, use_container_width=True, hide_index=True)
                                
                                # ========== ä¼˜åŠ¿æ€»ç»“ï¼ˆä»evidence_chainsæå–ï¼‰==========
                                with st.expander("âœ… **ä¼˜åŠ¿æ€»ç»“**", expanded=False):
                                    # ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„strengths_reasoning_chain
                                    if strengths_chain:
                                        for idx, item in enumerate(strengths_chain, 1):
                                            if not isinstance(item, dict):
                                                continue
                                            # Ultra-Formatå­—æ®µ
                                            conclusion = item.get('conclusion', item.get('action', 'æ— ç»“è®º'))
                                            detected_actions = item.get('detected_actions', item.get('action', ''))
                                            resume_evidence = item.get('resume_evidence', item.get('evidence', ''))
                                            ai_reasoning = item.get('ai_reasoning', item.get('reasoning', ''))
                                            
                                            st.markdown(f"**{idx}. {conclusion}**")
                                            if detected_actions:
                                                st.markdown(f"   *åŠ¨ä½œï¼š* {detected_actions[:80]}")
                                            if resume_evidence:
                                                st.markdown(f"   *è¯æ®ï¼š* {resume_evidence[:80]}")
                                            if ai_reasoning:
                                                st.markdown(f"   *æ¨ç†ï¼š* {ai_reasoning[:100]}")
                                            if idx < len(strengths_chain):
                                                st.markdown("---")
                                    else:
                                        st.caption("æš‚æ— ç›¸å…³è®°å½•")
                                
                                # ========== åŠ£åŠ¿æ€»ç»“ï¼ˆä»weaknesses_reasoning_chainæå–ï¼‰==========
                                with st.expander("âš ï¸ **åŠ£åŠ¿æ€»ç»“**", expanded=False):
                                    # ä¼˜å…ˆä½¿ç”¨Ultraæ ¼å¼çš„weaknesses_reasoning_chain
                                    if weaknesses_chain:
                                        for idx, item in enumerate(weaknesses_chain, 1):
                                            if isinstance(item, dict):
                                                # Ultra-Formatå­—æ®µ
                                                conclusion = item.get("conclusion", item.get("action", "åŠ£åŠ¿é¡¹"))
                                                resume_gap = item.get("resume_gap", item.get("evidence", ""))
                                                compare_to_jd = item.get("compare_to_jd", "")
                                                ai_reasoning = item.get("ai_reasoning", item.get("reasoning", ""))
                                                
                                                if conclusion or resume_gap or compare_to_jd or ai_reasoning:
                                                    st.markdown(f"**{idx}. {conclusion}**")
                                                    if resume_gap:
                                                        gap_text = resume_gap if isinstance(resume_gap, str) else ", ".join(resume_gap[:3]) if isinstance(resume_gap, list) else str(resume_gap)
                                                        st.markdown(f"   *ç¼ºå¤±é¡¹ï¼š* {gap_text[:80]}")
                                                    if compare_to_jd:
                                                        st.markdown(f"   *å¯¹æ¯”JDï¼š* {compare_to_jd[:80]}")
                                                    if ai_reasoning:
                                                        st.markdown(f"   *æ¨ç†ï¼š* {ai_reasoning[:100]}")
                                                    if idx < len(weaknesses_chain):
                                                        st.markdown("---")
                                            else:
                                                # å…¼å®¹æ—§æ ¼å¼
                                                conclusion = item.get('conclusion', 'æ— ç»“è®º') if isinstance(item, dict) else str(item)
                                                st.markdown(f"**{idx}. {conclusion}**")
                                                if idx < len(weaknesses_chain):
                                                    st.markdown("---")
                                    else:
                                        st.caption("æš‚æ— ç›¸å…³è®°å½•")
                            
                            with col_right:
                                # ========== è¯æ®é“¾è¯¦æƒ…ï¼ˆUltraæ ¼å¼ï¼šå››ç»´åº¦å®Œæ•´æ˜¾ç¤ºï¼‰==========
                                evidence_chains_ultra = row.get("evidence_chains", {})
                                evidence_text_ultra = row.get("evidence_text", "")
                                
                                if evidence_chains_ultra and isinstance(evidence_chains_ultra, dict) and len(evidence_chains_ultra) > 0:
                                    # ä½¿ç”¨Ultraæ ¼å¼çš„è¯æ®é“¾ï¼ˆå››ç»´åº¦ï¼‰
                                    with st.expander("ğŸ“‹ **è¯æ®é“¾è¯¦æƒ…**", expanded=False):
                                        dimension_order = ["æŠ€èƒ½åŒ¹é…åº¦", "ç»éªŒç›¸å…³æ€§", "æˆé•¿æ½œåŠ›", "ç¨³å®šæ€§"]
                                        for dim in dimension_order:
                                            if dim in evidence_chains_ultra:
                                                dim_evidences = evidence_chains_ultra[dim]
                                                if isinstance(dim_evidences, list) and len(dim_evidences) > 0:
                                                    st.markdown(f"### ã€{dim}ã€‘")
                                                    for idx, ev in enumerate(dim_evidences, 1):
                                                        if isinstance(ev, dict):
                                                            action = ev.get('action', 'æš‚æ— ')
                                                            evidence = ev.get('evidence', 'æš‚æ— ')
                                                            reasoning = ev.get('reasoning', 'æš‚æ— ')
                                                            
                                                            st.markdown(f"**{idx}. åŠ¨ä½œï¼š** {action}")
                                                            if len(evidence) > 80:
                                                                evidence = evidence[:80] + "..."
                                                            st.markdown(f"   **åŸæ–‡è¯æ®ï¼š** {evidence}")
                                                            if len(reasoning) > 100:
                                                                reasoning = reasoning[:100] + "..."
                                                            st.markdown(f"   **æ¨ç†ï¼š** {reasoning}")
                                                            if idx < len(dim_evidences):
                                                                st.markdown("---")
                                                    if dim != dimension_order[-1]:
                                                        st.markdown("")
                                elif evidence_text_ultra:
                                    # å›é€€åˆ°æ–‡æœ¬æ ¼å¼
                                    with st.expander("ğŸ“‹ **è¯æ®é“¾è¯¦æƒ…**", expanded=False):
                                        st.markdown(f'<div style="white-space: pre-wrap; line-height: 1.6;">{evidence_text_ultra}</div>', unsafe_allow_html=True)
                                else:
                                    # å›é€€åˆ°æ—§æ ¼å¼æ¨ç†é“¾
                                    with st.expander("ğŸ” **ä¼˜åŠ¿æ¨ç†é“¾è¯¦æƒ…**", expanded=False):
                                        if strengths_chain:
                                            for idx, item in enumerate(strengths_chain, 1):
                                                if isinstance(item, dict):
                                                    action = item.get("action", item.get("detected_actions", "æœªæä¾›"))
                                                    evidence = item.get("evidence", item.get("resume_evidence", "æœªæä¾›"))
                                                    reasoning = item.get("reasoning", item.get("ai_reasoning", "æœªæä¾›"))
                                                    st.markdown(f"""
                                                    <div class="reasoning-item">
                                                        <strong>{idx}. {action}</strong><br/>
                                                        <small>è¯æ®ï¼š{evidence[:80]}</small><br/>
                                                        <small>æ¨æ–­ï¼š{reasoning[:100]}</small>
                                                    </div>
                                                    """, unsafe_allow_html=True)
                                        else:
                                            st.caption("æš‚æ— ç›¸å…³è®°å½•")
                                    
                                    with st.expander("ğŸ” **åŠ£åŠ¿æ¨ç†é“¾è¯¦æƒ…**", expanded=False):
                                        if weaknesses_chain:
                                            for idx, item in enumerate(weaknesses_chain, 1):
                                                if isinstance(item, dict):
                                                    action = item.get("action", item.get("resume_gap", "æœªæä¾›"))
                                                    evidence = item.get("evidence", item.get("compare_to_jd", "æœªæä¾›"))
                                                    reasoning = item.get("reasoning", item.get("ai_reasoning", "æœªæä¾›"))
                                                    st.markdown(f"""
                                                    <div class="reasoning-item">
                                                        <strong>{idx}. {action}</strong><br/>
                                                        <small>è¯æ®ï¼š{evidence[:80]}</small><br/>
                                                        <small>é£é™©ï¼š{reasoning[:100]}</small>
                                                    </div>
                                                    """, unsafe_allow_html=True)
                                        else:
                                            st.caption("æš‚æ— ç›¸å…³è®°å½•")

                    # âœ… ä¸€é”®ä¿®å¤ç‰ˆï¼šAI åŒ¹é…å®Œæˆåè‡ªåŠ¨ä¿å­˜ & è·³è½¬

                    # åˆ¤æ–­AIåŒ¹é…ç»“æœæ˜¯å¦ä¸ºç©º
                    if "result_df" in locals() and not result_df.empty:
                        # ä¿å­˜è¯„åˆ†ç»“æœåˆ°session_stateï¼Œä¾›ä¸‹ä¸€æ­¥â€œå»é‡&æ’åºâ€ä½¿ç”¨
                        st.session_state["score_df"] = result_df
                        st.session_state["scored"] = result_df

                        # æ˜¾ç¤ºæˆåŠŸæç¤º
                        st.success("AI åŒ¹é…åˆ†æå®Œæˆ âœ…")
                        st.info("ç³»ç»Ÿå·²è‡ªåŠ¨ä¿å­˜è¯„åˆ†ç»“æœï¼Œè¯·ç‚¹å‡»é¡¶éƒ¨å¯¼èˆªæ ã€3 å»é‡ & æ’åºã€æŸ¥çœ‹ Top-N å€™é€‰äººã€‚")

                        # è‡ªåŠ¨å¯¼å‡ºCSVæ–‡ä»¶åˆ°é¡¹ç›®dataç›®å½•
                        import os
                        output_path = os.path.join("data", "ai_match_results.csv")
                        try:
                            export_df.to_csv(output_path, index=False, encoding="utf-8-sig")
                            st.write(f"âœ… å·²è‡ªåŠ¨ä¿å­˜åŒ¹é…ç»“æœè‡³ `{output_path}`")
                        except Exception as e:
                            st.warning(f"âš ï¸ ä¿å­˜CSVå¤±è´¥: {e}")

                        # ï¼ˆå¯é€‰ï¼‰æä¾›ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½ AI åŒ¹é…ç»“æœï¼ˆCSVï¼‰",
                            data=export_df.to_csv(index=False).encode("utf-8-sig"),
                            file_name="ai_match_results.csv",
                            mime="text/csv"
                        )
                    else:
                        st.warning("âš ï¸ æš‚æ— åŒ¹é…ç»“æœï¼Œè¯·å…ˆå®ŒæˆAIåŒ¹é…è¯„åˆ†åå†å°è¯•ã€‚")
    else:
        st.info("è¯·ä¸Šä¼ ä¸€æ‰¹ç®€å†æ–‡ä»¶å¼€å§‹åˆ†æã€‚")

with tab3:
    st.subheader("å»é‡ & æ’åºï¼ˆå±•ç¤º Top-Nï¼‰")
    topn = st.slider("Top-N", 5, 50, 10)
    st.session_state["topn_limit"] = topn
    score_source = None
    if "score_df" in st.session_state:
        score_source = st.session_state["score_df"]
    elif "scored" in st.session_state:
        score_source = st.session_state["scored"]

    if score_source is not None:
        # å»é‡æ’åº
        deduped = pipe.dedup_and_rank(score_source)
        st.session_state["shortlist"] = deduped.head(topn)
        shortlist_ids: list[str] = []
        if "candidate_id" in st.session_state["shortlist"].columns:
            shortlist_ids = (
                st.session_state["shortlist"]["candidate_id"].astype(str).tolist()
            )
        elif "åºå·" in st.session_state["shortlist"].columns:
            shortlist_ids = (
                st.session_state["shortlist"]["åºå·"].astype(str).tolist()
            )
        st.session_state["topn_ids"] = shortlist_ids
        
        # ä½¿ç”¨ä¸tab2å®Œå…¨ä¸€è‡´çš„å­—æ®µæ˜¾ç¤ºé¡ºåºå’Œé€»è¾‘
        display_columns = [
            "candidate_id",
            "name",
            "file",
            "æ€»åˆ†",
            "æŠ€èƒ½åŒ¹é…åº¦",
            "ç»éªŒç›¸å…³æ€§",
            "æˆé•¿æ½œåŠ›",
            "ç¨³å®šæ€§",
            "short_eval",
            "highlights",
            "resume_mini",
            "è¯æ®",
        ]
        
        # åªé€‰æ‹©å­˜åœ¨çš„åˆ—ï¼Œä¿æŒé¡ºåºï¼ˆä¸tab2é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
        existing_display = [col for col in display_columns if col in deduped.columns]
        if existing_display:
            # åˆ›å»ºæ˜¾ç¤ºç”¨çš„DataFrameå‰¯æœ¬ï¼Œç¡®ä¿æ•°æ®ä¸è¢«ä¿®æ”¹
            deduped_display = deduped.head(topn)[existing_display].copy()
            
            # å¯¹resume_miniè¿›è¡Œé•¿åº¦é™åˆ¶ï¼ˆä¸tab2å®Œå…¨ä¸€è‡´ï¼‰
            if "resume_mini" in deduped_display.columns:
                deduped_display["resume_mini"] = deduped_display["resume_mini"].apply(
                    lambda x: (x[:80] + "â€¦") if isinstance(x, str) and len(x) > 80 else x
                )
            
            # æ±‰åŒ–æ˜¾ç¤ºï¼ˆä¸tab2å®Œå…¨ä¸€è‡´ï¼‰
            deduped_display = translate_dataframe_columns(deduped_display)
            st.dataframe(
                deduped_display,
                use_container_width=True,
                hide_index=True,
            )
        else:
            # å¦‚æœæ²¡æœ‰åŒ¹é…çš„åˆ—ï¼Œæ˜¾ç¤ºåŸå§‹æ•°æ®
            deduped_display = translate_dataframe_columns(deduped.head(topn))
            st.dataframe(deduped_display, use_container_width=True, hide_index=True)
    else:
        st.warning("è¯·å…ˆå®Œæˆè¯„åˆ†")

with tab4:
    st.subheader("ğŸ¤– ä¸€é”®é‚€çº¦ + è‡ªåŠ¨æ’æœŸ")
    st.markdown("è®©AIå¸®ä½ ç”Ÿæˆä¸ªæ€§åŒ–é‚€çº¦é‚®ä»¶ï¼ˆå«å€™é€‰äº®ç‚¹ + æ—¥å†é™„ä»¶ï¼‰")

    # ä¼˜å…ˆä½¿ç”¨å»é‡&æ’åºåçš„shortlistï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹score_df
    shortlist = st.session_state.get("shortlist")
    score_df = st.session_state.get("score_df")
    
    if shortlist is not None and not shortlist.empty:
        # ä½¿ç”¨å»é‡&æ’åºåçš„ç»“æœ
        df = shortlist.copy()
        st.info(f"âœ… å·²ä½¿ç”¨ã€Œå»é‡&æ’åºã€æ­¥éª¤ç­›é€‰åçš„ Top-{len(df)} åå€™é€‰äºº")
    elif score_df is not None and not score_df.empty:
        # å¦‚æœæ²¡æœ‰shortlistï¼Œä½¿ç”¨åŸå§‹score_dfï¼ˆéœ€è¦å…ˆæ’åºï¼‰
        df = score_df.copy()
        # æŒ‰æ€»åˆ†é™åºæ’åº
        if "æ€»åˆ†" in df.columns:
            df = df.sort_values(by="æ€»åˆ†", ascending=False, ignore_index=True)
        elif "score_total" in df.columns:
            df = df.sort_values(by="score_total", ascending=False, ignore_index=True)
        st.warning("âš ï¸ å»ºè®®å…ˆåœ¨ã€Œå»é‡&æ’åºã€æ­¥éª¤ä¸­ç­›é€‰å€™é€‰äººï¼Œå½“å‰ä½¿ç”¨åŸå§‹è¯„åˆ†ç»“æœï¼ˆå·²æŒ‰æ€»åˆ†æ’åºï¼‰")
    else:
        st.warning("è¯·å…ˆå®ŒæˆAIåŒ¹é…è¯„åˆ†ã€‚")
        df = None
    
    if df is not None and not df.empty:
        max_candidates = len(df)
        default_top = min(5, max_candidates)
        top_n = st.number_input(
            "é€‰æ‹©è¦é‚€çº¦çš„å€™é€‰äººæ•°ï¼ˆTop-Nï¼‰",
            min_value=1,
            max_value=max_candidates,
            value=default_top,
            step=1,
        )
        top_n = int(top_n)
        selected_candidates = df.head(top_n)

        score_col = "æ€»åˆ†" if "æ€»åˆ†" in df.columns else "score_total" if "score_total" in df.columns else None
        display_cols = [
            col
            for col in [
                "name",
                "file",
                "email",
                "phone",
                score_col,
                "æŠ€èƒ½åŒ¹é…åº¦",
                "ç»éªŒç›¸å…³æ€§",
                "æˆé•¿æ½œåŠ›",
                "ç¨³å®šæ€§",
                "short_eval",
                "highlights",
                "resume_mini",
            ]
            if col and col in df.columns
        ]
        if not display_cols:
            display_cols = df.columns.tolist()

        st.write(f"å·²é€‰æ‹© {top_n} ä½å€™é€‰äººï¼š")
        st.dataframe(selected_candidates[display_cols], use_container_width=True)

        # æ—¶åŒºé€‰æ‹©ï¼ˆå…¨å±€è®¾ç½®ï¼‰
        timezone = st.selectbox("ğŸŒ æ—¶åŒº", ["Asia/Shanghai", "Asia/Beijing", "UTC"], index=0)
        
        # ä¸ºæ¯ä½å€™é€‰äººå•ç‹¬è®¾ç½®é¢è¯•æ—¶é—´
        st.markdown("### ğŸ“… ä¸ºæ¯ä½å€™é€‰äººè®¾ç½®é¢è¯•æ—¶é—´")
        st.info("ğŸ’¡ æ¯ä½å€™é€‰äººå¯ä»¥è®¾ç½®ä¸åŒçš„é¢è¯•æ—¶é—´ï¼Œé¿å…ç¾¤é¢å†²çª")
        
        candidate_interview_times = {}
        candidate_interview_locations = {}
        
        # é»˜è®¤é¢è¯•æ—¶é—´å’Œåœ°ç‚¹
        default_date = datetime.now().date() + timedelta(days=1)
        default_time = datetime.strptime("14:00", "%H:%M").time()
        default_location = "å…¬å¸ä¼šè®®å®¤ï¼ˆå…·ä½“åœ°å€å¾…ç¡®è®¤ï¼‰"
        
        for idx, (_, row) in enumerate(selected_candidates.iterrows()):
            row_dict = row.to_dict()
            candidate_name = row_dict.get("name") or row_dict.get("file") or f"å€™é€‰äºº{idx+1}"
            
            with st.expander(f"ğŸ“… {candidate_name} çš„é¢è¯•å®‰æ’", expanded=(idx == 0)):
                col_date, col_time = st.columns(2)
                with col_date:
                    # ä»session_stateè·å–ä¹‹å‰è®¾ç½®çš„æ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                    date_key = f"interview_date_{idx}"
                    prev_date = st.session_state.get(date_key, default_date)
                    interview_date = st.date_input(
                        "é¢è¯•æ—¥æœŸ",
                        value=prev_date,
                        key=date_key,
                        label_visibility="visible"
                    )
                with col_time:
                    time_key = f"interview_time_{idx}"
                    prev_time = st.session_state.get(time_key, default_time)
                    interview_hour = st.time_input(
                        "é¢è¯•æ—¶é—´",
                        value=prev_time,
                        key=time_key,
                        label_visibility="visible"
                    )
                
                # æ ¼å¼åŒ–é¢è¯•æ—¶é—´å­—ç¬¦ä¸²
                interview_datetime = datetime.combine(interview_date, interview_hour)
                interview_time_str = f"{interview_datetime.strftime('%Y-%m-%d %H:%M')}, {timezone}"
                candidate_interview_times[idx] = interview_time_str
                
                # é¢è¯•åœ°ç‚¹ï¼ˆå¯ä»¥ä¸ºæ¯ä¸ªå€™é€‰äººå•ç‹¬è®¾ç½®ï¼‰
                location_key = f"interview_location_{idx}"
                prev_location = st.session_state.get(location_key, default_location if idx == 0 else "")
                interview_location = st.text_input(
                    "ğŸ“ é¢è¯•åœ°ç‚¹",
                    value=prev_location,
                    key=location_key,
                    help="å¯ä¸ºæ¯ä½å€™é€‰äººè®¾ç½®ä¸åŒçš„é¢è¯•åœ°ç‚¹",
                    label_visibility="visible"
                )
                candidate_interview_locations[idx] = interview_location or default_location
        
        # å…¨å±€é¢è¯•åœ°ç‚¹å’Œæ—¶é—´ï¼ˆå¦‚æœæ‰€æœ‰å€™é€‰äººä½¿ç”¨ç›¸åŒåœ°ç‚¹å’Œæ—¶é—´ï¼Œå¯ä»¥åœ¨è¿™é‡Œè®¾ç½®ï¼‰
        st.markdown("---")
        st.markdown("### ğŸŒ ç»Ÿä¸€é¢è¯•è®¾ç½®ï¼ˆå¯é€‰ï¼‰")
        st.info("ğŸ’¡ å¦‚æœæ‰€æœ‰å€™é€‰äººä½¿ç”¨ç›¸åŒçš„æ—¶é—´å’Œåœ°ç‚¹ï¼Œå¯ä»¥åœ¨è¿™é‡Œç»Ÿä¸€è®¾ç½®ï¼Œå°†è¦†ç›–ä¸Šè¿°å•ç‹¬è®¾ç½®")
        
        # æ˜¯å¦å¯ç”¨ç»Ÿä¸€é¢è¯•æ—¶é—´
        use_unified_time = st.checkbox("âœ… ä½¿ç”¨ç»Ÿä¸€é¢è¯•æ—¶é—´", value=False, help="å‹¾é€‰åï¼Œæ‰€æœ‰å€™é€‰äººå°†ä½¿ç”¨ç›¸åŒçš„é¢è¯•æ—¶é—´")
        
        # ç»Ÿä¸€é¢è¯•æ—¶é—´ï¼ˆä»…åœ¨å¯ç”¨æ—¶æ˜¾ç¤ºï¼‰
        unified_interview_time_str = None
        if use_unified_time:
            col_unified_date, col_unified_time = st.columns(2)
            with col_unified_date:
                unified_date_key = "unified_interview_date"
                prev_unified_date = st.session_state.get(unified_date_key, default_date)
                unified_interview_date = st.date_input(
                    "ğŸ“… ç»Ÿä¸€é¢è¯•æ—¥æœŸ",
                    value=prev_unified_date,
                    key=unified_date_key,
                    help="å°†åº”ç”¨äºæ‰€æœ‰å€™é€‰äºº",
                    label_visibility="visible"
                )
            with col_unified_time:
                unified_time_key = "unified_interview_time"
                prev_unified_time = st.session_state.get(unified_time_key, default_time)
                unified_interview_hour = st.time_input(
                    "â° ç»Ÿä¸€é¢è¯•æ—¶é—´",
                    value=prev_unified_time,
                    key=unified_time_key,
                    help="å°†åº”ç”¨äºæ‰€æœ‰å€™é€‰äºº",
                    label_visibility="visible"
                )
            
            # æ ¼å¼åŒ–ç»Ÿä¸€é¢è¯•æ—¶é—´å­—ç¬¦ä¸²
            unified_interview_datetime = datetime.combine(unified_interview_date, unified_interview_hour)
            unified_interview_time_str = f"{unified_interview_datetime.strftime('%Y-%m-%d %H:%M')}, {timezone}"
        
        # ç»Ÿä¸€é¢è¯•åœ°ç‚¹
        interview_location = st.text_input("ğŸ“ ç»Ÿä¸€é¢è¯•åœ°ç‚¹ï¼ˆå¯é€‰ï¼Œå¦‚ä¸ºç©ºåˆ™ä½¿ç”¨ä¸Šè¿°å•ç‹¬è®¾ç½®çš„åœ°ç‚¹ï¼‰", value="", help="å¦‚æœæ‰€æœ‰å€™é€‰äººä½¿ç”¨ç›¸åŒåœ°ç‚¹ï¼Œå¯ä»¥åœ¨è¿™é‡Œç»Ÿä¸€è®¾ç½®")
        
        organizer_email = st.text_input("ğŸ“§ é¢è¯•ç»„ç»‡è€…é‚®ç®±", value=os.getenv("SMTP_USER", "hr@company.com"))
        
        # ä¼ä¸šå¾®ä¿¡é…ç½®ï¼ˆå¯é€‰ï¼‰
        with st.expander("ğŸ“± ä¼ä¸šå¾®ä¿¡é…ç½®ï¼ˆå¯é€‰ï¼‰"):
            organizer_name = st.text_input("ç»„ç»‡è€…å§“å", "HR", help="ç”¨äºä¼ä¸šå¾®ä¿¡æ¶ˆæ¯ä¸­çš„è”ç³»äººæ˜¾ç¤º", key="organizer_name")
            organizer_wechat = st.text_input("ç»„ç»‡è€…ä¼ä¸šå¾®ä¿¡ID", "", help="å¯é€‰ï¼Œç”¨äºç”Ÿæˆä¼ä¸šå¾®ä¿¡æ·»åŠ é“¾æ¥", key="organizer_wechat")
            meeting_link = st.text_input("ä¼šè®®é“¾æ¥ï¼ˆå¯é€‰ï¼‰", "", help="å¦‚ï¼šè…¾è®¯ä¼šè®®é“¾æ¥ã€Zoomé“¾æ¥ç­‰", key="meeting_link")

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç”Ÿæˆçš„é‚®ä»¶
        existing_invites = st.session_state.get("invite_results", [])
        show_existing = False
        if existing_invites and len(existing_invites) > 0:
            st.info(f"ğŸ’¡ æ£€æµ‹åˆ°å·²æœ‰ {len(existing_invites)} å°å·²ç”Ÿæˆçš„é‚®ä»¶ï¼Œæ‚¨å¯ä»¥ç»§ç»­ç¼–è¾‘æˆ–ç›´æ¥å‘é€ã€‚å¦‚éœ€é‡æ–°ç”Ÿæˆï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ã€‚")
            show_existing = True

        if st.button("ğŸš€ ä¸€é”®ç”Ÿæˆé‚€çº¦é‚®ä»¶ + ICS"):
            # è·å–ä¼ä¸šå¾®ä¿¡é…ç½®ï¼ˆå¦‚æœæœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
            organizer_name = st.session_state.get("organizer_name", "HR")
            organizer_wechat = st.session_state.get("organizer_wechat", "")
            meeting_link = st.session_state.get("meeting_link", "")
            st.info("AI æ­£åœ¨ç”Ÿæˆä¸ªæ€§åŒ–é‚€çº¦å†…å®¹ï¼Œè¯·ç¨å€™...")

            invite_results = []
            invites_dir = "reports/invites"
            os.makedirs(invites_dir, exist_ok=True)

            job_title = st.session_state.get("job_name") or "ç›®æ ‡å²—ä½"

            # ç”Ÿæˆé»˜è®¤é¢è¯•æ—¶é—´ä½œä¸ºfallback
            default_interview_datetime = datetime.combine(default_date, default_time)
            default_interview_time_str = f"{default_interview_datetime.strftime('%Y-%m-%d %H:%M')}, {timezone}"

            for idx, (_, row) in enumerate(selected_candidates.iterrows()):
                row_dict = row.to_dict()
                # ä¼˜å…ˆä½¿ç”¨nameå­—æ®µï¼ˆå§“åï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨fileå­—æ®µï¼ˆæ–‡ä»¶åï¼‰ï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
                candidate_name_raw = row_dict.get("name") or row_dict.get("file") or "åŒ¿åå€™é€‰äºº"
                # æ·»åŠ å…ˆç”Ÿ/å¥³å£«ç§°å‘¼
                candidate_name = add_name_title(candidate_name_raw, row_dict)
                candidate_email = row_dict.get("email", "")
                candidate_score = row_dict.get("æ€»åˆ†") or row_dict.get("score_total") or row_dict.get("score", "æœªçŸ¥")

                # è·å–è¯¥å€™é€‰äººçš„é¢è¯•æ—¶é—´å’Œåœ°ç‚¹
                # å¦‚æœå¯ç”¨äº†ç»Ÿä¸€æ—¶é—´ï¼Œä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€æ—¶é—´ï¼›å¦åˆ™ä½¿ç”¨å€™é€‰äººå•ç‹¬è®¾ç½®çš„æ—¶é—´
                if use_unified_time and unified_interview_time_str:
                    candidate_interview_time = unified_interview_time_str
                else:
                    candidate_interview_time = candidate_interview_times.get(idx, default_interview_time_str)
                
                # å¦‚æœè®¾ç½®äº†ç»Ÿä¸€åœ°ç‚¹ï¼Œä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€åœ°ç‚¹ï¼›å¦åˆ™ä½¿ç”¨å€™é€‰äººå•ç‹¬è®¾ç½®çš„åœ°ç‚¹
                if interview_location and interview_location.strip():
                    candidate_interview_location = interview_location
                else:
                    candidate_interview_location = candidate_interview_locations.get(idx, default_location)

                try:
                    candidate_highlight = generate_ai_summary(row_dict)
                except Exception as e:
                    candidate_highlight = f"AI æ€»ç»“å¤±è´¥ï¼š{e}"

                try:
                    # ç”ŸæˆICSæ–‡ä»¶æè¿°
                    ics_description = f"è¯·å‡†æ—¶å‚åŠ é¢è¯•ã€‚å¦‚éœ€è°ƒæ•´æ—¶é—´è¯·åŠæ—¶è”ç³»HRã€‚\nå²—ä½ï¼š{job_title}\né¢è¯•åœ°ç‚¹ï¼š{candidate_interview_location or 'å¾…ç¡®è®¤'}"
                    ics_path = create_ics_file(
                        title=f"{job_title}å²—ä½é¢è¯•",
                        start_time=candidate_interview_time,
                        organizer=organizer_email,
                        attendee=candidate_email or "candidate@example.com",
                        location=candidate_interview_location or "",
                        description=ics_description,
                    )
                except Exception as e:
                    st.warning(f"ç”Ÿæˆ {candidate_name} çš„æ—¥å†æ–‡ä»¶å¤±è´¥ï¼š{e}")
                    ics_path = ""

                try:
                    email_body = generate_ai_email(
                        name=candidate_name,
                        highlights=candidate_highlight,
                        position=job_title,
                        score=candidate_score,
                        ics_path=ics_path or "(é™„ä»¶ç”Ÿæˆå¤±è´¥)",
                    )
                    # åœ¨é‚®ä»¶æ­£æ–‡ä¸­æ·»åŠ é¢è¯•åœ°ç‚¹ä¿¡æ¯
                    if candidate_interview_location and candidate_interview_location.strip():
                        location_note = f"\n\nğŸ“ é¢è¯•åœ°ç‚¹ï¼š{candidate_interview_location}"
                        email_body = email_body + location_note
                except Exception as e:
                    email_body = f"AI é‚®ä»¶ç”Ÿæˆå¤±è´¥ï¼š{e}"

                # ç”Ÿæˆé‚®ä»¶ä¸»é¢˜ï¼šå…³äº {å§“å} åº”è˜ {å²—ä½} çš„é¢è¯•å®‰æ’é€šçŸ¥
                email_subject = f"å…³äº {candidate_name} åº”è˜ {job_title} çš„é¢è¯•å®‰æ’é€šçŸ¥"

                invite_results.append(
                    {
                        "candidate_id": str(row_dict.get("candidate_id") or row_dict.get("åºå·") or row_dict.get("id") or ""),
                        "file": row_dict.get("file"),
                        "name": candidate_name,
                        "email": candidate_email,
                        "ics": ics_path,
                        "body": email_body,
                        "subject": email_subject,
                        "highlights": candidate_highlight,
                        "score": candidate_score,
                        "position": job_title,
                        "interview_time": candidate_interview_time,
                        "interview_location": candidate_interview_location,
                        "email_sent": False,
                        "email_sent_at": "",
                        "email_status": "",
                        "wechat_sent": False,
                    }
                )

            json_payload = json.dumps(invite_results, ensure_ascii=False, indent=2)
            json_path = os.path.join(invites_dir, f"invite_batch_{datetime.now().strftime('%Y%m%d_%H%M')}.json")
            with open(json_path, "w", encoding="utf-8") as fp:
                fp.write(json_payload)

            st.success("âœ… AI ä¸ªæ€§åŒ–é‚€çº¦ç”Ÿæˆå®Œæˆï¼")
            
            # ä¿å­˜åˆ°session_stateï¼Œä¾›åç»­ç¼–è¾‘å’Œå‘é€ä½¿ç”¨
            st.session_state["invite_results"] = invite_results
            st.session_state["job_title"] = job_title
            # ä¿å­˜æ¯ä¸ªå€™é€‰äººçš„é¢è¯•æ—¶é—´é…ç½®ï¼ˆç”¨äºåç»­ç¼–è¾‘ï¼‰
            st.session_state["candidate_interview_times"] = candidate_interview_times
            st.session_state["candidate_interview_locations"] = candidate_interview_locations
        
        # æ˜¾ç¤ºé‚®ä»¶é¢„è§ˆå’Œç¼–è¾‘åŠŸèƒ½ï¼ˆæ— è®ºæ˜¯æ–°ç”Ÿæˆè¿˜æ˜¯å·²æœ‰é‚®ä»¶ï¼‰
        invite_results = st.session_state.get("invite_results", [])
        if invite_results and len(invite_results) > 0:
            job_title = st.session_state.get("job_title", "ç›®æ ‡å²—ä½")
            # interview_time å’Œ interview_location åœ¨å·²æœ‰é‚®ä»¶æ—¶ä»session_stateè·å–ï¼Œæ–°ç”Ÿæˆæ—¶ä½¿ç”¨ä¸Šé¢çš„å€¼
            default_interview_time = f"{datetime.combine(datetime.now().date() + timedelta(days=1), datetime.strptime('14:00', '%H:%M').time()).strftime('%Y-%m-%d %H:%M')}, {timezone}"
            interview_time = st.session_state.get("interview_time", default_interview_time)
            interview_location = st.session_state.get("interview_location", "å…¬å¸ä¼šè®®å®¤ï¼ˆå…·ä½“åœ°å€å¾…ç¡®è®¤ï¼‰")
            
            # é‚®ä»¶é¢„è§ˆå’Œç¼–è¾‘åŠŸèƒ½
            st.markdown("### ğŸ“§ é‚®ä»¶é¢„è§ˆä¸ç¼–è¾‘")
            st.info("ğŸ’¡ åœ¨å‘é€å‰ï¼Œæ‚¨å¯ä»¥é¢„è§ˆå’Œç¼–è¾‘æ¯å°é‚®ä»¶çš„å†…å®¹")
            
            for idx, invite in enumerate(invite_results):
                with st.expander(f"ğŸ“§ {invite.get('name', f'å€™é€‰äºº{idx+1}')} - {invite.get('email', '')}", expanded=(idx == 0)):
                    col_preview1, col_preview2 = st.columns([2, 1])
                    
                    with col_preview1:
                        st.markdown("**é‚®ä»¶ä¸»é¢˜ï¼š**")
                        subject_key = f"subject_{idx}"
                        # æ™ºèƒ½è¯†åˆ«å²—ä½å’Œå§“åï¼šä¼˜å…ˆä½¿ç”¨inviteä¸­çš„positionå’Œnameï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨job_titleå’Œé»˜è®¤å€¼
                        position_for_subject = invite.get("position", job_title)
                        candidate_name_for_subject = invite.get("name", "æ‚¨")
                        email_subject = st.text_input(
                            "ä¸»é¢˜",
                            value=invite.get("subject", f"å…³äº {candidate_name_for_subject} åº”è˜ {position_for_subject} çš„é¢è¯•å®‰æ’é€šçŸ¥"),
                            key=subject_key,
                            label_visibility="collapsed"
                        )
                        
                        st.markdown("**é‚®ä»¶æ­£æ–‡ï¼š**")
                        body_key = f"body_{idx}"
                        edited_body = st.text_area(
                            "æ­£æ–‡",
                            value=invite.get("body", ""),
                            height=300,
                            key=body_key,
                            label_visibility="collapsed"
                        )
                        
                        # æ›´æ–°invite_resultsä¸­çš„å†…å®¹
                        invite_results[idx]["body"] = edited_body
                        invite_results[idx]["subject"] = email_subject
                    
                    with col_preview2:
                        st.markdown("**é‚®ä»¶ä¿¡æ¯ï¼š**")
                        st.write(f"ğŸ“§ **æ”¶ä»¶äººï¼š** {invite.get('email', 'æœªæä¾›')}")
                        st.write(f"ğŸ“… **é¢è¯•æ—¶é—´ï¼š** {invite.get('interview_time', 'æœªè®¾ç½®')}")
                        st.write(f"ğŸ“ **é¢è¯•åœ°ç‚¹ï¼š** {invite.get('interview_location', 'æœªè®¾ç½®')}")
                        st.write(f"ğŸ’¼ **å²—ä½ï¼š** {invite.get('position', 'æœªè®¾ç½®')}")
                        st.write(f"â­ **è¯„åˆ†ï¼š** {invite.get('score', 'æœªçŸ¥')}")
                        
                        if invite.get("ics"):
                            st.success("âœ… æ—¥å†é™„ä»¶å·²ç”Ÿæˆ")
                        else:
                            st.warning("âš ï¸ æ—¥å†é™„ä»¶æœªç”Ÿæˆ")
                        
                        st.markdown("**äº®ç‚¹æ‘˜è¦ï¼š**")
                        st.caption(invite.get("highlights", "æ— ")[:200])
            
            # æ›´æ–°session_stateä¸­çš„ç¼–è¾‘åå†…å®¹
            st.session_state["invite_results"] = invite_results
            
            # ä¿å­˜JSONæ–‡ä»¶
            json_payload = json.dumps(invite_results, ensure_ascii=False, indent=2)
            json_path = os.path.join("reports/invites", f"invite_batch_{datetime.now().strftime('%Y%m%d_%H%M')}.json")
            os.makedirs("reports/invites", exist_ok=True)
            with open(json_path, "w", encoding="utf-8") as fp:
                fp.write(json_payload)
            
            # ä¼ä¸šå¾®ä¿¡é›†æˆ
            st.markdown("### ğŸ“± ä¼ä¸šå¾®ä¿¡é‚€çº¦")
            try:
                from backend.services.wechat_integration import create_wechat_invite_template
                
                wechat_results = []
                for invite in invite_results:
                    wechat_data = create_wechat_invite_template({
                        "name": invite.get("name", ""),
                        "email": invite.get("email", ""),
                        "position": invite.get("position", job_title),
                        "interview_time": invite.get("interview_time", interview_time),
                        "highlights": invite.get("highlights", ""),
                        "meeting_link": meeting_link,
                        "organizer_name": organizer_name,
                        "organizer_wechat": organizer_wechat,
                    })
                    wechat_results.append(wechat_data)
                
                # æ˜¾ç¤ºä¼ä¸šå¾®ä¿¡æ¶ˆæ¯ï¼ˆå¯å¤åˆ¶ï¼‰
                for idx, (invite, wechat_data) in enumerate(zip(invite_results, wechat_results)):
                    with st.expander(f"ğŸ“± {invite.get('name', f'å€™é€‰äºº{idx+1}')} - ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯"):
                        st.text_area(
                            "ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯å†…å®¹ï¼ˆç‚¹å‡»å¤åˆ¶ï¼‰",
                            value=wechat_data.get("wechat_message", ""),
                            height=200,
                            key=f"wechat_msg_{idx}",
                            help="å¤åˆ¶æ­¤å†…å®¹åˆ°ä¼ä¸šå¾®ä¿¡å‘é€ç»™å€™é€‰äºº"
                        )
                        if wechat_data.get("meeting_link"):
                            st.write(f"ğŸ”— ä¼šè®®é“¾æ¥ï¼š{wechat_data.get('meeting_link')}")
                        if wechat_data.get("wechat_link"):
                            st.write(f"ğŸ“± {wechat_data.get('wechat_link')}")
            except Exception as e:
                st.info(f"ğŸ’¡ ä¼ä¸šå¾®ä¿¡åŠŸèƒ½ï¼š{str(e)}")
            
            # é‚®ä»¶å¯¼å…¥ä¼ä¸šé‚®ç®±
            st.markdown("### ğŸ“§ é‚®ä»¶å¯¼å…¥ä¼ä¸šé‚®ç®±")
            col1, col2 = st.columns(2)
            
            with col1:
                try:
                    from backend.services.email_integration import generate_email_import_file, generate_outlook_import_csv
                    
                    if st.button("ğŸ“¥ ç”Ÿæˆé‚®ä»¶å¯¼å…¥æ–‡ä»¶ï¼ˆ.emlï¼‰"):
                        with st.spinner("æ­£åœ¨ç”Ÿæˆé‚®ä»¶å¯¼å…¥æ–‡ä»¶..."):
                            import_path = generate_email_import_file(invite_results)
                            if import_path:
                                st.success(f"âœ… é‚®ä»¶æ–‡ä»¶å·²ç”Ÿæˆï¼š`{import_path}`")
                                st.info("ğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼š\n1. Outlookï¼šæ–‡ä»¶ -> æ‰“å¼€ -> å…¶ä»–æ–‡ä»¶ -> é€‰æ‹© .eml æ–‡ä»¶\n2. ä¼ä¸šé‚®ç®±ï¼šè®¾ç½® -> å¯¼å…¥é‚®ä»¶ -> é€‰æ‹© .eml æ–‡ä»¶")
                            else:
                                st.warning("âš ï¸ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®")
                except Exception as e:
                    st.warning(f"é‚®ä»¶å¯¼å…¥åŠŸèƒ½ï¼š{str(e)}")
            
            with col2:
                try:
                    if st.button("ğŸ“‹ ç”ŸæˆOutlookå¯¼å…¥CSV"):
                        with st.spinner("æ­£åœ¨ç”ŸæˆCSVæ–‡ä»¶..."):
                            csv_path = generate_outlook_import_csv(invite_results)
                            if csv_path:
                                with open(csv_path, 'rb') as f:
                                    st.download_button(
                                        "â¬‡ï¸ ä¸‹è½½Outlookå¯¼å…¥CSV",
                                        data=f.read(),
                                        file_name=os.path.basename(csv_path),
                                        mime="text/csv"
                                    )
                                st.success(f"âœ… CSVæ–‡ä»¶å·²ç”Ÿæˆï¼š`{csv_path}`")
                except Exception as e:
                    st.warning(f"CSVç”ŸæˆåŠŸèƒ½ï¼š{str(e)}")
            
            # SMTPé‚®ä»¶å‘é€ï¼ˆå¯é€‰ï¼‰
            with st.expander("ğŸ“® é€šè¿‡SMTPç›´æ¥å‘é€é‚®ä»¶ï¼ˆéœ€è¦é…ç½®ï¼‰", expanded=True):
                st.info("ğŸ’¡ éœ€è¦åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹å‚æ•°ï¼š\n- SMTP_SERVERï¼ˆå¦‚ï¼šsmtp.exmail.qq.comï¼‰\n- SMTP_PORTï¼ˆé»˜è®¤587ï¼‰\n- SMTP_USERï¼ˆé‚®ç®±åœ°å€ï¼‰\n- SMTP_PASSWORDï¼ˆé‚®ç®±å¯†ç æˆ–æˆæƒç ï¼‰")
                
                smtp_server = st.text_input("SMTPæœåŠ¡å™¨", os.getenv("SMTP_SERVER", ""), help="å¦‚ï¼šsmtp.exmail.qq.com")
                smtp_port = st.number_input("SMTPç«¯å£", value=int(os.getenv("SMTP_PORT", "587")), min_value=1, max_value=65535)
                smtp_user = st.text_input("SMTPç”¨æˆ·åï¼ˆé‚®ç®±ï¼‰", os.getenv("SMTP_USER", ""))
                smtp_password = st.text_input("SMTPå¯†ç /æˆæƒç ", type="password", value=os.getenv("SMTP_PASSWORD", ""))
                
                # å‘é€å‰ç¡®è®¤
                if st.button("ğŸ“¤ æ‰¹é‡å‘é€é‚®ä»¶", type="primary"):
                    if not smtp_server or not smtp_user or not smtp_password:
                        st.error("âŒ è¯·å…ˆé…ç½®SMTPå‚æ•°")
                    elif not invite_results:
                        st.error("âŒ æ²¡æœ‰å¯å‘é€çš„é‚®ä»¶ï¼Œè¯·å…ˆç”Ÿæˆé‚€çº¦é‚®ä»¶")
                    else:
                        try:
                            from backend.services.email_integration import send_email_via_smtp
                            
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            success_count = 0
                            fail_count = 0
                            send_results = []
                            
                            total = len(invite_results)
                            for idx, invite in enumerate(invite_results):
                                candidate_name = invite.get("name", f"å€™é€‰äºº{idx+1}")
                                candidate_email = invite.get("email", "")
                                
                                # æ›´æ–°è¿›åº¦
                                progress = (idx + 1) / total
                                progress_bar.progress(progress)
                                status_text.text(f"æ­£åœ¨å‘é€ ({idx + 1}/{total}): {candidate_name} ({candidate_email})")
                                
                                # è·å–ç¼–è¾‘åçš„é‚®ä»¶å†…å®¹ï¼Œæ™ºèƒ½è¯†åˆ«å²—ä½å’Œå§“å
                                position_for_subject = invite.get("position", job_title)
                                candidate_name_for_subject = invite.get("name", "æ‚¨")
                                email_subject = invite.get("subject", f"å…³äº {candidate_name_for_subject} åº”è˜ {position_for_subject} çš„é¢è¯•å®‰æ’é€šçŸ¥")
                                email_body = invite.get("body", "")
                                
                                if not candidate_email or not candidate_email.strip():
                                    result = {
                                        "success": False,
                                        "message": "æ”¶ä»¶äººé‚®ç®±ä¸ºç©º"
                                    }
                                else:
                                    result = send_email_via_smtp(
                                        to_email=candidate_email,
                                        subject=email_subject,
                                        body=email_body,
                                        ics_path=invite.get("ics", ""),
                                        smtp_server=smtp_server,
                                        smtp_port=smtp_port,
                                        smtp_user=smtp_user,
                                        smtp_password=smtp_password,
                                        from_email=smtp_user
                                    )
                                
                                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                                invite["email_sent"] = result.get("success", False)
                                invite["email_sent_at"] = timestamp if result.get("success") else ""
                                invite["email_status"] = result.get("message", "")
                                send_results.append({
                                    "name": candidate_name,
                                    "email": candidate_email,
                                    "success": result.get("success", False),
                                    "message": result.get("message", "")
                                })
                                
                                if result.get("success"):
                                    success_count += 1
                                else:
                                    fail_count += 1
                            
                            progress_bar.empty()
                            status_text.empty()
                            
                            # æ˜¾ç¤ºå‘é€ç»“æœ
                            st.markdown("### ğŸ“Š å‘é€ç»“æœ")
                            if success_count > 0:
                                st.success(f"âœ… æˆåŠŸå‘é€ {success_count} å°é‚®ä»¶")
                            if fail_count > 0:
                                st.error(f"âŒ å‘é€å¤±è´¥ {fail_count} å°é‚®ä»¶")
                            
                            # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                            with st.expander("ğŸ“‹ è¯¦ç»†å‘é€ç»“æœ", expanded=(fail_count > 0)):
                                for result in send_results:
                                    if result["success"]:
                                        st.success(f"âœ… {result['name']} ({result['email']}) - å‘é€æˆåŠŸ")
                                    else:
                                        st.error(f"âŒ {result['name']} ({result['email']}) - {result['message']}")
                            
                            # ä¿å­˜å‘é€ç»“æœ
                            st.session_state["send_results"] = send_results
                            st.session_state["invite_results"] = invite_results
                            
                        except Exception as e:
                            st.error(f"âŒ å‘é€å¤±è´¥ï¼š{str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
            
            st.download_button(
                "ğŸ“¥ ä¸‹è½½é‚€çº¦ç»“æœï¼ˆJSONï¼‰",
                data=json_payload,
                file_name="ai_invites.json",
                mime="application/json",
            )

            # ä¿å­˜å¾…é¢è¯•æ¸…å•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
            pending_path = "reports/pending_interviews.csv"
            try:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                import os
                os.makedirs("reports", exist_ok=True)
                
                # å°è¯•å†™å…¥æ–‡ä»¶
                pd.DataFrame(invite_results).to_csv(pending_path, index=False, encoding="utf-8-sig")
                st.write(f"ğŸ“‹ å·²è‡ªåŠ¨æ›´æ–°å¾…é¢è¯•æ¸…å•ï¼š`{pending_path}`")
            except PermissionError:
                # å¦‚æœæ–‡ä»¶è¢«å ç”¨ï¼ˆå¦‚ Excel æ‰“å¼€ï¼‰ï¼Œä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                pending_path_alt = f"reports/pending_interviews_{timestamp}.csv"
                try:
                    pd.DataFrame(invite_results).to_csv(pending_path_alt, index=False, encoding="utf-8-sig")
                    st.warning(f"âš ï¸ åŸæ–‡ä»¶è¢«å ç”¨ï¼Œå·²ä¿å­˜åˆ°ï¼š`{pending_path_alt}`")
                    st.info("ğŸ’¡ æç¤ºï¼šè¯·å…³é—­å¯èƒ½æ­£åœ¨æ‰“å¼€ `pending_interviews.csv` çš„ç¨‹åºï¼ˆå¦‚ Excelï¼‰")
                except Exception as e:
                    st.warning(f"âš ï¸ ä¿å­˜å¾…é¢è¯•æ¸…å•å¤±è´¥ï¼š{str(e)}")
            except Exception as e:
                st.warning(f"âš ï¸ ä¿å­˜å¾…é¢è¯•æ¸…å•å¤±è´¥ï¼š{str(e)}")

            st.json(invite_results, expanded=False)

with tab5:
    st.subheader("é¢è¯•åŒ… & å¯¼å‡ºæŠ¥è¡¨")
    if st.button("å¯¼å‡ºæœ¬è½®æŠ¥è¡¨"):
        score_df = st.session_state.get("score_df", None)
        scored_df = st.session_state.get("scored", None)

        if score_df is not None and not score_df.empty:
            score_source = score_df
        elif scored_df is not None and not scored_df.empty:
            score_source = scored_df
        else:
            st.warning("æœªæ‰¾åˆ°å¯å¯¼å‡ºçš„è¯„åˆ†æ•°æ®ï¼Œè¯·å…ˆå®Œæˆ AI åŒ¹é…è¯„åˆ†ã€‚")
            st.stop()

        job_meta = st.session_state.get("job_meta", {})
        shortlist = st.session_state.get("shortlist")
        topn_ids = st.session_state.get("topn_ids", []) or []
        if (not topn_ids) and shortlist is not None and not shortlist.empty:
            if "candidate_id" in shortlist.columns:
                topn_ids = shortlist["candidate_id"].astype(str).tolist()
            elif "åºå·" in shortlist.columns:
                topn_ids = shortlist["åºå·"].astype(str).tolist()
        invite_results = st.session_state.get("invite_results", [])
        communication_meta = _build_invite_lookup(invite_results)
        round_meta = {
            "topn_cutoff": len(topn_ids) or st.session_state.get("topn_limit"),
            "topn_ids": topn_ids,
        }
        path = export_round_report(
            score_source,
            job_meta=job_meta,
            round_meta=round_meta,
            communication_meta=communication_meta,
        )
        st.success("å·²å¯¼å‡ºï¼š" + path)

