import json
import os
import re
import time

import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
from pathlib import Path
from backend.storage.db import init_db, get_db
from backend.services.pipeline import RecruitPipeline
from backend.services.reporting import export_round_report
from backend.utils.versioning import VersionManager
from backend.utils.field_mapping import translate_dataframe_columns, translate_field
# å¼ºåˆ¶é‡æ–°åŠ è½½æ¨¡å—ï¼Œé¿å…ç¼“å­˜é—®é¢˜
import importlib
import sys
if 'backend.services.jd_ai' in sys.modules:
    importlib.reload(sys.modules['backend.services.jd_ai'])
from backend.services.jd_ai import generate_jd_bundle, construct_full_ability_list
from backend.services.resume_parser import parse_uploaded_files_to_df
# ğŸ”„ ç¡®ä¿ AI åŒ¹é…é€»è¾‘æ›´æ–°æ—¶ç«‹å³ç”Ÿæ•ˆ
if 'backend.services.ai_matcher' in sys.modules:
    importlib.reload(sys.modules['backend.services.ai_matcher'])
from backend.services.ai_matcher import ai_match_resumes_df
from backend.services.ai_core import generate_ai_summary, generate_ai_email
# ğŸ”„ å¼ºåˆ¶é‡æ–°åŠ è½½æ—¥å†å·¥å…·æ¨¡å—ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬
if 'backend.services.calendar_utils' in sys.modules:
    importlib.reload(sys.modules['backend.services.calendar_utils'])
# åˆ é™¤å¯èƒ½å­˜åœ¨çš„æ—§å¯¼å…¥
if 'create_ics_file' in globals():
    del create_ics_file
from backend.services.calendar_utils import create_ics_file

def add_name_title(name: str, row_dict: dict = None) -> str:
    """
    ç»™å§“åæ·»åŠ å…ˆç”Ÿ/å¥³å£«ç§°å‘¼
    
    Args:
        name: å€™é€‰äººå§“å
        row_dict: å€™é€‰äººæ•°æ®å­—å…¸ï¼ˆå¯é€‰ï¼Œç”¨äºæå–æ€§åˆ«ä¿¡æ¯ï¼‰
    
    Returns:
        å¸¦ç§°å‘¼çš„å§“åï¼Œå¦‚"å¼ ä¸‰å…ˆç”Ÿ"æˆ–"æå››å¥³å£«"
    """
    if not name or name == "åŒ¿åå€™é€‰äºº":
        return "å…ˆç”Ÿ/å¥³å£«"
    
    # å°è¯•ä»æ•°æ®ä¸­æå–æ€§åˆ«ä¿¡æ¯
    gender = None
    if row_dict:
        # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„å­—æ®µä¸­æå–æ€§åˆ«
        gender_text = str(row_dict.get("gender", "") or row_dict.get("æ€§åˆ«", "") or "").strip()
        if "å¥³" in gender_text:
            gender = "å¥³"
        elif "ç”·" in gender_text:
            gender = "ç”·"
    
    # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„æ€§åˆ«ä¿¡æ¯ï¼Œå°è¯•ä»å§“ååˆ¤æ–­ï¼ˆç®€å•è§„åˆ™ï¼‰
    if not gender:
        # å¸¸è§å¥³æ€§åå­—ç‰¹å¾ï¼ˆç®€å•åˆ¤æ–­ï¼Œä¸å‡†ç¡®ä½†å¯ç”¨ï¼‰
        female_name_chars = ["éœ", "èŠ³", "å¨œ", "æ•", "é™", "ä¸½", "è‰³", "çº¢", "ç²", "é›ª", "æ¢…", "å…°", "èŠ", "è²", "èŠ±", "æœˆ", "æ˜¥", "ç§‹", "å†¬", "ç¾", "ç§€", "è‹±", "å", "æ…§", "å¨Ÿ", "è‰", "è", "ç‡•", "å‡¤", "å©·", "æ¬£", "æ‚¦", "æ€¡", "ç³", "è¹", "é›¯", "é›…", "æ´", "å€©", "è–‡", "èŒœ", "è“‰", "è²", "ç‘¶", "ç’", "ç‘¾", "ç’‡", "ç’", "ç’", "ç’"]
        # å¦‚æœåå­—æœ€åä¸€ä¸ªå­—åœ¨å¥³æ€§åå­—ç‰¹å¾ä¸­ï¼Œä½¿ç”¨"å¥³å£«"
        if len(name) >= 2 and name[-1] in female_name_chars:
            gender = "å¥³"
        else:
            # é»˜è®¤ä½¿ç”¨"å…ˆç”Ÿ"
            gender = "ç”·"
    
    return f"{name}{'å¥³å£«' if gender == 'å¥³' else 'å…ˆç”Ÿ'}"
# from backend.services.excel_exporter import generate_competency_excel, export_ability_sheet_to_file  # å‡½æ•°ä¸å­˜åœ¨ï¼Œå·²æ³¨é‡Š

# å¼ºåˆ¶é‡æ–°åŠ è½½ Excel å¯¼å‡ºæ¨¡å—ï¼Œç¡®ä¿æ¨¡æ¿æ ·å¼è°ƒæ•´åå‰ç«¯ç«‹å³ç”Ÿæ•ˆ
if 'backend.services.export_excel' in sys.modules:
    importlib.reload(sys.modules['backend.services.export_excel'])
from backend.services.export_excel import export_competency_excel
from dotenv import load_dotenv

# å°è¯•ä»å¤šä¸ªä½ç½®åŠ è½½.envæ–‡ä»¶
env_paths = [
    Path('.env'),  # å½“å‰ç›®å½•ï¼ˆapp/ï¼‰
    Path('../.env'),  # é¡¹ç›®æ ¹ç›®å½•
    Path(__file__).parent.parent / '.env',  # é¡¹ç›®æ ¹ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼‰
]
for env_path in env_paths:
    if env_path.exists():
        load_dotenv(dotenv_path=env_path)
        break
else:
    load_dotenv()  # é»˜è®¤åŠ è½½

# --- session åˆå§‹åŒ–ï¼ˆæ”¾åœ¨ import ä¹‹åï¼‰---
if "ai_bundle" not in st.session_state:
    st.session_state["ai_bundle"] = None

# ============ æ§åˆ¶æ˜¾ç¤ºéƒ¨åˆ† ============
SHOW_OFFLINE_SECTION = False   # æ˜¯å¦æ˜¾ç¤ºâ€œç¦»çº¿è§„åˆ™ç‰ˆâ€
SHOW_DETAIL_SECTIONS = True   # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†éƒ¨åˆ†ï¼ˆé•¿ç‰ˆJD / å²—ä½èƒ½åŠ›ç»´åº¦ / é¢è¯•é¢˜ç­‰ï¼‰
# =====================================

st.set_page_config(page_title="RecruitFlow | ä¸€é”®æ‹›è˜æµæ°´çº¿", layout="wide")
st.title("RecruitFlow â€” ä¸€é”®æ‹›è˜æµæ°´çº¿ï¼ˆæ•™è‚²æœºæ„ç‰ˆï¼‰")

def sanitize_single_line(text, default="æœªæä¾›ç›¸å…³ä¿¡æ¯", limit=None):
    if text is None:
        return default
    cleaned = str(text).replace("\r", " ").replace("\n", "ï¼›")
    cleaned = re.sub(r"\s+", " ", cleaned)
    cleaned = (
        cleaned.replace(",", "ï¼Œ")
        .replace(";", "ï¼›")
        .replace("|", "ï½œ")
        .strip(" ï¼›")
    )
    if not cleaned:
        cleaned = default
    if limit and len(cleaned) > limit:
        cleaned = cleaned[:limit].rstrip("ï¼› ï¼Œ") + "..."
    return cleaned


def _clean_single_line(text, default="æœªæä¾›", limit=None):
    return sanitize_single_line(text, default, limit)


def _format_highlights_for_export(row_dict):
    tags = []
    raw = row_dict.get("highlights")
    if isinstance(raw, str):
        tags = [seg.strip() for seg in re.split(r"[ï½œ|ï¼Œ,ã€ï¼›\s]+", raw) if seg.strip()]
    elif isinstance(raw, list):
        tags = [str(seg).strip() for seg in raw if str(seg).strip()]

    if len(tags) < 2:
        strengths_text = row_dict.get("short_eval", "")
        if strengths_text:
            candidates = [seg.strip(" ï¼›;") for seg in re.split(r"[ï½œ|ï¼Œ,ã€ï¼›\s]+", strengths_text) if seg.strip()]
            for item in candidates:
                if len(item) <= 8:
                    tags.append(item)
                if len(tags) >= 3:
                    break

    tags = [tag for tag in tags if tag][:3]
    if len(tags) == 1:
        tags.append("ç»¼åˆèƒ½åŠ›")
    return "ï½œ".join(tags) if tags else "æœªæä¾›"


def _safe_load_json(value):
    if isinstance(value, dict):
        return value
    if isinstance(value, str):
        try:
            return json.loads(value)
        except Exception:
            return {}
    return {}


def _format_resume_summary(row_dict):
    summary = row_dict.get("resume_mini") or row_dict.get("short_eval") or "æœªæä¾›ç›¸å…³ä¿¡æ¯"
    return _clean_single_line(summary, default="æœªæä¾›ç›¸å…³ä¿¡æ¯", limit=130)


def _format_evidence_field(row_dict):
    reasoning = _safe_load_json(row_dict.get("reasoning_chain"))
    short_eval_struct = _safe_load_json(row_dict.get("short_eval_struct"))

    def _format_strengths():
        chain = reasoning.get("strengths_reasoning_chain") or []
        entries = []
        for idx, item in enumerate(chain, 1):
            if not isinstance(item, dict):
                continue
            conclusion = _clean_single_line(item.get("conclusion"), "æœªå‘½åä¼˜åŠ¿", 18)
            actions = _clean_single_line(item.get("detected_actions"), "æœªæä¾›", 24)
            evidence = _clean_single_line(item.get("resume_evidence"), "æœªæä¾›", 48)
            reasoning_txt = _clean_single_line(item.get("ai_reasoning"), "æœªæä¾›", 36)
            entries.append(f"{idx}. {conclusion}ï½œåŠ¨ä½œ:{actions}ï½œè¯æ®:{evidence}ï½œæ¨æ–­:{reasoning_txt}")
        return "ï¼›".join(entries) if entries else "æš‚æ— å¯éªŒè¯ä¼˜åŠ¿"

    def _format_weaknesses():
        chain = reasoning.get("weaknesses_reasoning_chain") or []
        entries = []
        for idx, item in enumerate(chain, 1):
            if not isinstance(item, dict):
                continue
            conclusion = _clean_single_line(item.get("conclusion"), "æœªå‘½ååŠ£åŠ¿", 18)
            gap = _clean_single_line(item.get("resume_gap"), "æœªæä¾›", 32)
            compare = _clean_single_line(item.get("compare_to_jd"), "æœªæä¾›", 40)
            risk = _clean_single_line(item.get("ai_reasoning"), "æœªæä¾›", 36)
            entries.append(f"{idx}. {conclusion}ï½œç¼ºå£:{gap}ï½œJD:{compare}ï½œé£é™©:{risk}")
        return "ï¼›".join(entries) if entries else "æš‚æ— å¯éªŒè¯åŠ£åŠ¿"

    match_level = _clean_single_line(short_eval_struct.get("match_level"), "æ— æ³•è¯„ä¼°", 4)
    match_reason = _clean_single_line(short_eval_struct.get("match_reason"), "æœªæä¾›åŒ¹é…åŸå› ", 60)
    match_text = f"{match_level}ï¼š{match_reason}"

    evidence_text = f"ã€ä¼˜åŠ¿ã€‘{_format_strengths()}ã€åŠ£åŠ¿ã€‘{_format_weaknesses()}ã€åŒ¹é…åº¦ã€‘{match_text}"
    return _clean_single_line(evidence_text, default="æœªæä¾›")


def _build_export_dataframe(result_df, job_title):
    rows = []
    position_name = _clean_single_line(job_title, default="æœªæä¾›")
    for _, row in result_df.iterrows():
        row_dict = row.to_dict()
        candidate_id = row_dict.get("candidate_id")

        try:
            candidate_id = int(candidate_id)
        except Exception:
            candidate_id = 0

        export_row = {
            "å€™é€‰äººID": candidate_id,
            "å§“å": _clean_single_line(row_dict.get("name"), "æœªæä¾›"),
            "æ–‡ä»¶å": _clean_single_line(row_dict.get("file"), "æœªæä¾›"),
            "å²—ä½": position_name,
            "é‚®ç®±": _clean_single_line(row_dict.get("email"), "æœªæä¾›"),
            "æ‰‹æœºå·": _clean_single_line(row_dict.get("phone"), "æœªæä¾›"),
            "æ€»åˆ†": int(round(float(row_dict.get("æ€»åˆ†", 0)))),
            "äº®ç‚¹": _format_highlights_for_export(row_dict),
            "ç®€å†æ‘˜è¦": _format_resume_summary(row_dict),
            "è¯æ®": _format_evidence_field(row_dict),
        }
        rows.append(export_row)
    return pd.DataFrame(rows)


with st.sidebar:
    st.header("è®¾ç½®")
    cfg_file = Path("backend/configs/model_config.json")
    cfg = json.loads(cfg_file.read_text(encoding="utf-8"))
    
    # AIé…ç½®ï¼ˆé”å®šä¸ºGPT-4ï¼‰
    st.subheader("AIé…ç½®")
    st.markdown("**AIæä¾›å•†ï¼š** OpenAI (å·²é”å®š)")
    st.markdown("**æ¨¡å‹åç§°ï¼š** GPT-4 (å·²é”å®š)")
    st.info("ğŸ”’ AIé…ç½®å·²é”å®šä¸ºGPT-4ï¼Œç¡®ä¿ç”Ÿæˆè´¨é‡ã€‚å¦‚éœ€ä¿®æ”¹ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚")
    st.caption("ğŸ’¡ è¯·è®¾ç½®ç¯å¢ƒå˜é‡: OPENAI_API_KEY æˆ–é…ç½® backend/configs/api_keys.json")
    
    # å›ºå®šä½¿ç”¨GPT-4
    llm_provider = "openai"
    llm_model = "gpt-4"
    
    st.markdown("---")
    
    # å…¶ä»–è®¾ç½®
    st.subheader("ç­›é€‰è®¾ç½®")
    
    blind = st.toggle("ç›²ç­›æ¨¡å¼ï¼ˆéšè—å§“å/å­¦æ ¡ç­‰ï¼‰", value=cfg.get("blind_screen", True),
                     help="å¼€å¯åï¼Œåœ¨ç®€å†ç­›é€‰è¿‡ç¨‹ä¸­éšè—å€™é€‰äººçš„å§“åã€å­¦æ ¡ç­‰æ•æ„Ÿä¿¡æ¯ï¼Œé¿å…å› ä¸ªäººèƒŒæ™¯äº§ç”Ÿåè§ï¼Œç¡®ä¿å…¬å¹³ç­›é€‰")
    
    thr = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, cfg.get("confidence_threshold", 0.65), 0.05,
                    help="è¯„åˆ†ç½®ä¿¡åº¦ä½äºæ­¤é˜ˆå€¼çš„å€™é€‰äººå°†è¢«æ ‡è®°ä¸º'é˜ˆå€¼æ‹¦æˆª'ï¼Œä¸ä¼šè‡ªåŠ¨å‘é€é‚€çº¦ã€‚å»ºè®®å€¼ï¼š0.6-0.7ã€‚å€¼è¶Šé«˜ï¼Œç­›é€‰è¶Šä¸¥æ ¼ã€‚")
    
    st.caption("ğŸ’¡ ç½®ä¿¡åº¦é˜ˆå€¼è¯´æ˜ï¼šç³»ç»Ÿä¼šæ ¹æ®ç®€å†åŒ¹é…åº¦è®¡ç®—ä¸€ä¸ªç½®ä¿¡åº¦åˆ†æ•°ã€‚ä½äºé˜ˆå€¼çš„å€™é€‰äººéœ€è¦äººå·¥å®¡æ ¸åæ‰èƒ½é‚€çº¦ã€‚")
    if st.button("ä¿å­˜è®¾ç½®"):
        cfg["blind_screen"] = blind
        cfg["confidence_threshold"] = float(thr)
        # AIé…ç½®å·²é”å®šï¼Œä¸æ›´æ–°
        cfg["llm_provider"] = "openai"
        cfg["llm_model"] = "gpt-4"
        cfg_file.write_text(json.dumps(cfg, ensure_ascii=False, indent=2), encoding="utf-8")
        st.success("âœ… è®¾ç½®å·²ä¿å­˜ï¼ˆAIé…ç½®ä¿æŒé”å®šä¸ºGPT-4ï¼‰")
    st.markdown("---"); st.caption("ç‰ˆæœ¬æ§åˆ¶")
    vm = VersionManager()
    if st.button("åˆ›å»ºå¿«ç…§"):
        st.success("å·²åˆ›å»ºç‰ˆæœ¬ï¼š" + vm.snapshot())


init_db(); pipe = RecruitPipeline()
tab1, tab2, tab3, tab4, tab5 = st.tabs(["1 ç”Ÿæˆ JD","2 ç®€å†è§£æ & åŒ¹é…","3 å»é‡ & æ’åº","4 é‚€çº¦ & æ’æœŸ","5 é¢è¯•åŒ… & å¯¼å‡º"])

with tab1:
    # ==========================================================
    # âœ… ç»Ÿä¸€æŒ‰é’®å®šä¹‰ï¼Œé˜²æ­¢ StreamlitDuplicateElementId é”™è¯¯
    # ==========================================================
    
    # ğŸ”¹ åŠŸèƒ½ï¼šä¿å­˜ JD ä¸ Rubric æ•°æ®
    # ğŸ”¹ ä¿®å¤ï¼šä¸ºæŒ‰é’®åˆ†é…å”¯ä¸€ keyï¼Œé˜²æ­¢é‡å¤ ID å†²çª
    # ğŸ”¹ æµ‹è¯•ç»“æœï¼šå·²é€šè¿‡å¤šæ¬¡ Cursor ä¸ Streamlit è¿è¡ŒéªŒè¯ï¼ˆæ— å¼‚å¸¸ï¼‰
    # ==========================================================
    
    # å°è£…æŒ‰é’®è¡Œä¸ºï¼ˆå¯å¤ç”¨ï¼‰
    def save_to_system_action():
        """ç»Ÿä¸€çš„ä¿å­˜ JD + é¢˜åº“æ“ä½œ"""
        current_bundle = st.session_state.get("ai_bundle")
        if not current_bundle:
            st.warning('è¯·å…ˆç‚¹å‡»"ç”Ÿæˆ JD"è·å¾— AI ç»“æœã€‚')
            return
        
        try:
            job_to_save = (st.session_state.get("job_name") or "").strip()
            if not job_to_save:
                job_to_save = current_bundle.get("rubric", {}).get("job", "")
    
            pipe.save_jd(job_to_save, current_bundle["jd_long"], current_bundle["jd_short"], current_bundle["rubric"])
    
            q_path = Path("data/templates/é¢˜åº“ç¤ºä¾‹.csv")
            rows = []
            for q in current_bundle.get("interview", []):
                points = q.get("points") or []
                points_str = "ï¼›".join(points) if isinstance(points, list) else (str(q.get("points", "")) if q.get("points") else "")
                rows.append({
                    "job": job_to_save,
                    "èƒ½åŠ›ç»´åº¦": q.get("dimension", "é€šç”¨"),
                    "é¢˜ç›®": q.get("question", ""),
                    "è¯„åˆ†è¦ç‚¹": points_str,
                    "åˆ†å€¼": int(q.get("score", 0)),
                    "æƒé‡": round(float(q.get("score", 0)) / 100.0, 4)
                })
            if rows:
                qdf = pd.DataFrame(rows)
                q_path.parent.mkdir(parents=True, exist_ok=True)
                header = not q_path.exists()
                qdf.to_csv(q_path, mode="a", index=False, encoding="utf-8-sig", header=header)
            st.success("å·²å†™å…¥ï¼šJD / Rubric / é¢˜åº“")
        except Exception as e:
            st.error(f"âŒ å†™å…¥å¤±è´¥ï¼š{e}")
    
    st.subheader("æ™ºèƒ½ç”Ÿæˆ JDï¼ˆAIåˆ†æï¼‰")
    
    # === æ–°å¢ï¼šæ™ºèƒ½ç”Ÿæˆ JDï¼ˆAI åˆ†æï¼‰ ===
    st.markdown("### ğŸ¤– æ™ºèƒ½ç”Ÿæˆ JDï¼ˆAI åˆ†æï¼‰")
    
    # é¢„æ£€æŸ¥ï¼šAI Key
    key_present = bool(os.getenv("SILICONFLOW_API_KEY") or os.getenv("OPENAI_API_KEY"))
    if not key_present:
        st.warning("âš ï¸ æœªæ£€æµ‹åˆ° AI Keyï¼šè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` å¹¶é…ç½® SILICONFLOW_API_KEYã€‚")
    
    with st.form("ai_jd_form"):
        ai_job = st.text_input("å²—ä½åç§° *", value=st.session_state.get("job_name",""), help="ä¾‹å¦‚ï¼šæ•°å­¦ç«èµ›æ•™ç»ƒ/æ•™å­¦è¿è¥ä¸“å‘˜/ç­ä¸»ä»»/Javaåç«¯")
        ai_must = st.text_area("å¿…å¤‡ç»éªŒ/æŠ€èƒ½", value="", height=80, help="åˆ†å·æˆ–ç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚ï¼šå›½ä¸€; LaTeX; IMOè®­ç»ƒ")
        ai_nice = st.text_area("åŠ åˆ†é¡¹", value="", height=60, help="å¦‚ï¼šç«èµ›å‡ºé¢˜ç»éªŒ; å…¬å¼€è¯¾; å†…å®¹åˆ¶ä½œ")
        ai_excl = st.text_area("æ’é™¤é¡¹", value="", height=60, help="å¦‚ï¼šä»…å®ä¹ ; å…¼èŒ")
        submitted = st.form_submit_button("ğŸš€ ç”Ÿæˆ JD", type="primary", use_container_width=True)
        
        if submitted:
            if not ai_job:
                st.error("âŒ è¯·å¡«å†™å²—ä½åç§°")
            else:
                st.session_state["job_name"] = ai_job
                # è¾“å…¥æ¸…æ´—ï¼štex -> LaTeX
                ai_must = ai_must.replace("tex", "LaTeX").replace("Tex", "LaTeX")
                ai_nice = ai_nice.replace("tex", "LaTeX").replace("Tex", "LaTeX")
                try:
                    # å¼ºåˆ¶é‡æ–°åŠ è½½æ¨¡å—ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°ä»£ç 
                    if 'backend.services.jd_ai' in sys.modules:
                        importlib.reload(sys.modules['backend.services.jd_ai'])
                        from backend.services.jd_ai import generate_jd_bundle
                    with st.spinner("ğŸ¤– AIæ­£åœ¨æ™ºèƒ½åˆ†æå²—ä½éœ€æ±‚ï¼Œç”Ÿæˆä¸“ä¸šJDã€èƒ½åŠ›ç»´åº¦ã€é¢è¯•é¢˜ç›®ï¼Œè¯·ç¨å€™ï¼ˆé€šå¸¸éœ€è¦10-30ç§’ï¼‰..."):
                        bundle = generate_jd_bundle(ai_job, ai_must, ai_nice, ai_excl)
                        # åŸºäºé•¿ç‰ˆ JD å†åšä¸€æ¬¡â€œçŸ­ç‰ˆJDæå– + ä»»èŒè¦æ±‚æŠ½å–èƒ½åŠ›ä¸é¢è¯•é¢˜â€
                        from backend.services.jd_ai import extract_short_and_competencies_from_long_jd
                        extracted = extract_short_and_competencies_from_long_jd(bundle.get("jd_long",""), ai_job)
                        if extracted:
                            # âœ… ä¸å†ç”¨æŠ½å–å¾—åˆ°çš„çŸ­ç‰ˆ JD è¦†ç›–ï¼Œä»¥å…ç ´åâ€œå°çº¢ä¹¦é£æ ¼â€çŸ­ç‰ˆ JD
                            # å¦‚éœ€æŸ¥çœ‹æŠ½å–ç‰ˆçŸ­ JDï¼Œå¯åç»­å•ç‹¬åœ¨å‰ç«¯å±•ç¤º extracted["short_jd"]
                            # ç”¨æŠ½å–å¾—åˆ°çš„èƒ½åŠ›ç»´åº¦/é¢è¯•é¢˜è¦†ç›–å±•ç¤ºï¼ˆè½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼ï¼‰
                            dims = []
                            for d in extracted.get("èƒ½åŠ›ç»´åº¦", []):
                                anchors = d.get("è¯„åˆ†é”šç‚¹") or {}
                                dims.append({
                                    "name": d.get("ç»´åº¦åç§°", ""),
                                    "weight": round(float(d.get("æƒé‡", 0)) / 100.0, 4),
                                    "desc": d.get("å®šä¹‰", ""),
                                    "anchors": {
                                        "20": anchors.get("20") or "åŸºç¡€è¾¾æˆï¼šè¯·ç»“åˆ JD ä¸­çš„åŸºç¡€è¦æ±‚æè¿°ã€‚",
                                        "60": anchors.get("60") or "è‰¯å¥½è¾¾æˆï¼šèƒ½å¤Ÿç¨³å®šäº§å‡ºå¹¶ä¸æ–­ä¼˜åŒ–ã€‚",
                                        "100": anchors.get("100") or "ä¼˜ç§€è¾¾æˆï¼šæŒç»­è¾“å‡ºæ°å‡ºæˆæœå¹¶é‡åŒ–å½±å“ã€‚",
                                    },
                                })
                            if dims:
                                bundle["dimensions"] = dims
                            qs = []
                            for q in extracted.get("èƒ½åŠ›ç»´åº¦_é¢è¯•é¢˜", []):
                                raw_points = q.get("è¯„åˆ†è¦ç‚¹", [])
                                if isinstance(raw_points, str):
                                    points_list = [p.strip() for p in re.split(r"[ï¼›;ã€\n]", raw_points) if p.strip()]
                                else:
                                    points_list = [str(p).strip() for p in (raw_points or []) if str(p).strip()]
                                question_text = q.get("é¢è¯•é¢˜", "")
                                if isinstance(question_text, list):
                                    question_text = "ï¼›".join(str(item).strip() for item in question_text if str(item).strip())
                                qs.append({
                                    "dimension": q.get("ç»´åº¦åç§°", ""),
                                    "question": question_text,
                                    "points": points_list,
                                    "score": float(q.get("åˆ†å€¼", 0)),
                                })
                            if qs:
                                bundle["interview"] = qs
                            bundle["full_ability_list"] = construct_full_ability_list(
                                bundle.get("dimensions"), bundle.get("interview")
                            )
                    # âœ… æŒä¹…åŒ–ï¼šåç»­å…¶å®ƒæŒ‰é’®/åŒºåŸŸå¯å¤ç”¨
                    st.session_state["ai_bundle"] = bundle
                    st.success("âœ… AI ç”Ÿæˆå®Œæˆ")
                except Exception as e:
                    error_msg = str(e)
                    # æå–æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
                    if "Key" in error_msg or "æœªé…ç½®" in error_msg:
                        st.error(f"âŒ {error_msg}")
                        st.info("ğŸ’¡ è¯·æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶ï¼Œç¡®ä¿åŒ…å« SILICONFLOW_API_KEY æˆ– OPENAI_API_KEYï¼Œç„¶åé‡å¯ Streamlitã€‚")
                    elif "401" in error_msg or "403" in error_msg:
                        st.error(f"âŒ API Key éªŒè¯å¤±è´¥ï¼š{error_msg}")
                        st.info("ğŸ’¡ è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ API Key æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æ˜¯å¦å·²è¿‡æœŸã€‚")
                    elif "404" in error_msg or "æ¨¡å‹" in error_msg:
                        st.error(f"âŒ æ¨¡å‹ä¸å¯ç”¨ï¼š{error_msg}")
                        st.info("ğŸ’¡ è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ AI_MODEL æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•æ›´æ¢ä¸ºå…¶ä»–å¯ç”¨æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-32B-Instructï¼‰ã€‚")
                    else:
                        st.error(f"âŒ AI ç”Ÿæˆå¤±è´¥ï¼š{error_msg}")
                        st.info("ğŸ’¡ ç³»ç»Ÿå°†ç»§ç»­æ”¯æŒ'ç¦»çº¿è§„åˆ™ç‰ˆ'ç”Ÿæˆï¼Œç¡®ä¿å¯ç”¨ã€‚å±•å¼€ä¸‹æ–¹çš„'AI è¿æ¥è¯Šæ–­'æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")
    
    # æ˜¾ç¤ºAIç”Ÿæˆç»“æœ
    bundle = st.session_state.get("ai_bundle")
    if SHOW_DETAIL_SECTIONS:
        if bundle:
            st.subheader("ğŸ“„ é•¿ç‰ˆ JDï¼ˆBossç›´è˜å¯ç”¨ï¼‰")
            st.text_area("é•¿ç‰ˆ JD", bundle["jd_long"], height=260)
        
            st.subheader("ğŸª§ çŸ­ç‰ˆ JDï¼ˆç¤¾åª’/å†…æ¨ï¼‰")
            st.text_area("çŸ­ç‰ˆ JD", bundle["jd_short"], height=100)
        
            st.markdown("### å²—ä½èƒ½åŠ›ç»´åº¦ä¸é¢è¯•é¢˜ç›®ï¼ˆAIåˆ†æ + AIç”Ÿæˆï¼‰")
            full_ability = bundle.get("full_ability_list") or construct_full_ability_list(
                bundle.get("dimensions"), bundle.get("interview")
            )
            bundle["full_ability_list"] = full_ability

            display_rows = []
            for item in full_ability:
                display_rows.append({
                    "èƒ½åŠ›ç»´åº¦": item.get("dimension", ""),
                    "è¯´æ˜": item.get("description", ""),
                    "æƒé‡(%)": round(float(item.get("weight", 0.0)) * 100, 1),
                    "é¢è¯•é¢˜ç›®": item.get("question", ""),
                    "è¯„åˆ†è¦ç‚¹": item.get("score_points", ""),
                    "20åˆ†è¡Œä¸ºè¡¨ç°": item.get("score_20", ""),
                    "60åˆ†è¡Œä¸ºè¡¨ç°": item.get("score_60", ""),
                    "100åˆ†è¡Œä¸ºè¡¨ç°": item.get("score_100", ""),
                    "åˆ†å€¼": item.get("score_value", 0.0),
                })

            df_full = pd.DataFrame(display_rows)
            st.dataframe(df_full, use_container_width=True)

            # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ Excelï¼ˆæ–°ç‰ˆæœ¬ï¼Œå®Œå…¨åŸºäºæ¨¡æ¿ï¼‰
            job_name = (st.session_state.get('job_name') or 'å²—ä½').strip()
            try:
                # è½¬æ¢æ•°æ®æ ¼å¼ä¸º DataFrame
                dimensions_data = []
                for ability in full_ability:
                    dimensions_data.append({
                        "èƒ½åŠ›ç»´åº¦": ability.get("dimension", ""),
                        "è¯´æ˜": ability.get("description", ""),
                        "é¢è¯•é¢˜ç›®": ability.get("question", ""),
                        "è¯„åˆ†è¦ç‚¹": ability.get("score_points", ""),
                        "20åˆ†è¡Œä¸ºè¡¨ç°": ability.get("score_20", ""),
                        "60åˆ†è¡Œä¸ºè¡¨ç°": ability.get("score_60", ""),
                        "100åˆ†è¡Œä¸ºè¡¨ç°": ability.get("score_100", ""),
                        "æƒé‡": ability.get("weight", 0.0),
                    })
                
                # åˆ›å»º DataFrameï¼ˆå»æ‰æ§åˆ¶å°è°ƒè¯•è¾“å‡ºï¼Œé¿å… Windows æ§åˆ¶å°ç¼–ç å¯¼è‡´ OSErrorï¼‰
                data_df = pd.DataFrame(dimensions_data)
                
                # å›ºå®šè¾“å‡ºè·¯å¾„
                output_path = r"C:\RecruitFlow_Pro_MVP\docs\è¯¾ç¨‹é¡¾é—®_èƒ½åŠ›ç»´åº¦è¯„åˆ†è¡¨(æ”¹)_è¾“å‡º.xlsx"
                
                def _coerce_excel_result(result, fallback_path):
                    if isinstance(result, tuple):
                        return result
                    if isinstance(result, bytes):
                        return result, fallback_path
                    read_path = result if isinstance(result, str) else fallback_path
                    with open(read_path, "rb") as f:
                        return f.read(), read_path
                
                # ä½¿ç”¨æ–°çš„å¯¼å‡ºå‡½æ•°ï¼ˆå®Œå…¨åŸºäºæ¨¡æ¿ï¼‰
                try:
                    export_result = export_competency_excel(
                        data_df, output_path, job_title=job_name
                    )
                except TypeError:
                    print("[streamlit] export_competency_excel fallback to legacy signature")
                    export_result = export_competency_excel(data_df, output_path)

                excel_bytes, saved_path = _coerce_excel_result(export_result, output_path)

                if saved_path and saved_path != output_path:
                    st.warning(f"åŸå§‹è¾“å‡ºæ–‡ä»¶è¢«å ç”¨ï¼Œå·²æ”¹ä¸ºä¿å­˜åˆ°ï¼š`{saved_path}`")
                
                download_name = f"{job_name}_èƒ½åŠ›ç»´åº¦è¯„åˆ†è¡¨.xlsx"
                st.download_button(
                    "ğŸ“„ å¯¼å‡ºèƒ½åŠ›ç»´åº¦è¯„åˆ†è¡¨ï¼ˆExcelï¼‰",
                    data=excel_bytes,
                    file_name=download_name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )
            except Exception as e:
                st.error(f"å¯¼å‡ºå¤±è´¥ï¼š{str(e)}")
                st.exception(e)
 
            # ä¿ç•™å•ä¸€ä¿å­˜å…¥å£
            if st.button("ğŸ’¾ å†™å…¥ç³»ç»Ÿï¼ˆä¿å­˜ JD + é¢˜åº“ï¼‰", type="primary", key="btn_save_rubric_1"):
                save_to_system_action()
        else:
            st.info('å°šæœªç”Ÿæˆ Rubricï¼ˆè¯·å…ˆç‚¹å‡»ä¸Šæ–¹"ç”Ÿæˆ JD"ï¼‰')
        
        # âœ… éšè—è¯„åˆ†ç»´åº¦è§„åˆ™ï¼ˆRubricï¼‰éƒ¨åˆ†ï¼Œåªä¿ç•™åŠŸèƒ½é€»è¾‘
        # è¿™é‡Œä¿ç•™ bundle_for_rubric çš„ç”Ÿæˆå’Œä¿å­˜é€»è¾‘ï¼Œä½†ä¸æ¸²æŸ“åˆ°é¡µé¢
        bundle_for_rubric = st.session_state.get("ai_bundle")
        # bundle_for_rubric å˜é‡ä¿ç•™ï¼Œä¾›å†…éƒ¨é€»è¾‘ä½¿ç”¨ï¼ˆå¦‚ save_to_system_action å‡½æ•°ä¸­ä¼šç”¨åˆ°ï¼‰
        
        # ä¸å†æ˜¾ç¤ºæ ‡é¢˜å’Œå±•å¼€å—ï¼Œé¿å… UI é‡å¤
        # st.subheader("è¯„åˆ†ç»´åº¦è§„åˆ™ï¼ˆRubricï¼‰")  # âŒ æ³¨é‡Šæ‰
        # with st.expander("è¯„åˆ†ç»´åº¦è§„åˆ™ï¼ˆRubricï¼‰", expanded=False):
        #     st.json(bundle_for_rubric["rubric"])
        
        # âœ… ä»…ä¿ç•™ä¸€æ¬¡ä¿å­˜æŒ‰é’®ï¼ˆä¸Šæ–¹å·²æœ‰çš„æŒ‰é’® btn_save_rubric_1ï¼‰
        # å› æ­¤è¿™é‡Œåˆ é™¤é‡å¤æŒ‰é’®ï¼Œé˜²æ­¢é‡å¤æ˜¾ç¤º
        # if st.button("ğŸ’¾ å†™å…¥ç³»ç»Ÿï¼ˆä¿å­˜ JD + é¢˜åº“ï¼‰", type="primary", key="btn_save_rubric_2"):
        #     save_to_system_action()
    
    # ==== AI è¿æ¥è¯Šæ–­ï¼ˆæ”¾åœ¨é¡µé¢åº•éƒ¨ï¼‰====
    with st.expander("ğŸ”§ AI è¿æ¥è¯Šæ–­ï¼ˆæ‰“ä¸å¼€å°±ç‚¹æˆ‘ï¼‰"):
        try:
            # å¼ºåˆ¶é‡æ–°åŠ è½½æ¨¡å—ï¼Œé¿å…ç¼“å­˜é—®é¢˜
            import importlib
            import sys
            if 'backend.services.ai_client' in sys.modules:
                importlib.reload(sys.modules['backend.services.ai_client'])
            from backend.services.ai_client import get_client_and_cfg, AIConfig, chat_completion
        except ImportError as e:
            st.error(f"âŒ å¯¼å…¥ AI å®¢æˆ·ç«¯å¤±è´¥ï¼š{e}")
            st.info("ğŸ’¡ è¯·æ£€æŸ¥ backend/services/ai_client.py æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯æ­£å¸¸å¯¼å…¥")
            st.stop()
        
        cfg = AIConfig()
        key_present = bool(cfg.api_key)
        st.write("**å·²æ£€æµ‹åˆ° Keyï¼š**", "âœ…" if key_present else "âŒ")
        if key_present:
            st.write("**Key å‰ç¼€ï¼š**", cfg.api_key[:10] + "..." if len(cfg.api_key) > 10 else cfg.api_key)
        st.write("**Base URLï¼š**", cfg.base_url)
        st.write("**å½“å‰æ¨¡å‹ï¼š**", cfg.model)
        st.write("**Temperatureï¼š**", cfg.temperature)
        
        if st.button("ğŸ§ª æµ‹è¯•ä¸€æ¬¡ AI è¿é€šæ€§"):
            try:
                client, cfg = get_client_and_cfg()
                with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                    res = chat_completion(
                        client,
                        cfg,
                        messages=[{"role":"user","content":"åªè¿”å› OK"}],
                        temperature=0,
                        max_tokens=10
                    )
                    result = res["choices"][0]["message"]["content"].strip()
                    st.success(f"âœ… AI è¿é€šæ€§æµ‹è¯•æˆåŠŸï¼è¿”å›ï¼š{result}")
            except Exception as e:
                error_detail = str(e)
                st.error(f"âŒ è¿é€šæ€§å¤±è´¥ï¼š{error_detail}")
                if "ChatCompletion" in error_detail or "openai>=1.0.0" in error_detail:
                    st.error("âš ï¸ OpenAI API ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜")
                    st.info("ğŸ’¡ è¿™é€šå¸¸æ˜¯å› ä¸ºä»£ç ä¸­ä½¿ç”¨äº†æ—§ç‰ˆæœ¬çš„ OpenAI APIã€‚è¯·ç¡®ä¿ï¼š\n"
                           "1. å·²å®‰è£… openai>=1.0.0ï¼š`pip install --upgrade openai`\n"
                           "2. ä»£ç ä½¿ç”¨ `client.chat.completions.create` è€Œä¸æ˜¯ `openai.ChatCompletion.create`\n"
                           "3. é‡å¯ Streamlit åº”ç”¨ä»¥æ¸…é™¤ç¼“å­˜")
                    st.code("pip install --upgrade openai", language="bash")
                elif "Key" in error_detail or "æœªé…ç½®" in error_detail:
                    st.info("ğŸ’¡ æ£€æŸ¥ .env çš„ Key é…ç½®ï¼›ç¡®ä¿æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼›é‡å¯ Streamlit")
                elif "401" in error_detail or "403" in error_detail:
                    st.info("ğŸ’¡ API Key æ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·æ£€æŸ¥ .env ä¸­çš„ Key æ˜¯å¦æ­£ç¡®")
                elif "404" in error_detail:
                    st.info("ğŸ’¡ æ¨¡å‹ä¸å­˜åœ¨æˆ–æœªå¼€é€šï¼Œè¯·æ£€æŸ¥ .env ä¸­çš„ AI_MODELï¼Œå°è¯•æ›´æ¢ä¸º Qwen2.5-32B-Instruct")
                elif "timeout" in error_detail.lower() or "è¿æ¥" in error_detail:
                    st.info("ğŸ’¡ ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ£€æŸ¥å…¬å¸ç½‘ç»œæ˜¯å¦æ”¾è¡Œ api.siliconflow.cnï¼›æˆ–å°è¯•ä½¿ç”¨ OpenAI")
                else:
                    st.info("ğŸ’¡ æ£€æŸ¥ .env çš„ Key/æ¨¡å‹/Base URLï¼›æˆ–å…¬å¸ç½‘ç»œæ˜¯å¦æ”¾è¡Œ api.siliconflow.cn")
    
    # ä¸€é”®å¯åŠ¨è¯´æ˜
    with st.expander("ğŸš€ ä¸€é”®å¯åŠ¨ç¨‹åºï¼ˆé¦–æ¬¡ä½¿ç”¨å¿…çœ‹ï¼‰", expanded=False):
        st.markdown("""
        ### å¿«é€Ÿå¯åŠ¨æ–¹æ³•
        
        1. **æœ€ç®€å•æ–¹å¼**ï¼šåŒå‡»é¡¹ç›®æ ¹ç›®å½•çš„ `å¯åŠ¨ç¨‹åº.bat` æ–‡ä»¶
        2. **PowerShell æ–¹å¼**ï¼šå³é”® `å¯åŠ¨ç¨‹åº.ps1` -> ä½¿ç”¨ PowerShell è¿è¡Œ
        3. **å‘½ä»¤è¡Œæ–¹å¼**ï¼šè¿è¡Œ `å¯åŠ¨ç¨‹åº.bat` æˆ– `.\\å¯åŠ¨ç¨‹åº.ps1`
        
        ### é¦–æ¬¡ä½¿ç”¨å‰å‡†å¤‡
        
        - âœ… ç¡®ä¿å·²å®‰è£… Python 3.8+
        - âœ… å·²åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š`python -m venv .venv`
        - âœ… å·²å®‰è£…ä¾èµ–ï¼š`.venv\\Scripts\\pip install -r requirements.txt`
        - âœ… å·²é…ç½® `.env` æ–‡ä»¶ï¼ˆAI Key ç­‰ï¼Œå¯é€‰ï¼‰
        
        ### è¯¦ç»†ä½¿ç”¨è¯´æ˜
        
        è¯·æŸ¥çœ‹é¡¹ç›®æ ¹ç›®å½•çš„ `ä½¿ç”¨è¯´æ˜.md` æ–‡ä»¶ï¼ŒåŒ…å«ï¼š
        - ğŸ“‹ å®Œæ•´åŠŸèƒ½è¯´æ˜
        - ğŸ”§ å¸¸è§é—®é¢˜è§£ç­”
        - ğŸ¯ å„åŠŸèƒ½æ¨¡å—ä½¿ç”¨æŒ‡å—
        
        ### å½“å‰è¿è¡ŒçŠ¶æ€
        
        - ğŸŒ è®¿é—®åœ°å€ï¼šhttp://localhost:8501
        - ğŸ“ é¡¹ç›®ç›®å½•ï¼š""" + str(Path.cwd()) + """
        """)
        
        # æ˜¾ç¤ºå¯åŠ¨è„šæœ¬è·¯å¾„
        bat_path = Path.cwd() / "å¯åŠ¨ç¨‹åº.bat"
        ps1_path = Path.cwd() / "å¯åŠ¨ç¨‹åº.ps1"
        
        if bat_path.exists():
            st.success(f"âœ… å¯åŠ¨è„šæœ¬å·²æ‰¾åˆ°ï¼š`{bat_path}`")
        else:
            st.warning(f"âš ï¸ å¯åŠ¨è„šæœ¬ä¸å­˜åœ¨ï¼š`{bat_path}`")
        
        if ps1_path.exists():
            st.success(f"âœ… PowerShell è„šæœ¬å·²æ‰¾åˆ°ï¼š`{ps1_path}`")
        
        # æä¾›å¿«é€Ÿå‘½ä»¤
        cmd_text = f"""# å¿«é€Ÿå¯åŠ¨å‘½ä»¤ï¼ˆå¤åˆ¶åˆ°å‘½ä»¤è¡Œè¿è¡Œï¼‰
cd "{Path.cwd()}"
.venv\\Scripts\\python.exe -m streamlit run app/streamlit_app.py --server.port 8501"""
        st.code(cmd_text, language="bash")
    
    st.markdown("---")
    if SHOW_OFFLINE_SECTION:
        st.markdown("---")
        st.markdown("### ğŸ“‹ ç¦»çº¿è§„åˆ™ç‰ˆï¼ˆå¤‡ç”¨ï¼‰")
        
        # é‡æ–°è¯»å–é…ç½®ï¼ˆå› ä¸ºå¯èƒ½åœ¨ä¾§è¾¹æ å·²æ›´æ–°ï¼‰
        cfg = json.loads(cfg_file.read_text(encoding="utf-8"))
        use_ai = cfg.get("llm_provider") in ["openai", "claude", "siliconflow"]
        
        # è¾“å…¥è¡¨å•ï¼ˆç¦»çº¿ç‰ˆï¼‰
        with st.form("jd_generation_form"):
            col1, col2 = st.columns(2)
            with col1:
                job_name = st.text_input("å²—ä½åç§° *", placeholder="ä¾‹å¦‚ï¼šæ•°æ®åˆ†æå¸ˆã€äº§å“ç»ç†ã€è¿è¥ä¸“å‘˜ç­‰", 
                                        value=st.session_state.get("job_name", ""))
            with col2:
                st.caption("ğŸ’¡ å¿…å¡«é¡¹")
            
            must_have = st.text_area("å¿…å¤‡ç»éªŒ/æŠ€èƒ½", placeholder="ä¾‹å¦‚ï¼š3å¹´ä»¥ä¸Šæ•°æ®åˆ†æç»éªŒï¼›ç†Ÿæ‚‰Pythonã€SQLï¼›æœ‰æ•™è‚²è¡Œä¸šèƒŒæ™¯", 
                                    height=80, help="ç”¨åˆ†å·(;)åˆ†éš”å¤šä¸ªæŠ€èƒ½")
            nice_to_have = st.text_area("åŠ åˆ†é¡¹", placeholder="ä¾‹å¦‚ï¼šç†Ÿæ‚‰æœºå™¨å­¦ä¹ ï¼›æœ‰å›¢é˜Ÿç®¡ç†ç»éªŒï¼›æ•°æ®å¯è§†åŒ–èƒ½åŠ›å¼º", 
                                       height=80, help="ç”¨åˆ†å·(;)åˆ†éš”å¤šä¸ªåŠ åˆ†é¡¹")
            exclude_keywords = st.text_area("æ’é™¤é¡¹", placeholder="ä¾‹å¦‚ï¼šé¢‘ç¹è·³æ§½ï¼›ä»…å®ä¹ ç»éªŒï¼›å¤–åŒ…ç»å†", 
                                           height=60, help="ç”¨åˆ†å·(;)åˆ†éš”å¤šä¸ªæ’é™¤å…³é”®è¯")
            
            submitted = st.form_submit_button("ğŸš€ ç”Ÿæˆ JD", type="primary", use_container_width=True)
        
        # å¤„ç†ç”Ÿæˆè¯·æ±‚
        if submitted:
            if not job_name:
                st.error("âŒ è¯·å¡«å†™å²—ä½åç§°")
            else:
                st.session_state["job_name"] = job_name
                with st.spinner("ğŸ¤– AIæ­£åœ¨æ™ºèƒ½åˆ†æå²—ä½éœ€æ±‚ï¼Œç”Ÿæˆä¸“ä¸šJDã€èƒ½åŠ›ç»´åº¦ã€é¢è¯•é¢˜ç›®ï¼Œè¯·ç¨å€™ï¼ˆé€šå¸¸éœ€è¦10-30ç§’ï¼‰..."):
                    try:
                        jd_long, jd_short, rubric, interview_questions = pipe.generate_jd(
                            job_name, must_have=must_have, nice_to_have=nice_to_have, 
                            exclude_keywords=exclude_keywords, use_ai=use_ai
                        )
                        st.session_state["jd_result"] = (jd_long, jd_short, rubric, interview_questions)
                        st.success("âœ… AIç”ŸæˆæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
                        if use_ai:
                            st.info("æ­£åœ¨å°è¯•ä½¿ç”¨ç¦»çº¿æ¨¡å¼...")
                            try:
                                jd_long, jd_short, rubric, interview_questions = pipe.generate_jd(
                                    job_name, must_have=must_have, nice_to_have=nice_to_have, 
                                    exclude_keywords=exclude_keywords, use_ai=False
                                )
                                st.session_state["jd_result"] = (jd_long, jd_short, rubric, interview_questions)
                                st.success("âœ… ç¦»çº¿æ¨¡å¼ç”ŸæˆæˆåŠŸ")
                            except Exception as e2:
                                st.error(f"âŒ ç¦»çº¿æ¨¡å¼ä¹Ÿå¤±è´¥: {str(e2)}")
        
        # æ˜¾ç¤ºç»“æœ
        if "jd_result" in st.session_state:
            jd_long, jd_short, rubric, interview_questions = st.session_state["jd_result"]
            
            # é•¿ç‰ˆJD
            st.markdown("### ğŸ“„ é•¿ç‰ˆ JDï¼ˆBossç›´è˜å¯ç”¨ï¼‰")
            st.text_area("", jd_long, height=300, key="jd_long_display", label_visibility="collapsed")
            
            # çŸ­ç‰ˆJD
            st.markdown("### âœ¨ çŸ­ç‰ˆ JDï¼ˆç¤¾åª’/å†…æ¨ï¼‰")
            st.text_area("", jd_short, height=100, key="jd_short_display", label_visibility="collapsed")
            
            # èƒ½åŠ›ç»´åº¦
            st.markdown("### ğŸ¯ å²—ä½èƒ½åŠ›ç»´åº¦ï¼ˆAIåˆ†æï¼‰")
            if rubric.get("dimensions"):
                dim_data = []
                for dim in rubric["dimensions"]:
                    weight = float(dim.get("weight", 0))
                    dim_data.append({
                        "èƒ½åŠ›ç»´åº¦": dim.get("name", ""),
                        "æƒé‡": f"{weight * 100:.1f}%",
                        "è¯´æ˜": dim.get("description", "")
                    })
                dim_df = pd.DataFrame(dim_data)
                st.dataframe(dim_df, use_container_width=True)
            else:
                st.info('å°šæœªç”Ÿæˆ Rubricï¼ˆè¯·å…ˆç‚¹å‡»ä¸Šæ–¹"ç”Ÿæˆ JD"ï¼‰')
            
            # é¢è¯•é¢˜ç›®
            st.markdown("### ğŸ’¬ é¢è¯•é¢˜ç›®å’Œè¯„åˆ†æ ‡å‡†ï¼ˆAIç”Ÿæˆï¼‰")
            if interview_questions and interview_questions.get("questions"):
                for idx, q in enumerate(interview_questions["questions"], 1):
                    weight_pct = float(q.get('weight', 0)) * 100
                    with st.expander(f"é¢˜ç›® {idx}: {q.get('dimension', 'é€šç”¨')} - æƒé‡: {weight_pct:.0f}%"):
                        st.markdown(f"**é—®é¢˜ï¼š** {q.get('question', '')}")
                        st.markdown(f"**è¯„åˆ†æ ‡å‡†ï¼š** {q.get('evaluation_criteria', '')}")
                        if q.get('weight'):
                            st.caption(f"æƒé‡: {float(q.get('weight', 0)) * 100:.0f}%")
            else:
                st.info("æš‚æ— é¢è¯•é¢˜ç›®")
            
            # ä¿å­˜æŒ‰é’®
            col1, col2 = st.columns([1, 4])
            with col1:
                if st.button("ğŸ’¾ ä¿å­˜ JD & è¯„åˆ†ç»´åº¦", type="primary", key="btn_save_jd_score"):
                    pipe.save_jd(job_name, jd_long, jd_short, rubric, interview_questions)
                    st.success("âœ… å·²ä¿å­˜")

with tab2:
    st.subheader("å¯¼å…¥ç®€å†ï¼ˆCSV/TXT ç¤ºä¾‹ï¼‰å¹¶åŒ¹é…æ‰“åˆ†")
    uploaded = st.file_uploader("ä¸Šä¼ ç®€å† CSVï¼ˆè§ data/samples/sample_resumes.csvï¼‰æˆ– TXTï¼ˆå•ä¸ªï¼‰", type=["csv","txt"], accept_multiple_files=True)
    if uploaded:
        for f in uploaded:
            if f.name.endswith(".csv"):
                df = pd.read_csv(f); pipe.ingest_resumes_df(df)
            else:
                txt = f.read().decode("utf-8", errors="ignore"); pipe.ingest_text_resume(txt)
        st.success("å·²å¯¼å…¥")
    if st.button("æ‰¹é‡è¯„åˆ†"):
        start = time.time()
        result_df = pipe.score_all(st.session_state.get("job_name"))
        st.session_state["scored"] = result_df
        st.info(f"è¯„åˆ†å®Œæˆï¼Œç”¨æ—¶ {time.time()-start:.2f} s")
        # æ±‰åŒ–æ˜¾ç¤º
        result_df_display = translate_dataframe_columns(result_df)
        st.dataframe(result_df_display, use_container_width=True)

    st.markdown("---")
    st.markdown("## ğŸ¤– AI æ™ºèƒ½åŒ¹é…ï¼ˆæ‰¹é‡ä¸Šä¼  PDF/DOCX/å›¾ç‰‡ï¼‰")

    jd_text = ""
    if st.session_state.get("ai_bundle") and st.session_state["ai_bundle"].get("jd_long"):
        jd_text = st.session_state["ai_bundle"]["jd_long"]

    jd_text = st.text_area(
        "å²—ä½ JD æ–‡æœ¬ï¼ˆå·²è‡ªåŠ¨å¸¦å…¥ AI é•¿ç‰ˆ JDï¼Œå¯æ‰‹åŠ¨ç¼–è¾‘ï¼‰",
        value=jd_text,
        height=200,
        help="AI ä¼šåŸºäºè¿™é‡Œçš„ JD ä¸ç®€å†è¿›è¡ŒåŒ¹é…ï¼Œè¯·ç¡®ä¿å†…å®¹å‡†ç¡®ã€‚"
    )

    uploaded_files = st.file_uploader(
        "ä¸Šä¼ å¤šä»½ç®€å†ï¼ˆæ”¯æŒï¼špdfã€docxã€txtã€jpgã€jpegã€pngï¼‰",
        type=["pdf", "docx", "txt", "jpg", "jpeg", "png"],
        accept_multiple_files=True,
        key="ai_resume_uploader"
    )

    if uploaded_files:
        with st.spinner("æ­£åœ¨è§£æç®€å†æ–‡ä»¶â€¦"):
            resumes_df = parse_uploaded_files_to_df(uploaded_files)
        if resumes_df.empty:
            st.warning("æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆç®€å†ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
        else:
            st.success(f"å·²è§£æ {len(resumes_df)} ä»½ç®€å†ã€‚")
            base_columns = ["candidate_id", "name", "file", "email", "phone", "text_len"]
            for col in base_columns:
                if col not in resumes_df.columns:
                    if col == "candidate_id":
                        resumes_df[col] = range(1, len(resumes_df) + 1)
                    elif col == "text_len":
                        resumes_df[col] = resumes_df.get("resume_text", "").apply(lambda x: len(str(x)) if x else 0)
                    else:
                        resumes_df[col] = ""
            # ä½¿ç”¨å­—æ®µæ˜ å°„ç¿»è¯‘åˆ—å
            display_resumes_df = resumes_df[base_columns].copy()
            display_resumes_df = translate_dataframe_columns(display_resumes_df)
            st.dataframe(
                display_resumes_df,
                use_container_width=True
            )

            if st.button("ğŸš€ ç”¨ AI æ‰¹é‡åŒ¹é…å¹¶æ‰“åˆ†"):
                if not jd_text.strip():
                    st.warning("è¯·å…ˆå¡«å†™/ç²˜è´´å²—ä½ JDã€‚")
                else:
                    # è·å–å²—ä½åç§°ï¼Œç”¨äºå²—ä½çº§æ¸…æ´—é€»è¾‘
                    job_title = st.session_state.get("job_name", "")
                    with st.spinner("AI æ­£åœ¨æ™ºèƒ½åˆ†æåŒ¹é…åº¦ï¼Œè¯·ç¨å€™â€¦"):
                        scored_df = ai_match_resumes_df(jd_text, resumes_df, job_title)
                    score_columns = [
                        "candidate_id",
                        "name",
                        "file",
                        "email",
                        "phone",
                        "æ€»åˆ†",
                        "æŠ€èƒ½åŒ¹é…åº¦",
                        "ç»éªŒç›¸å…³æ€§",
                        "æˆé•¿æ½œåŠ›",
                        "ç¨³å®šæ€§",
                        "score_explain",
                        "short_eval",
                        "highlights",
                        "resume_mini",
                        "è¯æ®",
                    ]
                    for col in score_columns:
                        if col not in scored_df.columns:
                            if col == "candidate_id":
                                scored_df[col] = range(1, len(scored_df) + 1)
                            else:
                                scored_df[col] = ""
                    
                    result_df = scored_df
                    display_columns = [
                        "candidate_id",
                        "name",
                        "file",
                        "æ€»åˆ†",
                        "æŠ€èƒ½åŒ¹é…åº¦",
                        "ç»éªŒç›¸å…³æ€§",
                        "æˆé•¿æ½œåŠ›",
                        "ç¨³å®šæ€§",
                        "short_eval",
                        "highlights",
                        "resume_mini",
                        "è¯æ®",
                    ]
                    existing_display = [col for col in display_columns if col in result_df.columns]
                    if existing_display:
                        display_df = result_df[existing_display].copy()
                        if "resume_mini" in display_df.columns:
                            display_df["resume_mini"] = display_df["resume_mini"].apply(
                                lambda x: (x[:80] + "â€¦") if isinstance(x, str) and len(x) > 80 else x
                            )
                        display_df = translate_dataframe_columns(display_df)
                        st.dataframe(
                            display_df,
                            use_container_width=True,
                            hide_index=True,
                        )
                    export_job_title = st.session_state.get("job_name") or job_title or "æœªæä¾›"
                    export_df = _build_export_dataframe(result_df, export_job_title)

                    st.markdown("### å€™é€‰äººæ´å¯Ÿè¯¦æƒ…")
                    for _, row in result_df.iterrows():
                        score_label = row.get("æ€»åˆ†")
                        title = f"{row.get('name','åŒ¿åå€™é€‰äºº')}ï½œæ€»åˆ† {score_label if score_label is not None else 'â€”'}"
                        with st.expander(title):
                            raw_highlights = row.get("highlights", "")
                            if isinstance(raw_highlights, str):
                                highlights_raw = [tag.strip() for tag in re.split(r"[ï½œ|ï¼Œ,ã€\s]+", raw_highlights) if tag.strip()]
                            elif isinstance(raw_highlights, list):
                                highlights_raw = raw_highlights
                            else:
                                highlights_raw = []
                            if highlights_raw:
                                st.markdown(
                                    "**äº®ç‚¹æ ‡ç­¾**ï¼š" + " ".join(f"`{tag}`" for tag in highlights_raw if tag)
                                )
                            else:
                                st.markdown("**äº®ç‚¹æ ‡ç­¾**ï¼šæš‚æ— ")

                            resume_mini = row.get("resume_mini", "")
                            st.markdown("**çŸ­ç‰ˆç®€å†**")
                            st.write(resume_mini if resume_mini else "æš‚æ— çŸ­ç‰ˆç®€å†")

                            st.markdown("**AI æ¨ç†é“¾**")
                            reasoning_raw = row.get("reasoning_chain") or {}
                            try:
                                reasoning_obj = (
                                    json.loads(reasoning_raw)
                                    if isinstance(reasoning_raw, str)
                                    else reasoning_raw
                                )
                            except Exception:
                                reasoning_obj = {}
                            def render_chain(title: str, chain: list, fields: list):
                                st.markdown(f"##### {title}")
                                if not chain:
                                    st.caption("æš‚æ— ç›¸å…³è®°å½•")
                                    return
                                for idx, item in enumerate(chain, 1):
                                    if not isinstance(item, dict):
                                        continue
                                    st.markdown(f"**{idx}. {item.get('conclusion', 'æ— ç»“è®º')}**")
                                    for label, key in fields:
                                        value = str(item.get(key, "")).strip()
                                        if value:
                                            st.markdown(f"- {label}ï¼š{value}")
                                    st.markdown("---")
                            strengths_chain = reasoning_obj.get("strengths_reasoning_chain") or []
                            weaknesses_chain = reasoning_obj.get("weaknesses_reasoning_chain") or []
                            render_chain(
                                "ä¼˜åŠ¿æ¨ç†é“¾",
                                strengths_chain,
                                [
                                    ("detected_actions", "detected_actions"),
                                    ("resume_evidence", "resume_evidence"),
                                    ("ai_reasoning", "ai_reasoning"),
                                ],
                            )
                            render_chain(
                                "åŠ£åŠ¿æ¨ç†é“¾",
                                weaknesses_chain,
                                [
                                    ("resume_gap", "resume_gap"),
                                    ("compare_to_jd", "compare_to_jd"),
                                    ("ai_reasoning", "ai_reasoning"),
                                ],
                            )

                    # âœ… ä¸€é”®ä¿®å¤ç‰ˆï¼šAI åŒ¹é…å®Œæˆåè‡ªåŠ¨ä¿å­˜ & è·³è½¬

                    # åˆ¤æ–­AIåŒ¹é…ç»“æœæ˜¯å¦ä¸ºç©º
                    if "result_df" in locals() and not result_df.empty:
                        # ä¿å­˜è¯„åˆ†ç»“æœåˆ°session_stateï¼Œä¾›ä¸‹ä¸€æ­¥â€œå»é‡&æ’åºâ€ä½¿ç”¨
                        st.session_state["score_df"] = result_df
                        st.session_state["scored"] = result_df

                        # æ˜¾ç¤ºæˆåŠŸæç¤º
                        st.success("AI åŒ¹é…åˆ†æå®Œæˆ âœ…")
                        st.info("ç³»ç»Ÿå·²è‡ªåŠ¨ä¿å­˜è¯„åˆ†ç»“æœï¼Œè¯·ç‚¹å‡»é¡¶éƒ¨å¯¼èˆªæ ã€3 å»é‡ & æ’åºã€æŸ¥çœ‹ Top-N å€™é€‰äººã€‚")

                        # è‡ªåŠ¨å¯¼å‡ºCSVæ–‡ä»¶åˆ°é¡¹ç›®dataç›®å½•
                        import os
                        output_path = os.path.join("data", "ai_match_results.csv")
                        try:
                            export_df.to_csv(output_path, index=False, encoding="utf-8-sig")
                            st.write(f"âœ… å·²è‡ªåŠ¨ä¿å­˜åŒ¹é…ç»“æœè‡³ `{output_path}`")
                        except Exception as e:
                            st.warning(f"âš ï¸ ä¿å­˜CSVå¤±è´¥: {e}")

                        # ï¼ˆå¯é€‰ï¼‰æä¾›ä¸‹è½½æŒ‰é’®
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½ AI åŒ¹é…ç»“æœï¼ˆCSVï¼‰",
                            data=export_df.to_csv(index=False).encode("utf-8-sig"),
                            file_name="ai_match_results.csv",
                            mime="text/csv"
                        )
                    else:
                        st.warning("âš ï¸ æš‚æ— åŒ¹é…ç»“æœï¼Œè¯·å…ˆå®ŒæˆAIåŒ¹é…è¯„åˆ†åå†å°è¯•ã€‚")
    else:
        st.info("è¯·ä¸Šä¼ ä¸€æ‰¹ç®€å†æ–‡ä»¶å¼€å§‹åˆ†æã€‚")

with tab3:
    st.subheader("å»é‡ & æ’åºï¼ˆå±•ç¤º Top-Nï¼‰")
    topn = st.slider("Top-N", 5, 50, 10)
    score_source = None
    if "score_df" in st.session_state:
        score_source = st.session_state["score_df"]
    elif "scored" in st.session_state:
        score_source = st.session_state["scored"]

    if score_source is not None:
        # å»é‡æ’åº
        deduped = pipe.dedup_and_rank(score_source)
        st.session_state["shortlist"] = deduped.head(topn)
        
        # ä½¿ç”¨ä¸tab2å®Œå…¨ä¸€è‡´çš„å­—æ®µæ˜¾ç¤ºé¡ºåºå’Œé€»è¾‘
        display_columns = [
            "candidate_id",
            "name",
            "file",
            "æ€»åˆ†",
            "æŠ€èƒ½åŒ¹é…åº¦",
            "ç»éªŒç›¸å…³æ€§",
            "æˆé•¿æ½œåŠ›",
            "ç¨³å®šæ€§",
            "short_eval",
            "highlights",
            "resume_mini",
            "è¯æ®",
        ]
        
        # åªé€‰æ‹©å­˜åœ¨çš„åˆ—ï¼Œä¿æŒé¡ºåºï¼ˆä¸tab2é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
        existing_display = [col for col in display_columns if col in deduped.columns]
        if existing_display:
            # åˆ›å»ºæ˜¾ç¤ºç”¨çš„DataFrameå‰¯æœ¬ï¼Œç¡®ä¿æ•°æ®ä¸è¢«ä¿®æ”¹
            deduped_display = deduped.head(topn)[existing_display].copy()
            
            # å¯¹resume_miniè¿›è¡Œé•¿åº¦é™åˆ¶ï¼ˆä¸tab2å®Œå…¨ä¸€è‡´ï¼‰
            if "resume_mini" in deduped_display.columns:
                deduped_display["resume_mini"] = deduped_display["resume_mini"].apply(
                    lambda x: (x[:80] + "â€¦") if isinstance(x, str) and len(x) > 80 else x
                )
            
            # æ±‰åŒ–æ˜¾ç¤ºï¼ˆä¸tab2å®Œå…¨ä¸€è‡´ï¼‰
            deduped_display = translate_dataframe_columns(deduped_display)
            st.dataframe(
                deduped_display,
                use_container_width=True,
                hide_index=True,
            )
        else:
            # å¦‚æœæ²¡æœ‰åŒ¹é…çš„åˆ—ï¼Œæ˜¾ç¤ºåŸå§‹æ•°æ®
            deduped_display = translate_dataframe_columns(deduped.head(topn))
            st.dataframe(deduped_display, use_container_width=True, hide_index=True)
    else:
        st.warning("è¯·å…ˆå®Œæˆè¯„åˆ†")

with tab4:
    st.subheader("ğŸ¤– ä¸€é”®é‚€çº¦ + è‡ªåŠ¨æ’æœŸ")
    st.markdown("è®©AIå¸®ä½ ç”Ÿæˆä¸ªæ€§åŒ–é‚€çº¦é‚®ä»¶ï¼ˆå«å€™é€‰äº®ç‚¹ + æ—¥å†é™„ä»¶ï¼‰")

    # ä¼˜å…ˆä½¿ç”¨å»é‡&æ’åºåçš„shortlistï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹score_df
    shortlist = st.session_state.get("shortlist")
    score_df = st.session_state.get("score_df")
    
    if shortlist is not None and not shortlist.empty:
        # ä½¿ç”¨å»é‡&æ’åºåçš„ç»“æœ
        df = shortlist.copy()
        st.info(f"âœ… å·²ä½¿ç”¨ã€Œå»é‡&æ’åºã€æ­¥éª¤ç­›é€‰åçš„ Top-{len(df)} åå€™é€‰äºº")
    elif score_df is not None and not score_df.empty:
        # å¦‚æœæ²¡æœ‰shortlistï¼Œä½¿ç”¨åŸå§‹score_dfï¼ˆéœ€è¦å…ˆæ’åºï¼‰
        df = score_df.copy()
        # æŒ‰æ€»åˆ†é™åºæ’åº
        if "æ€»åˆ†" in df.columns:
            df = df.sort_values(by="æ€»åˆ†", ascending=False, ignore_index=True)
        elif "score_total" in df.columns:
            df = df.sort_values(by="score_total", ascending=False, ignore_index=True)
        st.warning("âš ï¸ å»ºè®®å…ˆåœ¨ã€Œå»é‡&æ’åºã€æ­¥éª¤ä¸­ç­›é€‰å€™é€‰äººï¼Œå½“å‰ä½¿ç”¨åŸå§‹è¯„åˆ†ç»“æœï¼ˆå·²æŒ‰æ€»åˆ†æ’åºï¼‰")
    else:
        st.warning("è¯·å…ˆå®ŒæˆAIåŒ¹é…è¯„åˆ†ã€‚")
        df = None
    
    if df is not None and not df.empty:
        max_candidates = len(df)
        default_top = min(5, max_candidates)
        top_n = st.number_input(
            "é€‰æ‹©è¦é‚€çº¦çš„å€™é€‰äººæ•°ï¼ˆTop-Nï¼‰",
            min_value=1,
            max_value=max_candidates,
            value=default_top,
            step=1,
        )
        top_n = int(top_n)
        selected_candidates = df.head(top_n)

        score_col = "æ€»åˆ†" if "æ€»åˆ†" in df.columns else "score_total" if "score_total" in df.columns else None
        display_cols = [
            col
            for col in [
                "name",
                "file",
                "email",
                "phone",
                score_col,
                "æŠ€èƒ½åŒ¹é…åº¦",
                "ç»éªŒç›¸å…³æ€§",
                "æˆé•¿æ½œåŠ›",
                "ç¨³å®šæ€§",
                "short_eval",
                "highlights",
                "resume_mini",
            ]
            if col and col in df.columns
        ]
        if not display_cols:
            display_cols = df.columns.tolist()

        st.write(f"å·²é€‰æ‹© {top_n} ä½å€™é€‰äººï¼š")
        st.dataframe(selected_candidates[display_cols], use_container_width=True)

        # æ—¶åŒºé€‰æ‹©ï¼ˆå…¨å±€è®¾ç½®ï¼‰
        timezone = st.selectbox("ğŸŒ æ—¶åŒº", ["Asia/Shanghai", "Asia/Beijing", "UTC"], index=0)
        
        # ä¸ºæ¯ä½å€™é€‰äººå•ç‹¬è®¾ç½®é¢è¯•æ—¶é—´
        st.markdown("### ğŸ“… ä¸ºæ¯ä½å€™é€‰äººè®¾ç½®é¢è¯•æ—¶é—´")
        st.info("ğŸ’¡ æ¯ä½å€™é€‰äººå¯ä»¥è®¾ç½®ä¸åŒçš„é¢è¯•æ—¶é—´ï¼Œé¿å…ç¾¤é¢å†²çª")
        
        candidate_interview_times = {}
        candidate_interview_locations = {}
        
        # é»˜è®¤é¢è¯•æ—¶é—´å’Œåœ°ç‚¹
        default_date = datetime.now().date() + timedelta(days=1)
        default_time = datetime.strptime("14:00", "%H:%M").time()
        default_location = "å…¬å¸ä¼šè®®å®¤ï¼ˆå…·ä½“åœ°å€å¾…ç¡®è®¤ï¼‰"
        
        for idx, (_, row) in enumerate(selected_candidates.iterrows()):
            row_dict = row.to_dict()
            candidate_name = row_dict.get("name") or row_dict.get("file") or f"å€™é€‰äºº{idx+1}"
            
            with st.expander(f"ğŸ“… {candidate_name} çš„é¢è¯•å®‰æ’", expanded=(idx == 0)):
                col_date, col_time = st.columns(2)
                with col_date:
                    # ä»session_stateè·å–ä¹‹å‰è®¾ç½®çš„æ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                    date_key = f"interview_date_{idx}"
                    prev_date = st.session_state.get(date_key, default_date)
                    interview_date = st.date_input(
                        "é¢è¯•æ—¥æœŸ",
                        value=prev_date,
                        key=date_key,
                        label_visibility="visible"
                    )
                with col_time:
                    time_key = f"interview_time_{idx}"
                    prev_time = st.session_state.get(time_key, default_time)
                    interview_hour = st.time_input(
                        "é¢è¯•æ—¶é—´",
                        value=prev_time,
                        key=time_key,
                        label_visibility="visible"
                    )
                
                # æ ¼å¼åŒ–é¢è¯•æ—¶é—´å­—ç¬¦ä¸²
                interview_datetime = datetime.combine(interview_date, interview_hour)
                interview_time_str = f"{interview_datetime.strftime('%Y-%m-%d %H:%M')}, {timezone}"
                candidate_interview_times[idx] = interview_time_str
                
                # é¢è¯•åœ°ç‚¹ï¼ˆå¯ä»¥ä¸ºæ¯ä¸ªå€™é€‰äººå•ç‹¬è®¾ç½®ï¼‰
                location_key = f"interview_location_{idx}"
                prev_location = st.session_state.get(location_key, default_location if idx == 0 else "")
                interview_location = st.text_input(
                    "ğŸ“ é¢è¯•åœ°ç‚¹",
                    value=prev_location,
                    key=location_key,
                    help="å¯ä¸ºæ¯ä½å€™é€‰äººè®¾ç½®ä¸åŒçš„é¢è¯•åœ°ç‚¹",
                    label_visibility="visible"
                )
                candidate_interview_locations[idx] = interview_location or default_location
        
        # å…¨å±€é¢è¯•åœ°ç‚¹å’Œæ—¶é—´ï¼ˆå¦‚æœæ‰€æœ‰å€™é€‰äººä½¿ç”¨ç›¸åŒåœ°ç‚¹å’Œæ—¶é—´ï¼Œå¯ä»¥åœ¨è¿™é‡Œè®¾ç½®ï¼‰
        st.markdown("---")
        st.markdown("### ğŸŒ ç»Ÿä¸€é¢è¯•è®¾ç½®ï¼ˆå¯é€‰ï¼‰")
        st.info("ğŸ’¡ å¦‚æœæ‰€æœ‰å€™é€‰äººä½¿ç”¨ç›¸åŒçš„æ—¶é—´å’Œåœ°ç‚¹ï¼Œå¯ä»¥åœ¨è¿™é‡Œç»Ÿä¸€è®¾ç½®ï¼Œå°†è¦†ç›–ä¸Šè¿°å•ç‹¬è®¾ç½®")
        
        # æ˜¯å¦å¯ç”¨ç»Ÿä¸€é¢è¯•æ—¶é—´
        use_unified_time = st.checkbox("âœ… ä½¿ç”¨ç»Ÿä¸€é¢è¯•æ—¶é—´", value=False, help="å‹¾é€‰åï¼Œæ‰€æœ‰å€™é€‰äººå°†ä½¿ç”¨ç›¸åŒçš„é¢è¯•æ—¶é—´")
        
        # ç»Ÿä¸€é¢è¯•æ—¶é—´ï¼ˆä»…åœ¨å¯ç”¨æ—¶æ˜¾ç¤ºï¼‰
        unified_interview_time_str = None
        if use_unified_time:
            col_unified_date, col_unified_time = st.columns(2)
            with col_unified_date:
                unified_date_key = "unified_interview_date"
                prev_unified_date = st.session_state.get(unified_date_key, default_date)
                unified_interview_date = st.date_input(
                    "ğŸ“… ç»Ÿä¸€é¢è¯•æ—¥æœŸ",
                    value=prev_unified_date,
                    key=unified_date_key,
                    help="å°†åº”ç”¨äºæ‰€æœ‰å€™é€‰äºº",
                    label_visibility="visible"
                )
            with col_unified_time:
                unified_time_key = "unified_interview_time"
                prev_unified_time = st.session_state.get(unified_time_key, default_time)
                unified_interview_hour = st.time_input(
                    "â° ç»Ÿä¸€é¢è¯•æ—¶é—´",
                    value=prev_unified_time,
                    key=unified_time_key,
                    help="å°†åº”ç”¨äºæ‰€æœ‰å€™é€‰äºº",
                    label_visibility="visible"
                )
            
            # æ ¼å¼åŒ–ç»Ÿä¸€é¢è¯•æ—¶é—´å­—ç¬¦ä¸²
            unified_interview_datetime = datetime.combine(unified_interview_date, unified_interview_hour)
            unified_interview_time_str = f"{unified_interview_datetime.strftime('%Y-%m-%d %H:%M')}, {timezone}"
        
        # ç»Ÿä¸€é¢è¯•åœ°ç‚¹
        interview_location = st.text_input("ğŸ“ ç»Ÿä¸€é¢è¯•åœ°ç‚¹ï¼ˆå¯é€‰ï¼Œå¦‚ä¸ºç©ºåˆ™ä½¿ç”¨ä¸Šè¿°å•ç‹¬è®¾ç½®çš„åœ°ç‚¹ï¼‰", value="", help="å¦‚æœæ‰€æœ‰å€™é€‰äººä½¿ç”¨ç›¸åŒåœ°ç‚¹ï¼Œå¯ä»¥åœ¨è¿™é‡Œç»Ÿä¸€è®¾ç½®")
        
        organizer_email = st.text_input("ğŸ“§ é¢è¯•ç»„ç»‡è€…é‚®ç®±", value=os.getenv("SMTP_USER", "hr@company.com"))
        
        # ä¼ä¸šå¾®ä¿¡é…ç½®ï¼ˆå¯é€‰ï¼‰
        with st.expander("ğŸ“± ä¼ä¸šå¾®ä¿¡é…ç½®ï¼ˆå¯é€‰ï¼‰"):
            organizer_name = st.text_input("ç»„ç»‡è€…å§“å", "HR", help="ç”¨äºä¼ä¸šå¾®ä¿¡æ¶ˆæ¯ä¸­çš„è”ç³»äººæ˜¾ç¤º", key="organizer_name")
            organizer_wechat = st.text_input("ç»„ç»‡è€…ä¼ä¸šå¾®ä¿¡ID", "", help="å¯é€‰ï¼Œç”¨äºç”Ÿæˆä¼ä¸šå¾®ä¿¡æ·»åŠ é“¾æ¥", key="organizer_wechat")
            meeting_link = st.text_input("ä¼šè®®é“¾æ¥ï¼ˆå¯é€‰ï¼‰", "", help="å¦‚ï¼šè…¾è®¯ä¼šè®®é“¾æ¥ã€Zoomé“¾æ¥ç­‰", key="meeting_link")

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç”Ÿæˆçš„é‚®ä»¶
        existing_invites = st.session_state.get("invite_results", [])
        show_existing = False
        if existing_invites and len(existing_invites) > 0:
            st.info(f"ğŸ’¡ æ£€æµ‹åˆ°å·²æœ‰ {len(existing_invites)} å°å·²ç”Ÿæˆçš„é‚®ä»¶ï¼Œæ‚¨å¯ä»¥ç»§ç»­ç¼–è¾‘æˆ–ç›´æ¥å‘é€ã€‚å¦‚éœ€é‡æ–°ç”Ÿæˆï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ã€‚")
            show_existing = True
        
        if st.button("ğŸš€ ä¸€é”®ç”Ÿæˆé‚€çº¦é‚®ä»¶ + ICS"):
            # è·å–ä¼ä¸šå¾®ä¿¡é…ç½®ï¼ˆå¦‚æœæœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
            organizer_name = st.session_state.get("organizer_name", "HR")
            organizer_wechat = st.session_state.get("organizer_wechat", "")
            meeting_link = st.session_state.get("meeting_link", "")
            st.info("AI æ­£åœ¨ç”Ÿæˆä¸ªæ€§åŒ–é‚€çº¦å†…å®¹ï¼Œè¯·ç¨å€™...")

            invite_results = []
            invites_dir = "reports/invites"
            os.makedirs(invites_dir, exist_ok=True)

            job_title = st.session_state.get("job_name") or "ç›®æ ‡å²—ä½"

            # ç”Ÿæˆé»˜è®¤é¢è¯•æ—¶é—´ä½œä¸ºfallback
            default_interview_datetime = datetime.combine(default_date, default_time)
            default_interview_time_str = f"{default_interview_datetime.strftime('%Y-%m-%d %H:%M')}, {timezone}"

            for idx, (_, row) in enumerate(selected_candidates.iterrows()):
                row_dict = row.to_dict()
                # ä¼˜å…ˆä½¿ç”¨nameå­—æ®µï¼ˆå§“åï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨fileå­—æ®µï¼ˆæ–‡ä»¶åï¼‰ï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
                candidate_name_raw = row_dict.get("name") or row_dict.get("file") or "åŒ¿åå€™é€‰äºº"
                # æ·»åŠ å…ˆç”Ÿ/å¥³å£«ç§°å‘¼
                candidate_name = add_name_title(candidate_name_raw, row_dict)
                candidate_email = row_dict.get("email", "")
                candidate_score = row_dict.get("æ€»åˆ†") or row_dict.get("score_total") or row_dict.get("score", "æœªçŸ¥")

                # è·å–è¯¥å€™é€‰äººçš„é¢è¯•æ—¶é—´å’Œåœ°ç‚¹
                # å¦‚æœå¯ç”¨äº†ç»Ÿä¸€æ—¶é—´ï¼Œä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€æ—¶é—´ï¼›å¦åˆ™ä½¿ç”¨å€™é€‰äººå•ç‹¬è®¾ç½®çš„æ—¶é—´
                if use_unified_time and unified_interview_time_str:
                    candidate_interview_time = unified_interview_time_str
                else:
                    candidate_interview_time = candidate_interview_times.get(idx, default_interview_time_str)
                
                # å¦‚æœè®¾ç½®äº†ç»Ÿä¸€åœ°ç‚¹ï¼Œä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€åœ°ç‚¹ï¼›å¦åˆ™ä½¿ç”¨å€™é€‰äººå•ç‹¬è®¾ç½®çš„åœ°ç‚¹
                if interview_location and interview_location.strip():
                    candidate_interview_location = interview_location
                else:
                    candidate_interview_location = candidate_interview_locations.get(idx, default_location)

                try:
                    candidate_highlight = generate_ai_summary(row_dict)
                except Exception as e:
                    candidate_highlight = f"AI æ€»ç»“å¤±è´¥ï¼š{e}"

                try:
                    # ç”ŸæˆICSæ–‡ä»¶æè¿°
                    ics_description = f"è¯·å‡†æ—¶å‚åŠ é¢è¯•ã€‚å¦‚éœ€è°ƒæ•´æ—¶é—´è¯·åŠæ—¶è”ç³»HRã€‚\nå²—ä½ï¼š{job_title}\né¢è¯•åœ°ç‚¹ï¼š{candidate_interview_location or 'å¾…ç¡®è®¤'}"
                    ics_path = create_ics_file(
                        title=f"{job_title}å²—ä½é¢è¯•",
                        start_time=candidate_interview_time,
                        organizer=organizer_email,
                        attendee=candidate_email or "candidate@example.com",
                        location=candidate_interview_location or "",
                        description=ics_description,
                    )
                except Exception as e:
                    st.warning(f"ç”Ÿæˆ {candidate_name} çš„æ—¥å†æ–‡ä»¶å¤±è´¥ï¼š{e}")
                    ics_path = ""

                try:
                    email_body = generate_ai_email(
                        name=candidate_name,
                        highlights=candidate_highlight,
                        position=job_title,
                        score=candidate_score,
                        ics_path=ics_path or "(é™„ä»¶ç”Ÿæˆå¤±è´¥)",
                    )
                    # åœ¨é‚®ä»¶æ­£æ–‡ä¸­æ·»åŠ é¢è¯•åœ°ç‚¹ä¿¡æ¯
                    if candidate_interview_location and candidate_interview_location.strip():
                        location_note = f"\n\nğŸ“ é¢è¯•åœ°ç‚¹ï¼š{candidate_interview_location}"
                        email_body = email_body + location_note
                except Exception as e:
                    email_body = f"AI é‚®ä»¶ç”Ÿæˆå¤±è´¥ï¼š{e}"

                # ç”Ÿæˆé‚®ä»¶ä¸»é¢˜ï¼šå…³äº {å§“å} åº”è˜ {å²—ä½} çš„é¢è¯•å®‰æ’é€šçŸ¥
                email_subject = f"å…³äº {candidate_name} åº”è˜ {job_title} çš„é¢è¯•å®‰æ’é€šçŸ¥"

                invite_results.append(
                    {
                        "name": candidate_name,
                        "email": candidate_email,
                        "ics": ics_path,
                        "body": email_body,
                        "subject": email_subject,
                        "highlights": candidate_highlight,
                        "score": candidate_score,
                        "position": job_title,
                        "interview_time": candidate_interview_time,
                        "interview_location": candidate_interview_location,
                    }
                )

            json_payload = json.dumps(invite_results, ensure_ascii=False, indent=2)
            json_path = os.path.join(invites_dir, f"invite_batch_{datetime.now().strftime('%Y%m%d_%H%M')}.json")
            with open(json_path, "w", encoding="utf-8") as fp:
                fp.write(json_payload)

            st.success("âœ… AI ä¸ªæ€§åŒ–é‚€çº¦ç”Ÿæˆå®Œæˆï¼")
            
            # ä¿å­˜åˆ°session_stateï¼Œä¾›åç»­ç¼–è¾‘å’Œå‘é€ä½¿ç”¨
            st.session_state["invite_results"] = invite_results
            st.session_state["job_title"] = job_title
            # ä¿å­˜æ¯ä¸ªå€™é€‰äººçš„é¢è¯•æ—¶é—´é…ç½®ï¼ˆç”¨äºåç»­ç¼–è¾‘ï¼‰
            st.session_state["candidate_interview_times"] = candidate_interview_times
            st.session_state["candidate_interview_locations"] = candidate_interview_locations
        
        # æ˜¾ç¤ºé‚®ä»¶é¢„è§ˆå’Œç¼–è¾‘åŠŸèƒ½ï¼ˆæ— è®ºæ˜¯æ–°ç”Ÿæˆè¿˜æ˜¯å·²æœ‰é‚®ä»¶ï¼‰
        invite_results = st.session_state.get("invite_results", [])
        if invite_results and len(invite_results) > 0:
            job_title = st.session_state.get("job_title", "ç›®æ ‡å²—ä½")
            # interview_time å’Œ interview_location åœ¨å·²æœ‰é‚®ä»¶æ—¶ä»session_stateè·å–ï¼Œæ–°ç”Ÿæˆæ—¶ä½¿ç”¨ä¸Šé¢çš„å€¼
            default_interview_time = f"{datetime.combine(datetime.now().date() + timedelta(days=1), datetime.strptime('14:00', '%H:%M').time()).strftime('%Y-%m-%d %H:%M')}, {timezone}"
            interview_time = st.session_state.get("interview_time", default_interview_time)
            interview_location = st.session_state.get("interview_location", "å…¬å¸ä¼šè®®å®¤ï¼ˆå…·ä½“åœ°å€å¾…ç¡®è®¤ï¼‰")
            
            # é‚®ä»¶é¢„è§ˆå’Œç¼–è¾‘åŠŸèƒ½
            st.markdown("### ğŸ“§ é‚®ä»¶é¢„è§ˆä¸ç¼–è¾‘")
            st.info("ğŸ’¡ åœ¨å‘é€å‰ï¼Œæ‚¨å¯ä»¥é¢„è§ˆå’Œç¼–è¾‘æ¯å°é‚®ä»¶çš„å†…å®¹")
            
            for idx, invite in enumerate(invite_results):
                with st.expander(f"ğŸ“§ {invite.get('name', f'å€™é€‰äºº{idx+1}')} - {invite.get('email', '')}", expanded=(idx == 0)):
                    col_preview1, col_preview2 = st.columns([2, 1])
                    
                    with col_preview1:
                        st.markdown("**é‚®ä»¶ä¸»é¢˜ï¼š**")
                        subject_key = f"subject_{idx}"
                        # æ™ºèƒ½è¯†åˆ«å²—ä½å’Œå§“åï¼šä¼˜å…ˆä½¿ç”¨inviteä¸­çš„positionå’Œnameï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨job_titleå’Œé»˜è®¤å€¼
                        position_for_subject = invite.get("position", job_title)
                        candidate_name_for_subject = invite.get("name", "æ‚¨")
                        email_subject = st.text_input(
                            "ä¸»é¢˜",
                            value=invite.get("subject", f"å…³äº {candidate_name_for_subject} åº”è˜ {position_for_subject} çš„é¢è¯•å®‰æ’é€šçŸ¥"),
                            key=subject_key,
                            label_visibility="collapsed"
                        )
                        
                        st.markdown("**é‚®ä»¶æ­£æ–‡ï¼š**")
                        body_key = f"body_{idx}"
                        edited_body = st.text_area(
                            "æ­£æ–‡",
                            value=invite.get("body", ""),
                            height=300,
                            key=body_key,
                            label_visibility="collapsed"
                        )
                        
                        # æ›´æ–°invite_resultsä¸­çš„å†…å®¹
                        invite_results[idx]["body"] = edited_body
                        invite_results[idx]["subject"] = email_subject
                    
                    with col_preview2:
                        st.markdown("**é‚®ä»¶ä¿¡æ¯ï¼š**")
                        st.write(f"ğŸ“§ **æ”¶ä»¶äººï¼š** {invite.get('email', 'æœªæä¾›')}")
                        st.write(f"ğŸ“… **é¢è¯•æ—¶é—´ï¼š** {invite.get('interview_time', 'æœªè®¾ç½®')}")
                        st.write(f"ğŸ“ **é¢è¯•åœ°ç‚¹ï¼š** {invite.get('interview_location', 'æœªè®¾ç½®')}")
                        st.write(f"ğŸ’¼ **å²—ä½ï¼š** {invite.get('position', 'æœªè®¾ç½®')}")
                        st.write(f"â­ **è¯„åˆ†ï¼š** {invite.get('score', 'æœªçŸ¥')}")
                        
                        if invite.get("ics"):
                            st.success("âœ… æ—¥å†é™„ä»¶å·²ç”Ÿæˆ")
                        else:
                            st.warning("âš ï¸ æ—¥å†é™„ä»¶æœªç”Ÿæˆ")
                        
                        st.markdown("**äº®ç‚¹æ‘˜è¦ï¼š**")
                        st.caption(invite.get("highlights", "æ— ")[:200])
            
            # æ›´æ–°session_stateä¸­çš„ç¼–è¾‘åå†…å®¹
            st.session_state["invite_results"] = invite_results
            
            # ä¿å­˜JSONæ–‡ä»¶
            json_payload = json.dumps(invite_results, ensure_ascii=False, indent=2)
            json_path = os.path.join("reports/invites", f"invite_batch_{datetime.now().strftime('%Y%m%d_%H%M')}.json")
            os.makedirs("reports/invites", exist_ok=True)
            with open(json_path, "w", encoding="utf-8") as fp:
                fp.write(json_payload)
            
            # ä¼ä¸šå¾®ä¿¡é›†æˆ
            st.markdown("### ğŸ“± ä¼ä¸šå¾®ä¿¡é‚€çº¦")
            try:
                from backend.services.wechat_integration import create_wechat_invite_template
                
                wechat_results = []
                for invite in invite_results:
                    wechat_data = create_wechat_invite_template({
                        "name": invite.get("name", ""),
                        "email": invite.get("email", ""),
                        "position": invite.get("position", job_title),
                        "interview_time": invite.get("interview_time", interview_time),
                        "highlights": invite.get("highlights", ""),
                        "meeting_link": meeting_link,
                        "organizer_name": organizer_name,
                        "organizer_wechat": organizer_wechat,
                    })
                    wechat_results.append(wechat_data)
                
                # æ˜¾ç¤ºä¼ä¸šå¾®ä¿¡æ¶ˆæ¯ï¼ˆå¯å¤åˆ¶ï¼‰
                for idx, (invite, wechat_data) in enumerate(zip(invite_results, wechat_results)):
                    with st.expander(f"ğŸ“± {invite.get('name', f'å€™é€‰äºº{idx+1}')} - ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯"):
                        st.text_area(
                            "ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯å†…å®¹ï¼ˆç‚¹å‡»å¤åˆ¶ï¼‰",
                            value=wechat_data.get("wechat_message", ""),
                            height=200,
                            key=f"wechat_msg_{idx}",
                            help="å¤åˆ¶æ­¤å†…å®¹åˆ°ä¼ä¸šå¾®ä¿¡å‘é€ç»™å€™é€‰äºº"
                        )
                        if wechat_data.get("meeting_link"):
                            st.write(f"ğŸ”— ä¼šè®®é“¾æ¥ï¼š{wechat_data.get('meeting_link')}")
                        if wechat_data.get("wechat_link"):
                            st.write(f"ğŸ“± {wechat_data.get('wechat_link')}")
            except Exception as e:
                st.info(f"ğŸ’¡ ä¼ä¸šå¾®ä¿¡åŠŸèƒ½ï¼š{str(e)}")
            
            # é‚®ä»¶å¯¼å…¥ä¼ä¸šé‚®ç®±
            st.markdown("### ğŸ“§ é‚®ä»¶å¯¼å…¥ä¼ä¸šé‚®ç®±")
            col1, col2 = st.columns(2)
            
            with col1:
                try:
                    from backend.services.email_integration import generate_email_import_file, generate_outlook_import_csv
                    
                    if st.button("ğŸ“¥ ç”Ÿæˆé‚®ä»¶å¯¼å…¥æ–‡ä»¶ï¼ˆ.emlï¼‰"):
                        with st.spinner("æ­£åœ¨ç”Ÿæˆé‚®ä»¶å¯¼å…¥æ–‡ä»¶..."):
                            import_path = generate_email_import_file(invite_results)
                            if import_path:
                                st.success(f"âœ… é‚®ä»¶æ–‡ä»¶å·²ç”Ÿæˆï¼š`{import_path}`")
                                st.info("ğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼š\n1. Outlookï¼šæ–‡ä»¶ -> æ‰“å¼€ -> å…¶ä»–æ–‡ä»¶ -> é€‰æ‹© .eml æ–‡ä»¶\n2. ä¼ä¸šé‚®ç®±ï¼šè®¾ç½® -> å¯¼å…¥é‚®ä»¶ -> é€‰æ‹© .eml æ–‡ä»¶")
                            else:
                                st.warning("âš ï¸ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®")
                except Exception as e:
                    st.warning(f"é‚®ä»¶å¯¼å…¥åŠŸèƒ½ï¼š{str(e)}")
            
            with col2:
                try:
                    if st.button("ğŸ“‹ ç”ŸæˆOutlookå¯¼å…¥CSV"):
                        with st.spinner("æ­£åœ¨ç”ŸæˆCSVæ–‡ä»¶..."):
                            csv_path = generate_outlook_import_csv(invite_results)
                            if csv_path:
                                with open(csv_path, 'rb') as f:
                                    st.download_button(
                                        "â¬‡ï¸ ä¸‹è½½Outlookå¯¼å…¥CSV",
                                        data=f.read(),
                                        file_name=os.path.basename(csv_path),
                                        mime="text/csv"
                                    )
                                st.success(f"âœ… CSVæ–‡ä»¶å·²ç”Ÿæˆï¼š`{csv_path}`")
                except Exception as e:
                    st.warning(f"CSVç”ŸæˆåŠŸèƒ½ï¼š{str(e)}")
            
            # SMTPé‚®ä»¶å‘é€ï¼ˆå¯é€‰ï¼‰
            with st.expander("ğŸ“® é€šè¿‡SMTPç›´æ¥å‘é€é‚®ä»¶ï¼ˆéœ€è¦é…ç½®ï¼‰", expanded=True):
                st.info("ğŸ’¡ éœ€è¦åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹å‚æ•°ï¼š\n- SMTP_SERVERï¼ˆå¦‚ï¼šsmtp.exmail.qq.comï¼‰\n- SMTP_PORTï¼ˆé»˜è®¤587ï¼‰\n- SMTP_USERï¼ˆé‚®ç®±åœ°å€ï¼‰\n- SMTP_PASSWORDï¼ˆé‚®ç®±å¯†ç æˆ–æˆæƒç ï¼‰")
                
                smtp_server = st.text_input("SMTPæœåŠ¡å™¨", os.getenv("SMTP_SERVER", ""), help="å¦‚ï¼šsmtp.exmail.qq.com")
                smtp_port = st.number_input("SMTPç«¯å£", value=int(os.getenv("SMTP_PORT", "587")), min_value=1, max_value=65535)
                smtp_user = st.text_input("SMTPç”¨æˆ·åï¼ˆé‚®ç®±ï¼‰", os.getenv("SMTP_USER", ""))
                smtp_password = st.text_input("SMTPå¯†ç /æˆæƒç ", type="password", value=os.getenv("SMTP_PASSWORD", ""))
                
                # å‘é€å‰ç¡®è®¤
                if st.button("ğŸ“¤ æ‰¹é‡å‘é€é‚®ä»¶", type="primary"):
                    if not smtp_server or not smtp_user or not smtp_password:
                        st.error("âŒ è¯·å…ˆé…ç½®SMTPå‚æ•°")
                    elif not invite_results:
                        st.error("âŒ æ²¡æœ‰å¯å‘é€çš„é‚®ä»¶ï¼Œè¯·å…ˆç”Ÿæˆé‚€çº¦é‚®ä»¶")
                    else:
                        try:
                            from backend.services.email_integration import send_email_via_smtp
                            
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            success_count = 0
                            fail_count = 0
                            send_results = []
                            
                            total = len(invite_results)
                            for idx, invite in enumerate(invite_results):
                                candidate_name = invite.get("name", f"å€™é€‰äºº{idx+1}")
                                candidate_email = invite.get("email", "")
                                
                                # æ›´æ–°è¿›åº¦
                                progress = (idx + 1) / total
                                progress_bar.progress(progress)
                                status_text.text(f"æ­£åœ¨å‘é€ ({idx + 1}/{total}): {candidate_name} ({candidate_email})")
                                
                                # è·å–ç¼–è¾‘åçš„é‚®ä»¶å†…å®¹ï¼Œæ™ºèƒ½è¯†åˆ«å²—ä½å’Œå§“å
                                position_for_subject = invite.get("position", job_title)
                                candidate_name_for_subject = invite.get("name", "æ‚¨")
                                email_subject = invite.get("subject", f"å…³äº {candidate_name_for_subject} åº”è˜ {position_for_subject} çš„é¢è¯•å®‰æ’é€šçŸ¥")
                                email_body = invite.get("body", "")
                                
                                if not candidate_email or not candidate_email.strip():
                                    result = {
                                        "success": False,
                                        "message": "æ”¶ä»¶äººé‚®ç®±ä¸ºç©º"
                                    }
                                else:
                                    result = send_email_via_smtp(
                                        to_email=candidate_email,
                                        subject=email_subject,
                                        body=email_body,
                                        ics_path=invite.get("ics", ""),
                                        smtp_server=smtp_server,
                                        smtp_port=smtp_port,
                                        smtp_user=smtp_user,
                                        smtp_password=smtp_password,
                                        from_email=smtp_user
                                    )
                                
                                send_results.append({
                                    "name": candidate_name,
                                    "email": candidate_email,
                                    "success": result.get("success", False),
                                    "message": result.get("message", "")
                                })
                                
                                if result.get("success"):
                                    success_count += 1
                                else:
                                    fail_count += 1
                            
                            progress_bar.empty()
                            status_text.empty()
                            
                            # æ˜¾ç¤ºå‘é€ç»“æœ
                            st.markdown("### ğŸ“Š å‘é€ç»“æœ")
                            if success_count > 0:
                                st.success(f"âœ… æˆåŠŸå‘é€ {success_count} å°é‚®ä»¶")
                            if fail_count > 0:
                                st.error(f"âŒ å‘é€å¤±è´¥ {fail_count} å°é‚®ä»¶")
                            
                            # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                            with st.expander("ğŸ“‹ è¯¦ç»†å‘é€ç»“æœ", expanded=(fail_count > 0)):
                                for result in send_results:
                                    if result["success"]:
                                        st.success(f"âœ… {result['name']} ({result['email']}) - å‘é€æˆåŠŸ")
                                    else:
                                        st.error(f"âŒ {result['name']} ({result['email']}) - {result['message']}")
                            
                            # ä¿å­˜å‘é€ç»“æœ
                            st.session_state["send_results"] = send_results
                            
                        except Exception as e:
                            st.error(f"âŒ å‘é€å¤±è´¥ï¼š{str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
            
            st.download_button(
                "ğŸ“¥ ä¸‹è½½é‚€çº¦ç»“æœï¼ˆJSONï¼‰",
                data=json_payload,
                file_name="ai_invites.json",
                mime="application/json",
            )

            # ä¿å­˜å¾…é¢è¯•æ¸…å•ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
            pending_path = "reports/pending_interviews.csv"
            try:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                import os
                os.makedirs("reports", exist_ok=True)
                
                # å°è¯•å†™å…¥æ–‡ä»¶
                pd.DataFrame(invite_results).to_csv(pending_path, index=False, encoding="utf-8-sig")
                st.write(f"ğŸ“‹ å·²è‡ªåŠ¨æ›´æ–°å¾…é¢è¯•æ¸…å•ï¼š`{pending_path}`")
            except PermissionError:
                # å¦‚æœæ–‡ä»¶è¢«å ç”¨ï¼ˆå¦‚ Excel æ‰“å¼€ï¼‰ï¼Œä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                pending_path_alt = f"reports/pending_interviews_{timestamp}.csv"
                try:
                    pd.DataFrame(invite_results).to_csv(pending_path_alt, index=False, encoding="utf-8-sig")
                    st.warning(f"âš ï¸ åŸæ–‡ä»¶è¢«å ç”¨ï¼Œå·²ä¿å­˜åˆ°ï¼š`{pending_path_alt}`")
                    st.info("ğŸ’¡ æç¤ºï¼šè¯·å…³é—­å¯èƒ½æ­£åœ¨æ‰“å¼€ `pending_interviews.csv` çš„ç¨‹åºï¼ˆå¦‚ Excelï¼‰")
                except Exception as e:
                    st.warning(f"âš ï¸ ä¿å­˜å¾…é¢è¯•æ¸…å•å¤±è´¥ï¼š{str(e)}")
            except Exception as e:
                st.warning(f"âš ï¸ ä¿å­˜å¾…é¢è¯•æ¸…å•å¤±è´¥ï¼š{str(e)}")

            st.json(invite_results, expanded=False)

with tab5:
    st.subheader("é¢è¯•åŒ… & å¯¼å‡ºæŠ¥è¡¨")
    if st.button("å¯¼å‡ºæœ¬è½®æŠ¥è¡¨"):
        score_df = st.session_state.get("score_df", None)
        scored_df = st.session_state.get("scored", None)

        if score_df is not None and not score_df.empty:
            score_source = score_df
        elif scored_df is not None and not scored_df.empty:
            score_source = scored_df
        else:
            st.warning("æœªæ‰¾åˆ°å¯å¯¼å‡ºçš„è¯„åˆ†æ•°æ®ï¼Œè¯·å…ˆå®Œæˆ AI åŒ¹é…è¯„åˆ†ã€‚")
            st.stop()

        path = export_round_report(score_source)
        st.success("å·²å¯¼å‡ºï¼š" + path)

