# ======================================================
# ğŸ§  ResumeAI é˜²å¹»è§‰ä¸è¡Œä¸šçº åå¼•æ“ï¼ˆFinal Ver.ï¼‰
# ä½œè€…ï¼šChatGPT ä¼ä¸šçº§ä¼˜åŒ–ç‰ˆ
# åŠŸèƒ½ï¼š
#   - é¿å… GPT è‡ªåŠ¨ç¼–é€ "ç«èµ›è·å¥–""æ•™å­¦ç»éªŒ"ç­‰è™šå‡å†…å®¹
#   - æ ¹æ®å²—ä½è¯­ä¹‰è‡ªåŠ¨ä¿®æ­£è¾“å‡ºç»“æœ
#   - æ”¯æŒæ‰€æœ‰è¡Œä¸šï¼ˆé”€å”®/è¿è¥/æ•™è‚²/æŠ€æœ¯/è¡Œæ”¿ç­‰ï¼‰
# ======================================================

import re

# å¯¼å…¥ç»Ÿä¸€çš„é˜²å¹»è§‰å‡½æ•°
from backend.utils.sanitize import sanitize_ai_output as _sanitize_ai_output

# ğŸš§ å®šä¹‰è¡Œä¸šå…³é”®å­—ï¼ˆè¯­ä¹‰è¯†åˆ«å±‚ï¼‰
JOB_DOMAINS = {
    "é”€å”®": ["é”€å”®", "é¡¾é—®", "ç”µé”€", "é‚€çº¦", "è½¬åŒ–", "å•†åŠ¡", "å®¢æˆ·", "è¯¾ç¨‹"],
    "è¿è¥": ["è¿è¥", "æ¨å¹¿", "ç­–åˆ’", "æ–°åª’ä½“", "å°çº¢ä¹¦", "æŠ–éŸ³", "å…¬ä¼—å·"],
    "æ•™è‚²": ["æ•™å­¦", "è®²å¸ˆ", "æ•™å¸ˆ", "è¾…å¯¼", "å­¦å‘˜", "è¯¾ç¨‹è®¾è®¡", "åŸ¹è®­å¸ˆ"],
    "æŠ€æœ¯": ["å¼€å‘", "å·¥ç¨‹å¸ˆ", "æµ‹è¯•", "ç³»ç»Ÿ", "ç®—æ³•", "ä»£ç "],
    "è¡Œæ”¿": ["è¡Œæ”¿", "äººäº‹", "æ¡£æ¡ˆ", "ç»©æ•ˆ", "è€ƒå‹¤"]
}

# ğŸš« æ˜ç¡®ç¦æ­¢å‡ºç°åœ¨éæ•™è‚²ç±»ç®€å†çš„çŸ­è¯­
FORBIDDEN_EDU_PHRASES = [
    "ç«èµ›", "æ¯”èµ›", "è·å¥–", "è¾…å¯¼", "æ•™å­¦", "æˆè¯¾", "å­¦ç”Ÿ", "è¯¾å ‚", "è®²è§£", "æ•™è‚²èƒŒæ™¯", "æ•™å¸ˆèµ„æ ¼"
]

# ğŸš« æ˜ç¡®ç¦æ­¢å‡ºç°åœ¨éå­¦æœ¯ç±»æ–‡æœ¬çš„å¹»è§‰æ¨¡æ¿
AI_HALLUCINATION_PATTERNS = [
    r"è·å¾—.{0,6}ç«èµ›å¥–", r"æ‹¥æœ‰.{0,6}æ•™å­¦ç»éªŒ", r"æŒ‡å¯¼.{0,6}å­¦ç”Ÿ", r"è¾…å¯¼.{0,6}æ¯”èµ›",
    r"å‚åŠ .{0,6}ç«èµ›", r"æˆè¯¾", r"æ•™è‚²è¡Œä¸šèƒŒæ™¯", r"æ•™å¸ˆèŒä¸šèµ„æ ¼"
]

def clean_text(text: str) -> str:
    """ç»Ÿä¸€æ–‡æœ¬æ ¼å¼"""
    text = text.lower().strip()
    text = re.sub(r"\s+", " ", text)
    return text

def detect_job_domain(job_title: str) -> str:
    """è‡ªåŠ¨åˆ¤æ–­å²—ä½ç±»å‹"""
    for domain, keywords in JOB_DOMAINS.items():
        if any(k in job_title for k in keywords):
            return domain
    return "æœªçŸ¥"

def sanitize_ai_output(ai_text: str, job_title: str) -> str:
    """
    ğŸš€ ä¸»å‡½æ•°ï¼šé˜²æ­¢å¹»è§‰å†…å®¹å‡ºç°åœ¨AIè¾“å‡ºä¸­ï¼ˆç»ˆæç‰ˆï¼‰
    ä½¿ç”¨ç»Ÿä¸€çš„é˜²å¹»è§‰æ€»æ§æ¨¡å—
    """
    return _sanitize_ai_output(ai_text, job_title)


# ---------------- å‘åå…¼å®¹å‡½æ•°ï¼ˆä¿ç•™ï¼‰ -----------------
def clean_resume_text(text: str) -> str:
    """æ ‡å‡†åŒ–ã€å»å™ªï¼ˆå‘åå…¼å®¹ï¼‰"""
    return clean_text(text)

def detect_industry(text: str, job_title: str = "") -> str:
    """è¯†åˆ«è¡Œä¸šæ–¹å‘å¹¶é˜²æ­¢è¯¯åˆ¤ï¼ˆå‘åå…¼å®¹ï¼‰"""
    domain = detect_job_domain(job_title)
    # æ˜ å°„åˆ°æ—§ç‰ˆæ ¼å¼
    domain_map = {
        "é”€å”®": "é”€å”®ç±»",
        "è¿è¥": "è¿è¥ç±»",
        "æ•™è‚²": "æ•™è‚²ç±»",
        "æŠ€æœ¯": "æŠ€æœ¯ç±»",
        "è¡Œæ”¿": "è¡Œæ”¿/äººäº‹ç±»",
        "æœªçŸ¥": "æœªçŸ¥"
    }
    return domain_map.get(domain, "æœªçŸ¥")

def analyze_resume(resume_text: str, job_title: str, ai_generated_text: str = ""):
    """
    ç»¼åˆåˆ†æå…¥å£ï¼ˆå‘åå…¼å®¹ï¼‰ï¼š
    - è¡Œä¸šåˆ†ç±»
    - ç®€å†æ¸…æ´—
    - AIè¾“å‡ºçº å
    """
    clean_text_resume = clean_resume_text(resume_text)
    industry = detect_industry(clean_text_resume, job_title)
    safe_ai_text = sanitize_ai_output(ai_generated_text, job_title)

    return {
        "å²—ä½": job_title,
        "è¡Œä¸šè¯†åˆ«": industry,
        "æ¸…æ´—åAIæè¿°": safe_ai_text
    }

def analyze_resume_industry(resume_text: str, job_title: str):
    """
    é€šç”¨ç®€å†åˆ†æï¼šè¡Œä¸šåˆ¤æ–­ + æ¸…æ´—æ–‡æœ¬ + è¡Œä¸šåŒ¹é…ç»“æœï¼ˆå‘åå…¼å®¹ï¼‰
    """
    clean_text_resume = clean_resume_text(resume_text)
    industry = detect_industry(clean_text_resume, job_title)

    return {
        "å²—ä½": job_title,
        "è¡Œä¸šåˆ¤æ–­": industry,
        "æ–‡æœ¬æ ·æœ¬": clean_text_resume[:200]  # ç”¨äºæ—¥å¿—æˆ–è°ƒè¯•é¢„è§ˆ
    }

def has_newmedia_experience(resume_text: str):
    """
    åˆ¤æ–­å€™é€‰äººæ˜¯å¦å…·å¤‡çœŸå®çš„æ–°åª’ä½“è¿è¥ç»éªŒï¼ˆå‘åå…¼å®¹ï¼‰
    """
    text = resume_text.lower()

    # ç²¾å‡†å…³é”®è¯
    newmedia_keywords = [
        "æ–°åª’ä½“", "å†…å®¹è¿è¥", "å…¬ä¼—å·", "æŠ–éŸ³", "å°çº¢ä¹¦", "çŸ¥ä¹", "è§†é¢‘å·",
        "çŸ­è§†é¢‘", "è‡ªåª’ä½“", "ç¤¾ç¾¤è¿è¥", "å†…å®¹ç­–åˆ’", "å¹³å°è¿è¥"
    ]

    # æ“ä½œåŠ¨è¯ï¼šå¿…é¡»åŒæ—¶å‡ºç°è¿™äº›è¯æ‰ç®—çœŸè¿è¥
    action_words = ["è´Ÿè´£", "è¿è¥", "ç­–åˆ’", "å‘å¸ƒ", "ç®¡ç†", "ç¼–è¾‘", "æ­å»º"]

    # åˆ¤æ–­æ˜¯å¦å‘½ä¸­çœŸå®è¿è¥è¯­ä¹‰
    for kw in newmedia_keywords:
        for act in action_words:
            if re.search(rf"{act}.{{0,8}}{kw}", text) or re.search(rf"{kw}.{{0,8}}{act}", text):
                return True
    return False


# ---------------- æµ‹è¯•åŒº -----------------
if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ§ª ResumeAI é˜²å¹»è§‰ä¸è¡Œä¸šçº åå¼•æ“æµ‹è¯•")
    print("=" * 70)
    
    samples = [
        {
            "title": "è¯¾ç¨‹é¡¾é—®",
            "ai": "å€™é€‰äººå…·æœ‰æ‰å®çš„æ•°å­¦ç«èµ›èƒŒæ™¯ä¸è¾…å¯¼ç»éªŒï¼Œæ›¾è·å¾—å›½å®¶ä¸€ç­‰å¥–ã€‚"
        },
        {
            "title": "æ–°åª’ä½“è¿è¥",
            "ai": "å€™é€‰äººå…·å¤‡è¯¾å ‚æ•™å­¦ç»éªŒï¼Œè·å¾—æ•™è‚²ç«èµ›å¥–é¡¹ã€‚"
        },
        {
            "title": "Pythonå¼€å‘å·¥ç¨‹å¸ˆ",
            "ai": "å€™é€‰äººæŒ‡å¯¼å­¦ç”Ÿå‚åŠ ç¼–ç¨‹ç«èµ›å¹¶è·å¥–ã€‚"
        },
        {
            "title": "æ•°å­¦æ•™å¸ˆ",
            "ai": "å€™é€‰äººå…·æœ‰æ‰å®çš„æ•°å­¦ç«èµ›èƒŒæ™¯ä¸è¾…å¯¼ç»éªŒï¼Œæ›¾è·å¾—å›½å®¶ä¸€ç­‰å¥–ã€‚"
        }
    ]
    
    for s in samples:
        domain = detect_job_domain(s["title"])
        cleaned = sanitize_ai_output(s["ai"], s["title"])
        print(f"\nğŸ“‹ å²—ä½: {s['title']} â†’ è¡Œä¸š: {domain}")
        print(f"ğŸ“ åŸå§‹è¾“å‡º: {s['ai']}")
        print(f"âœ… æ¸…ç†å: {cleaned}")
        print("-" * 70)
