# backend/services/ai_client.py
import os
from pathlib import Path
from dataclasses import dataclass

import httpx
from dotenv import load_dotenv
from openai import OpenAI

# å¯é åŠ è½½ .env
ROOT = Path(__file__).resolve().parents[2]
for cand in (ROOT / ".env", ROOT / "app" / ".env", Path.cwd() / ".env"):
    if cand.exists():
        load_dotenv(dotenv_path=cand, override=True)
        break


@dataclass
class AIConfig:
    provider: str = None
    api_key: str = None
    base_url: str = None
    model: str = None
    temperature: float = None

    def __post_init__(self):
        """è‡ªåŠ¨è¯†åˆ«ç¡…åŸº / OpenAI"""
        if self.provider is None and self.api_key is None:
            if os.getenv("SILICONFLOW_API_KEY"):
                self.provider = "siliconflow"
                self.api_key = os.getenv("SILICONFLOW_API_KEY")
                self.base_url = os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1")
                self.model = os.getenv("AI_MODEL", "Qwen2.5-32B-Instruct")
                self.temperature = float(os.getenv("AI_TEMPERATURE", "0.7"))
            elif os.getenv("OPENAI_API_KEY"):
                self.provider = "openai"
                self.api_key = os.getenv("OPENAI_API_KEY")
                self.base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
                self.model = os.getenv("AI_MODEL", "gpt-4o-mini")
                self.temperature = float(os.getenv("AI_TEMPERATURE", "0.7"))
            else:
                raise RuntimeError("æœªé…ç½® API Key")


def fix_messages_for_siliconflow(messages):
    """
    SiliconFlow ä¸æ”¯æŒ role=developerï¼Œä¸æ”¯æŒ response_formatã€‚
    è‡ªåŠ¨ä¿®æ­£ä¸º system + user ç»“æ„ã€‚
    """
    fixed = []
    for m in messages:
        role = m.get("role", "")

        if role == "developer":
            # developer â†’ systemï¼ˆæœ€å…¼å®¹ï¼‰
            fixed.append({"role": "system", "content": m["content"]})
        else:
            fixed.append(m)

    return fixed


def get_client_and_cfg():
    """ç»Ÿä¸€åˆ›å»º client"""
    cfg = AIConfig()
    proxy = os.getenv("PROXY_URL") or os.getenv("HTTPS_PROXY") or os.getenv("HTTP_PROXY")

    if proxy:
        http_client = httpx.Client(proxies=proxy, timeout=60.0)
        client = OpenAI(api_key=cfg.api_key, base_url=cfg.base_url, http_client=http_client)
    else:
        client = OpenAI(api_key=cfg.api_key, base_url=cfg.base_url)

    return client, cfg


def chat_completion(client, cfg, messages, **kwargs):
    """
    ğŸš€ ç»Ÿä¸€å…¥å£ï¼šç¡…åŸºè‡ªåŠ¨ä¿®å¤ messages
    """
    if cfg.provider == "siliconflow":
        messages = fix_messages_for_siliconflow(messages)
        kwargs.pop("response_format", None)   # åˆ é™¤ä¸æ”¯æŒçš„å­—æ®µ

    return client.chat.completions.create(
        model=cfg.model,
        messages=messages,
        **kwargs
    )
