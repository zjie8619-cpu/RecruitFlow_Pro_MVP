# backend/services/ai_client.py
import os
from pathlib import Path
from dataclasses import dataclass

from dotenv import load_dotenv
from openai import OpenAI

# å¯é åŠ è½½ .env
ROOT = Path(__file__).resolve().parents[2]
for cand in (ROOT / ".env", ROOT / "app" / ".env", Path.cwd() / ".env"):
    if cand.exists():
        load_dotenv(dotenv_path=cand, override=True)
        break


@dataclass
class AIConfig:
    provider: str = None
    api_key: str = None
    base_url: str = None
    model: str = None
    temperature: float = None

    def __post_init__(self):
        """è‡ªåŠ¨è¯†åˆ«ç¡…åŸº / OpenAI"""
        if self.provider is None and self.api_key is None:
            if os.getenv("SILICONFLOW_API_KEY"):
                self.provider = "siliconflow"
                self.api_key = os.getenv("SILICONFLOW_API_KEY")
                self.base_url = os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1")
                self.model = os.getenv("AI_MODEL", "Qwen2.5-32B-Instruct")
                self.temperature = float(os.getenv("AI_TEMPERATURE", "0.7"))
            elif os.getenv("OPENAI_API_KEY"):
                self.provider = "openai"
                self.api_key = os.getenv("OPENAI_API_KEY")
                self.base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
                self.model = os.getenv("AI_MODEL", "gpt-4o-mini")
                self.temperature = float(os.getenv("AI_TEMPERATURE", "0.7"))
            else:
                # raise RuntimeError("æœªé…ç½® API Key")
                pass


def fix_messages_for_siliconflow(messages):
    """
#     SiliconFlow ä¸æ”¯æŒ role=developer,ä¸æ”¯æŒ response_format.
#     è‡ªåŠ¨ä¿®æ­£ä¸º system + user ç»“æ„.
    """
    fixed = []
    for m in messages:
        role = m.get("role", "")

        if role == "developer":
            # developer â†’ system(æœ€å…¼å®¹)
            fixed.append({"role": "system", "content": m["content"]})
        else:
            fixed.append(m)

    return fixed


def get_client_and_cfg():
    """ç»Ÿä¸€åˆ›å»º client"""
    cfg = AIConfig()
    client = OpenAI(
        api_key=cfg.api_key,
        base_url=cfg.base_url
    )
    return client, cfg


def chat_completion(client, cfg, messages, **kwargs):
    """
    ğŸš€ ç»Ÿä¸€å…¥å£:ç¡…åŸºè‡ªåŠ¨ä¿®å¤ messages
    ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ OpenAI SDK (>=1.0.0) å…¼å®¹æ ¼å¼
    """
    # ç¡®ä¿ client æ˜¯ OpenAI å®ä¾‹ï¼Œè€Œä¸æ˜¯ openai æ¨¡å—
    if not hasattr(client, 'chat') or not hasattr(client.chat, 'completions'):
        # å¦‚æœä¼ å…¥çš„ä¸æ˜¯æ­£ç¡®çš„ OpenAI å®¢æˆ·ç«¯ï¼Œå°è¯•é‡æ–°åˆ›å»º
        if cfg.api_key and cfg.base_url:
            client = OpenAI(
                api_key=cfg.api_key,
                base_url=cfg.base_url
            )
        else:
            raise ValueError(
                "å®¢æˆ·ç«¯å¯¹è±¡æ— æ•ˆã€‚è¯·ç¡®ä¿ä½¿ç”¨ OpenAI() å®ä¾‹ï¼Œè€Œä¸æ˜¯ openai æ¨¡å—ã€‚"
                "å¦‚æœä½¿ç”¨ get_client_and_cfg()ï¼Œå®ƒä¼šè¿”å›æ­£ç¡®çš„å®¢æˆ·ç«¯ã€‚"
            )
    
    if cfg.provider == "siliconflow":
        messages = fix_messages_for_siliconflow(messages)
    kwargs.pop("response_format", None)

    params = {
        "model": kwargs.pop("model", getattr(cfg, "model", None)),
        "messages": messages,
        "temperature": kwargs.pop("temperature", getattr(cfg, "temperature", 0.7)),
    }
    if "max_tokens" in kwargs:
        params["max_tokens"] = kwargs.pop("max_tokens")
    params.update(kwargs)
    params = {k: v for k, v in params.items() if v is not None}

    try:
        # ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ OpenAI API (>=1.0.0)
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯ client.chat.completions.createï¼Œä¸æ˜¯ openai.ChatCompletion.create
        response = client.chat.completions.create(**params)
        
        # è½¬æ¢ä¸ºæ—§æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
        return {
            "choices": [{
                "message": {
                    "content": response.choices[0].message.content,
                    "role": response.choices[0].message.role
                }
            }]
        }
    except AttributeError as e:
        error_msg = str(e)
        if "ChatCompletion" in error_msg or "chat.completions" in error_msg:
            raise RuntimeError(
                "OpenAI API ç‰ˆæœ¬ä¸å…¼å®¹ã€‚è¯·ç¡®ä¿ï¼š\n"
                "1. å·²å®‰è£… openai>=1.0.0ï¼špip install --upgrade openai\n"
                "2. ä»£ç ä½¿ç”¨ client.chat.completions.create è€Œä¸æ˜¯ openai.ChatCompletion.create\n"
                "3. é‡å¯ Streamlit åº”ç”¨ä»¥æ¸…é™¤ç¼“å­˜\n"
                f"åŸå§‹é”™è¯¯: {error_msg}"
            ) from e
        raise
    except Exception as e:
        error_msg = str(e)
        # æ£€æŸ¥æ˜¯å¦æ˜¯ OpenAI SDK çš„ç‰ˆæœ¬å…¼å®¹æ€§é”™è¯¯
        if "ChatCompletion" in error_msg and "no longer supported" in error_msg:
            raise RuntimeError(
                "OpenAI API ç‰ˆæœ¬ä¸å…¼å®¹ã€‚æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬çš„ API è°ƒç”¨æ–¹å¼ã€‚\n"
                "è§£å†³æ–¹æ¡ˆï¼š\n"
                "1. å‡çº§ openai åŒ…ï¼špip install --upgrade openai\n"
                "2. ç¡®ä¿ä»£ç ä½¿ç”¨ client.chat.completions.create\n"
                "3. å®Œå…¨é‡å¯ Streamlit åº”ç”¨ï¼ˆåœæ­¢æ‰€æœ‰è¿›ç¨‹å¹¶é‡æ–°å¯åŠ¨ï¼‰\n"
                f"åŸå§‹é”™è¯¯: {error_msg}"
            ) from e
        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä¿ç•™åŸå§‹é”™è¯¯ä¿¡æ¯
        raise
